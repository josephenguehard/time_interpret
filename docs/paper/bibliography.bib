@article{kokhlikyan2020captum,
  title={Captum: A unified and generic model interpretability library for pytorch},
  author={Kokhlikyan, Narine and Miglani, Vivek and Martin, Miguel and Wang, Edward and Alsallakh, Bilal and Reynolds, Jonathan and Melnikov, Alexander and Kliushkina, Natalia and Araya, Carlos and Yan, Siqi and others},
  journal={arXiv preprint arXiv:2009.07896},
  year={2020}
}

@incollection{NEURIPS2019_9015,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@software{Falcon_PyTorch_Lightning_2019,
author = {Falcon, William and {The PyTorch Lightning team}},
doi = {10.5281/zenodo.3828935},
license = {Apache-2.0},
month = mar,
title = {{PyTorch Lightning}},
url = {https://github.com/Lightning-AI/lightning},
version = {1.4},
year = {2019}
}

@article{tonekaboni2020went,
  title={What went wrong and when? Instance-wise feature importance for time-series black-box models},
  author={Tonekaboni, Sana and Joshi, Shalmali and Campbell, Kieran and Duvenaud, David K and Goldenberg, Anna},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={799--809},
  year={2020}
}

@article{slack2021reliable,
  title={Reliable post hoc explanations: Modeling uncertainty in explainability},
  author={Slack, Dylan and Hilgard, Anna and Singh, Sameer and Lakkaraju, Himabindu},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={9391--9404},
  year={2021}
}

@inproceedings{ribeiro2016should,
  title={" Why should i trust you?" Explaining the predictions of any classifier},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={1135--1144},
  year={2016}
}

@article{lundberg2017unified,
  title={A unified approach to interpreting model predictions},
  author={Lundberg, Scott M and Lee, Su-In},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{sanyal2021discretized,
  title={Discretized integrated gradients for explaining language models},
  author={Sanyal, Soumya and Ren, Xiang},
  journal={arXiv preprint arXiv:2108.13654},
  year={2021}
}

@inproceedings{crabbe2021explaining,
  title={Explaining time series predictions with dynamic masks},
  author={Crabb{\'e}, Jonathan and Van Der Schaar, Mihaela},
  booktitle={International Conference on Machine Learning},
  pages={2166--2177},
  year={2021},
  organization={PMLR}
}

@inproceedings{fong2017interpretable,
  title={Interpretable explanations of black boxes by meaningful perturbation},
  author={Fong, Ruth C and Vedaldi, Andrea},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={3429--3437},
  year={2017}
}

@inproceedings{fong2019understanding,
  title={Understanding deep networks via extremal perturbations and smooth masks},
  author={Fong, Ruth and Patrick, Mandela and Vedaldi, Andrea},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={2950--2958},
  year={2019}
}
