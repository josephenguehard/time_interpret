

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Attribution Methods &mdash; Time Interpret 0.2.1 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="_static/sphinx_paramlinks.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
        <script src="_static/clipboard.min.js"></script>
        <script src="_static/copybutton.js"></script>
        <script src="_static/toggleprompt.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Attribution Models" href="attr_models.html" />
    <link rel="prev" title="Installation" href="install.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> Time Interpret
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="install.html">Installation</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Attribution Methods</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#summary">Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-tint.attr">Detailed classes and methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.AugmentedOcclusion"><code class="docutils literal notranslate"><span class="pre">AugmentedOcclusion</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.AugmentedOcclusion.attribute"><code class="docutils literal notranslate"><span class="pre">AugmentedOcclusion.attribute()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.BayesKernelShap"><code class="docutils literal notranslate"><span class="pre">BayesKernelShap</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.BayesLime"><code class="docutils literal notranslate"><span class="pre">BayesLime</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.DiscretetizedIntegratedGradients"><code class="docutils literal notranslate"><span class="pre">DiscretetizedIntegratedGradients</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.DiscretetizedIntegratedGradients.attribute"><code class="docutils literal notranslate"><span class="pre">DiscretetizedIntegratedGradients.attribute()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.DynaMask"><code class="docutils literal notranslate"><span class="pre">DynaMask</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.DynaMask.attribute"><code class="docutils literal notranslate"><span class="pre">DynaMask.attribute()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.ExtremalMask"><code class="docutils literal notranslate"><span class="pre">ExtremalMask</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.ExtremalMask.attribute"><code class="docutils literal notranslate"><span class="pre">ExtremalMask.attribute()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.FeatureAblation"><code class="docutils literal notranslate"><span class="pre">FeatureAblation</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.FeatureAblation.attribute"><code class="docutils literal notranslate"><span class="pre">FeatureAblation.attribute()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.Fit"><code class="docutils literal notranslate"><span class="pre">Fit</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.Fit.attribute"><code class="docutils literal notranslate"><span class="pre">Fit.attribute()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.Fit.representation"><code class="docutils literal notranslate"><span class="pre">Fit.representation()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.GeodesicIntegratedGradients"><code class="docutils literal notranslate"><span class="pre">GeodesicIntegratedGradients</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.GeodesicIntegratedGradients.attribute"><code class="docutils literal notranslate"><span class="pre">GeodesicIntegratedGradients.attribute()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.GeodesicIntegratedGradients.compute_curvature"><code class="docutils literal notranslate"><span class="pre">GeodesicIntegratedGradients.compute_curvature()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.GeodesicIntegratedGradients.has_convergence_delta"><code class="docutils literal notranslate"><span class="pre">GeodesicIntegratedGradients.has_convergence_delta()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.LofKernelShap"><code class="docutils literal notranslate"><span class="pre">LofKernelShap</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.LofLime"><code class="docutils literal notranslate"><span class="pre">LofLime</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.NonLinearitiesTunnel"><code class="docutils literal notranslate"><span class="pre">NonLinearitiesTunnel</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.NonLinearitiesTunnel.attribute"><code class="docutils literal notranslate"><span class="pre">NonLinearitiesTunnel.attribute()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.NonLinearitiesTunnel.has_convergence_delta"><code class="docutils literal notranslate"><span class="pre">NonLinearitiesTunnel.has_convergence_delta()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.Occlusion"><code class="docutils literal notranslate"><span class="pre">Occlusion</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.Occlusion.attribute"><code class="docutils literal notranslate"><span class="pre">Occlusion.attribute()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.Retain"><code class="docutils literal notranslate"><span class="pre">Retain</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.Retain.attribute"><code class="docutils literal notranslate"><span class="pre">Retain.attribute()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.Retain.representation"><code class="docutils literal notranslate"><span class="pre">Retain.representation()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.SequentialIntegratedGradients"><code class="docutils literal notranslate"><span class="pre">SequentialIntegratedGradients</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.SequentialIntegratedGradients.attribute"><code class="docutils literal notranslate"><span class="pre">SequentialIntegratedGradients.attribute()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.SequentialIntegratedGradients.has_convergence_delta"><code class="docutils literal notranslate"><span class="pre">SequentialIntegratedGradients.has_convergence_delta()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.TemporalAugmentedOcclusion"><code class="docutils literal notranslate"><span class="pre">TemporalAugmentedOcclusion</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.TemporalAugmentedOcclusion.attribute"><code class="docutils literal notranslate"><span class="pre">TemporalAugmentedOcclusion.attribute()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.TemporalIntegratedGradients"><code class="docutils literal notranslate"><span class="pre">TemporalIntegratedGradients</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.TemporalIntegratedGradients.attribute"><code class="docutils literal notranslate"><span class="pre">TemporalIntegratedGradients.attribute()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.TemporalOcclusion"><code class="docutils literal notranslate"><span class="pre">TemporalOcclusion</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.TemporalOcclusion.attribute"><code class="docutils literal notranslate"><span class="pre">TemporalOcclusion.attribute()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.TimeForwardTunnel"><code class="docutils literal notranslate"><span class="pre">TimeForwardTunnel</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.TimeForwardTunnel.attribute"><code class="docutils literal notranslate"><span class="pre">TimeForwardTunnel.attribute()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.TimeForwardTunnel.has_convergence_delta"><code class="docutils literal notranslate"><span class="pre">TimeForwardTunnel.has_convergence_delta()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="attr_models.html">Attribution Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="datasets.html">Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="metrics.html">Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="metrics_weights.html">Metrics Weights</a></li>
<li class="toctree-l1"><a class="reference internal" href="white_box_metrics.html">White Box Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="models.html">Models</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Time Interpret</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Attribution Methods</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/attr.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <section id="attribution-methods">
<h1>Attribution Methods<a class="headerlink" href="#attribution-methods" title="Permalink to this heading">¶</a></h1>
<p>time_interpret expands on Captum by providing time series specific
attribution methods. These methods are listed below:</p>
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this heading">¶</a></h2>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#tint.attr.AugmentedOcclusion" title="tint.attr.AugmentedOcclusion"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.AugmentedOcclusion</span></code></a>(forward_func, data)</p></td>
<td><p>Augmented Occlusion by sampling the baseline from a bootstrapped distribution.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tint.attr.BayesKernelShap" title="tint.attr.BayesKernelShap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.BayesKernelShap</span></code></a>(forward_func[, ...])</p></td>
<td><p>Bayesian version of KernelShap.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tint.attr.BayesLime" title="tint.attr.BayesLime"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.BayesLime</span></code></a>(forward_func[, ...])</p></td>
<td><p>Bayesian version of Lime.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tint.attr.DiscretetizedIntegratedGradients" title="tint.attr.DiscretetizedIntegratedGradients"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.DiscretetizedIntegratedGradients</span></code></a>(...)</p></td>
<td><p>Discretetized Integrated Gradients.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tint.attr.DynaMask" title="tint.attr.DynaMask"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.DynaMask</span></code></a>(forward_func)</p></td>
<td><p>Dynamic masks.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tint.attr.ExtremalMask" title="tint.attr.ExtremalMask"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.ExtremalMask</span></code></a>(forward_func)</p></td>
<td><p>Extremal masks.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tint.attr.FeatureAblation" title="tint.attr.FeatureAblation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.FeatureAblation</span></code></a>(forward_func)</p></td>
<td><p>Feature ablation.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tint.attr.Fit" title="tint.attr.Fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.Fit</span></code></a>(forward_func[, generator, ...])</p></td>
<td><p>Feature Importance in Time.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tint.attr.GeodesicIntegratedGradients" title="tint.attr.GeodesicIntegratedGradients"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.GeodesicIntegratedGradients</span></code></a>(...[, ...])</p></td>
<td><p>Geodesic Integrated Gradients.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tint.attr.LofKernelShap" title="tint.attr.LofKernelShap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.LofKernelShap</span></code></a>(forward_func, embeddings)</p></td>
<td><p>Local Outlier Factor Kernel Shap.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tint.attr.LofLime" title="tint.attr.LofLime"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.LofLime</span></code></a>(forward_func, embeddings)</p></td>
<td><p>Local Outlier Factor Lime.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tint.attr.NonLinearitiesTunnel" title="tint.attr.NonLinearitiesTunnel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.NonLinearitiesTunnel</span></code></a>(...)</p></td>
<td><p>Replace non linearities (or any module) with others before running an attribution method.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tint.attr.Occlusion" title="tint.attr.Occlusion"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.Occlusion</span></code></a>(forward_func)</p></td>
<td><p>A perturbation based approach to compute attribution, involving replacing each contiguous rectangular region with a given baseline / reference, and computing the difference in output.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tint.attr.Retain" title="tint.attr.Retain"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.Retain</span></code></a>([forward_func, retain, ...])</p></td>
<td><p>Retain explainer method.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tint.attr.SequentialIntegratedGradients" title="tint.attr.SequentialIntegratedGradients"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.SequentialIntegratedGradients</span></code></a>(...)</p></td>
<td><p>Sequential Integrated Gradients.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tint.attr.TemporalAugmentedOcclusion" title="tint.attr.TemporalAugmentedOcclusion"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.TemporalAugmentedOcclusion</span></code></a>(...[, ...])</p></td>
<td><p>Temporal Augmented Occlusion.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tint.attr.TemporalIntegratedGradients" title="tint.attr.TemporalIntegratedGradients"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.TemporalIntegratedGradients</span></code></a>(...[, ...])</p></td>
<td><p>Temporal Integrated Gradients.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tint.attr.TemporalOcclusion" title="tint.attr.TemporalOcclusion"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.TemporalOcclusion</span></code></a>(forward_func)</p></td>
<td><p>Temporal Occlusion.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tint.attr.TimeForwardTunnel" title="tint.attr.TimeForwardTunnel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.TimeForwardTunnel</span></code></a>(attribution_method)</p></td>
<td><p>Time Forward Tunnel.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="module-tint.attr">
<span id="detailed-classes-and-methods"></span><h2>Detailed classes and methods<a class="headerlink" href="#module-tint.attr" title="Permalink to this heading">¶</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.AugmentedOcclusion">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">AugmentedOcclusion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_sampling</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_temporal</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/augmented_occlusion.html#AugmentedOcclusion"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.AugmentedOcclusion" title="Permalink to this definition">¶</a></dt>
<dd><p>Augmented Occlusion by sampling the baseline from a bootstrapped
distribution.</p>
<p>Instead of replacing occulted data by zero, this method samples data from
a distribution, which replace occulted data. The resulted occulted data
should be closer to the actual data as a result, limiting the amount of
out of distribution samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.AugmentedOcclusion.params.forward_func"></span><strong>forward_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.AugmentedOcclusion.params.forward_func">¶</a> (<em>callable</em>) – The forward function of the model or
any modification of it.</p></li>
<li><p><span class="target" id="tint.attr.AugmentedOcclusion.params.data"></span><strong>data</strong><a class="paramlink headerlink reference internal" href="#tint.attr.AugmentedOcclusion.params.data">¶</a> (<em>tuple</em><em>, </em><em>Tensor</em>) – The data from which the baselines are sampled.
The shape of the data must be the same as the inputs, except
on the first dimension.</p></li>
<li><p><span class="target" id="tint.attr.AugmentedOcclusion.params.n_sampling"></span><strong>n_sampling</strong><a class="paramlink headerlink reference internal" href="#tint.attr.AugmentedOcclusion.params.n_sampling">¶</a> (<em>int</em>) – Number of sampling to run for each occlusion.
Default: 1</p></li>
<li><p><span class="target" id="tint.attr.AugmentedOcclusion.params.is_temporal"></span><strong>is_temporal</strong><a class="paramlink headerlink reference internal" href="#tint.attr.AugmentedOcclusion.params.is_temporal">¶</a> (<em>bool</em>) – Whether the data is temporal or not.
If <code class="docutils literal notranslate"><span class="pre">True</span></code>, the data will be ablated to the inputs
on the temporal dimension (dimension 1).
Default: False</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://arxiv.org/abs/2003.02821">https://arxiv.org/abs/2003.02821</a></p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">AugmentedOcclusion</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.models</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">AugmentedOcclusion</span><span class="p">(</span><span class="n">mlp</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.AugmentedOcclusion.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sliding_window_shapes</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">perturbations_per_eval</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attributions_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></span><a class="reference internal" href="_modules/tint/attr/augmented_occlusion.html#AugmentedOcclusion.attribute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.AugmentedOcclusion.attribute" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.AugmentedOcclusion.attribute.params.inputs"></span><strong>inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.AugmentedOcclusion.attribute.params.inputs">¶</a> (<em>tensor</em><em> or </em><em>tuple</em><em> of </em><em>tensors</em>) – Input for which occlusion
attributions are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.
If forward_func takes multiple tensors as input, a tuple
of the input tensors should be provided. It is assumed
that for all given input tensors, dimension 0 corresponds
to the number of examples (aka batch size), and if
multiple input tensors are provided, the examples must
be aligned appropriately.</p></li>
<li><p><span class="target" id="tint.attr.AugmentedOcclusion.attribute.params.sliding_window_shapes"></span><strong>sliding_window_shapes</strong><a class="paramlink headerlink reference internal" href="#tint.attr.AugmentedOcclusion.attribute.params.sliding_window_shapes">¶</a> (<em>tuple</em><em> or </em><em>tuple</em><em> of </em><em>tuples</em>) – Shape of patch
(hyperrectangle) to occlude each input. For a single
input tensor, this must be a tuple of length equal to the
number of dimensions of the input tensor - 1, defining
the dimensions of the patch. If the input tensor is 1-d,
this should be an empty tuple. For multiple input tensors,
this must be a tuple containing one tuple for each input
tensor defining the dimensions of the patch for that
input tensor, as described for the single tensor case.</p></li>
<li><p><span class="target" id="tint.attr.AugmentedOcclusion.attribute.params.strides"></span><strong>strides</strong><a class="paramlink headerlink reference internal" href="#tint.attr.AugmentedOcclusion.attribute.params.strides">¶</a> (<em>int</em><em> or </em><em>tuple</em><em> or </em><em>tuple</em><em> of </em><em>ints</em><em> or </em><em>tuple</em><em> of </em><em>tuples</em><em>, </em><em>optional</em>) – This defines the step by which the occlusion hyperrectangle
should be shifted by in each direction for each iteration.
For a single tensor input, this can be either a single
integer, which is used as the step size in each direction,
or a tuple of integers matching the number of dimensions
in the occlusion shape, defining the step size in the
corresponding dimension. For multiple tensor inputs, this
can be either a tuple of integers, one for each input
tensor (used for all dimensions of the corresponding
tensor), or a tuple of tuples, providing the stride per
dimension for each tensor.
To ensure that all inputs are covered by at least one
sliding window, the stride for any dimension must be
&lt;= the corresponding sliding window dimension if the
sliding window dimension is less than the input
dimension.
If None is provided, a stride of 1 is used for each
dimension of each input tensor.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.AugmentedOcclusion.attribute.params.target"></span><strong>target</strong><a class="paramlink headerlink reference internal" href="#tint.attr.AugmentedOcclusion.attribute.params.target">¶</a> (<em>int</em><em>, </em><em>tuple</em><em>, </em><em>tensor</em><em> or </em><em>list</em><em>, </em><em>optional</em>) – <p>Output indices for
which difference is computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><p>a single integer or a tensor containing a single
integer, which is applied to all input examples</p></li>
<li><p>a list of integers or a 1D tensor, with length matching
the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p></li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><p>A single tuple, which contains #output_dims - 1
elements. This target index is applied to all examples.</p></li>
<li><p>A list of tuples with length equal to the number of
examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p></li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.AugmentedOcclusion.attribute.params.additional_forward_args"></span><strong>additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.AugmentedOcclusion.attribute.params.additional_forward_args">¶</a> (<em>any</em><em>, </em><em>optional</em>) – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a
tuple containing multiple additional arguments including
tensors or any arbitrary python types. These arguments
are provided to forward_func in order following the
arguments in inputs.
For a tensor, the first dimension of the tensor must
correspond to the number of examples. For all other types,
the given argument is used for all forward evaluations.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.AugmentedOcclusion.attribute.params.perturbations_per_eval"></span><strong>perturbations_per_eval</strong><a class="paramlink headerlink reference internal" href="#tint.attr.AugmentedOcclusion.attribute.params.perturbations_per_eval">¶</a> (<em>int</em><em>, </em><em>optional</em>) – Allows multiple occlusions
to be included in one batch (one call to forward_fn).
By default, perturbations_per_eval is 1, so each occlusion
is processed individually.
Each forward pass will contain a maximum of
perturbations_per_eval * #examples samples.
For DataParallel models, each batch is split among the
available devices, so evaluations on each available
device contain at most
(perturbations_per_eval * #examples) / num_devices
samples.
Default: 1</p></li>
<li><p><span class="target" id="tint.attr.AugmentedOcclusion.attribute.params.attributions_fn"></span><strong>attributions_fn</strong><a class="paramlink headerlink reference internal" href="#tint.attr.AugmentedOcclusion.attribute.params.attributions_fn">¶</a> (<em>Callable</em><em>, </em><em>optional</em>) – Applies a function to the
attributions before performing the weighted sum.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.AugmentedOcclusion.attribute.params.show_progress"></span><strong>show_progress</strong><a class="paramlink headerlink reference internal" href="#tint.attr.AugmentedOcclusion.attribute.params.show_progress">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – Displays the progress of
computation. It will try to use tqdm if available for
advanced features (e.g. time estimation). Otherwise, it
will fallback to a simple output of progress.
Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><dl class="simple">
<dt><strong>attributions</strong> (<em>tensor</em> or tuple of <em>tensors</em>):</dt><dd><p>The attributions with respect to each input feature.
Attributions will always be
the same size as the provided inputs, with each value
providing the attribution of the corresponding input index.
If a single tensor is provided as inputs, a single tensor
is returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>tensor</em> or tuple of <em>tensors</em> of <strong>attributions</strong></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.BayesKernelShap">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">BayesKernelShap</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">interpretable_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Model</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/bayes.html#BayesKernelShap"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.BayesKernelShap" title="Permalink to this definition">¶</a></dt>
<dd><p>Bayesian version of KernelShap.</p>
<p>This method replace the linear regression of the original KernelShap with
a bayesian linear regression, allowing to model uncertainty in
explainability.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.BayesKernelShap.params.forward_func"></span><strong>forward_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.BayesKernelShap.params.forward_func">¶</a> (<em>callable</em>) – The forward function of the model or any
modification of it.</p></li>
<li><p><span class="target" id="tint.attr.BayesKernelShap.params.interpretable_model"></span><strong>interpretable_model</strong><a class="paramlink headerlink reference internal" href="#tint.attr.BayesKernelShap.params.interpretable_model">¶</a> (<em>Model</em>) – <p>Model object to train interpretable model.</p>
<p>This argument is optional and defaults to SkLearnBayesianRidge(),
which is a wrapper around the Bayesian Ridge in SkLearn.
This requires having sklearn version &gt;= 0.23 available.</p>
<p>Other predefined interpretable linear models are provided in
tint.attr.models.bayes_linear.</p>
<p>Alternatively, a custom model object must provide a <cite>fit</cite> method to
train the model, given a dataloader, with batches containing
three tensors:</p>
<ul>
<li><p>interpretable_inputs: Tensor
[2D num_samples x num_interp_features],</p></li>
<li><p>expected_outputs: Tensor [1D num_samples],</p></li>
<li><p>weights: Tensor [1D num_samples]</p></li>
</ul>
<p>The model object must also provide a <cite>representation</cite> method to
access the appropriate coefficients or representation of the
interpretable model after fitting.</p>
<p>Note that calling fit multiple times should retrain the
interpretable model, each attribution call reuses
the same given interpretable model object.</p>
<p>Default: None</p>
</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://arxiv.org/pdf/2008.05030">https://arxiv.org/pdf/2008.05030</a></p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">BayesKernelShap</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.models</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">BayesKernelShap</span><span class="p">(</span><span class="n">mlp</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.BayesLime">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">BayesLime</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">interpretable_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Model</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/bayes.html#BayesLime"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.BayesLime" title="Permalink to this definition">¶</a></dt>
<dd><p>Bayesian version of Lime.</p>
<p>This method replace the linear regression of the original Lime with a
bayesian linear regression, allowing to model uncertainty in
explainability.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.BayesLime.params.forward_func"></span><strong>forward_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.BayesLime.params.forward_func">¶</a> (<em>callable</em>) – The forward function of the model or any
modification of it.</p></li>
<li><p><span class="target" id="tint.attr.BayesLime.params.interpretable_model"></span><strong>interpretable_model</strong><a class="paramlink headerlink reference internal" href="#tint.attr.BayesLime.params.interpretable_model">¶</a> (<em>Model</em>) – <p>Model object to train interpretable model.</p>
<p>This argument is optional and defaults to SkLearnBayesianRidge(),
which is a wrapper around the Bayesian Ridge in SkLearn.
This requires having sklearn version &gt;= 0.23 available.</p>
<p>Other predefined interpretable linear models are provided in
tint.attr.models.bayes_linear.</p>
<p>Alternatively, a custom model object must provide a <cite>fit</cite> method to
train the model, given a dataloader, with batches containing
three tensors:</p>
<ul>
<li><p>interpretable_inputs: Tensor
[2D num_samples x num_interp_features],</p></li>
<li><p>expected_outputs: Tensor [1D num_samples],</p></li>
<li><p>weights: Tensor [1D num_samples]</p></li>
</ul>
<p>The model object must also provide a <cite>representation</cite> method to
access the appropriate coefficients or representation of the
interpretable model after fitting.</p>
<p>Note that calling fit multiple times should retrain the
interpretable model, each attribution call reuses
the same given interpretable model object.</p>
<p>Default: None</p>
</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://arxiv.org/pdf/2008.05030">https://arxiv.org/pdf/2008.05030</a></p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">BayesLime</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.models</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">BayesLime</span><span class="p">(</span><span class="n">mlp</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.DiscretetizedIntegratedGradients">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">DiscretetizedIntegratedGradients</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multiply_by_inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/discretised_ig.html#DiscretetizedIntegratedGradients"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.DiscretetizedIntegratedGradients" title="Permalink to this definition">¶</a></dt>
<dd><p>Discretetized Integrated Gradients.</p>
<p>This method discretizes the path between an input and a reference
baseline. It was developed for text data and language models, to handle
the discreteness of the word embedding space.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.DiscretetizedIntegratedGradients.params.forward_func"></span><strong>forward_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.DiscretetizedIntegratedGradients.params.forward_func">¶</a> (<em>callable</em>) – The forward function of the model or any
modification of it</p></li>
<li><p><span class="target" id="tint.attr.DiscretetizedIntegratedGradients.params.multiply_by_inputs"></span><strong>multiply_by_inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.DiscretetizedIntegratedGradients.params.multiply_by_inputs">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – <p>Indicates whether to factor
model inputs’ multiplier in the final attribution scores.
In the literature this is also known as local vs global
attribution. If inputs’ multiplier isn’t factored in,
then that type of attribution method is also called local
attribution. If it is, then that type of attribution
method is called global.
More detailed can be found here:
<a class="reference external" href="https://arxiv.org/abs/1711.06104">https://arxiv.org/abs/1711.06104</a></p>
<p>In case of integrated gradients, if <cite>multiply_by_inputs</cite>
is set to True, final sensitivity scores are being multiplied by
(inputs - baselines).</p>
</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://github.com/INK-USC/DIG">https://github.com/INK-USC/DIG</a></p>
<p><a class="reference external" href="https://arxiv.org/abs/2108.13654">https://arxiv.org/abs/2108.13654</a></p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">DiscretetizedIntegratedGradients</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.models</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">DiscretetizedIntegratedGradients</span><span class="p">(</span><span class="n">mlp</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.DiscretetizedIntegratedGradients.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scaled_features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_convergence_delta</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">TensorOrTupleOfTensorsGeneric</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">TensorOrTupleOfTensorsGeneric</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/tint/attr/discretised_ig.html#DiscretetizedIntegratedGradients.attribute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.DiscretetizedIntegratedGradients.attribute" title="Permalink to this definition">¶</a></dt>
<dd><p>Attribute method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.DiscretetizedIntegratedGradients.attribute.params.scaled_features"></span><strong>scaled_features</strong><a class="paramlink headerlink reference internal" href="#tint.attr.DiscretetizedIntegratedGradients.attribute.params.scaled_features">¶</a> – (tensor, tuple):  Input for which integrated
gradients are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.
If forward_func takes multiple tensors as input, a tuple
of the input tensors should be provided. It is assumed
that for all given input tensors, dimension 0 corresponds
to the number of examples, and if multiple input tensors
are provided, the examples must be aligned appropriately.</p></li>
<li><p><span class="target" id="tint.attr.DiscretetizedIntegratedGradients.attribute.params.target"></span><strong>target</strong><a class="paramlink headerlink reference internal" href="#tint.attr.DiscretetizedIntegratedGradients.attribute.params.target">¶</a> (<em>int</em><em>, </em><em>int</em><em>, </em><em>tuple</em><em>, </em><em>tensor</em><em>, </em><em>list</em>) – <p>Output indices for
which gradients are computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><p>a single integer or a tensor containing a single
integer, which is applied to all input examples</p></li>
<li><p>a list of integers or a 1D tensor, with length matching
the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p></li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><p>A single tuple, which contains #output_dims - 1
elements. This target index is applied to all examples.</p></li>
<li><p>A list of tuples with length equal to the number of
examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p></li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.DiscretetizedIntegratedGradients.attribute.params.additional_forward_args"></span><strong>additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.DiscretetizedIntegratedGradients.attribute.params.additional_forward_args">¶</a> (<em>Any</em>) – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a
tuple containing multiple additional arguments including
tensors or any arbitrary python types. These arguments
are provided to forward_func in order following the
arguments in inputs.
For a tensor, the first dimension of the tensor must
correspond to the number of examples. It will be
repeated for each of <cite>n_steps</cite> along the integrated
path. For all other types, the given argument is used
for all forward evaluations.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.DiscretetizedIntegratedGradients.attribute.params.n_steps"></span><strong>n_steps</strong><a class="paramlink headerlink reference internal" href="#tint.attr.DiscretetizedIntegratedGradients.attribute.params.n_steps">¶</a> – The number of steps used by the approximation
method. Default: 50.</p></li>
<li><p><span class="target" id="tint.attr.DiscretetizedIntegratedGradients.attribute.params.return_convergence_delta"></span><strong>return_convergence_delta</strong><a class="paramlink headerlink reference internal" href="#tint.attr.DiscretetizedIntegratedGradients.attribute.params.return_convergence_delta">¶</a> – Indicates whether to return
convergence delta or not. If <cite>return_convergence_delta</cite>
is set to True convergence delta will be returned in
a tuple following attributions.
Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><dl class="simple">
<dt><strong>attributions</strong> (<em>tensor</em> or tuple of <em>tensors</em>):</dt><dd><p>Integrated gradients with respect to each input feature.
attributions will always be the same size as the provided
inputs, with each value providing the attribution of the
corresponding input index.
If a single tensor is provided as inputs, a single tensor is
returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>delta</strong> (<em>tensor</em>, returned if return_convergence_delta=True):</dt><dd><p>The difference between the total approximated and true
integrated gradients. This is computed using the property
that the total sum of forward_func(inputs) -
forward_func(baselines) must equal the total sum of the
integrated gradient.
Delta is calculated per example, meaning that the number of
elements in returned delta tensor is equal to the number of
of examples in inputs.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>attributions</strong> or 2-element tuple of <strong>attributions</strong>, <strong>delta</strong></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.DynaMask">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">DynaMask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/dynamic_masks.html#DynaMask"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.DynaMask" title="Permalink to this definition">¶</a></dt>
<dd><p>Dynamic masks.</p>
<p>This method aims to explain time series data, by learning a mask
representing features importance. This method was inspired from
Fong et al., and can be used in “preservation game” mode: trying to keep
the closest predictions, compared with unperturebed data, with the
minimal number of features, or in “deletion game” mode, trying to get the
furthest predictions by removing the minimal number of features.</p>
<p>This implementation batchify the original method by leanrning in parallel
multiple inputs and multiple <code class="docutils literal notranslate"><span class="pre">keep_ratio</span></code> (called <code class="docutils literal notranslate"><span class="pre">mask_group</span></code> in the
original implementation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="target" id="tint.attr.DynaMask.params.forward_func"></span><strong>forward_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.DynaMask.params.forward_func">¶</a> (<em>callable</em>) – The forward function of the model or any
modification of it.</p>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://arxiv.org/pdf/2106.05303">https://arxiv.org/pdf/2106.05303</a>
<a class="reference external" href="https://arxiv.org/pdf/1910.08485">https://arxiv.org/pdf/1910.08485</a></p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">DynaMask</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.models</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">DynaMask</span><span class="p">(</span><span class="n">mlp</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.DynaMask.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Trainer</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_net</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="attr_models.html#tint.attr.models.MaskNet" title="tint.attr.models.mask.MaskNet"><span class="pre">MaskNet</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temporal_additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_temporal_attributions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_best_ratio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></span><a class="reference internal" href="_modules/tint/attr/dynamic_masks.html#DynaMask.attribute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.DynaMask.attribute" title="Permalink to this definition">¶</a></dt>
<dd><p>Attribute method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.DynaMask.attribute.params.inputs"></span><strong>inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.DynaMask.attribute.params.inputs">¶</a> (<em>tuple</em><em>, </em><em>th.Tensor</em>) – Input data.</p></li>
<li><p><span class="target" id="tint.attr.DynaMask.attribute.params.additional_forward_args"></span><strong>additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.DynaMask.attribute.params.additional_forward_args">¶</a> (<em>Any</em>) – Any additional argument passed
to the model. Default to <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><span class="target" id="tint.attr.DynaMask.attribute.params.trainer"></span><strong>trainer</strong><a class="paramlink headerlink reference internal" href="#tint.attr.DynaMask.attribute.params.trainer">¶</a> (<em>Trainer</em>) – Pytorch Lightning trainer. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, a
default trainer will be provided. Default to <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><span class="target" id="tint.attr.DynaMask.attribute.params.mask_net"></span><strong>mask_net</strong><a class="paramlink headerlink reference internal" href="#tint.attr.DynaMask.attribute.params.mask_net">¶</a> (<a class="reference internal" href="attr_models.html#tint.attr.models.MaskNet" title="tint.attr.models.MaskNet"><em>MaskNet</em></a>) – A Mask model. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, a default model
will be provided. Default to <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><span class="target" id="tint.attr.DynaMask.attribute.params.batch_size"></span><strong>batch_size</strong><a class="paramlink headerlink reference internal" href="#tint.attr.DynaMask.attribute.params.batch_size">¶</a> (<em>int</em>) – Batch size for Mask training. Default to 32</p></li>
<li><p><span class="target" id="tint.attr.DynaMask.attribute.params.temporal_additional_forward_args"></span><strong>temporal_additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.DynaMask.attribute.params.temporal_additional_forward_args">¶</a> (<em>tuple</em>) – Set each
additional forward arg which is temporal.
Only used with return_temporal_attributions.
Default to <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><span class="target" id="tint.attr.DynaMask.attribute.params.return_temporal_attributions"></span><strong>return_temporal_attributions</strong><a class="paramlink headerlink reference internal" href="#tint.attr.DynaMask.attribute.params.return_temporal_attributions">¶</a> (<em>bool</em>) – Whether to return
attributions for all times or not. Default to <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><span class="target" id="tint.attr.DynaMask.attribute.params.return_best_ratio"></span><strong>return_best_ratio</strong><a class="paramlink headerlink reference internal" href="#tint.attr.DynaMask.attribute.params.return_best_ratio">¶</a> (<em>bool</em>) – Whether to return the best keep_ratio
or not. Default to <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Attributions.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(th.Tensor, tuple)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.ExtremalMask">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">ExtremalMask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/extremal_mask.html#ExtremalMask"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.ExtremalMask" title="Permalink to this definition">¶</a></dt>
<dd><p>Extremal masks.</p>
<p>This method extends the work of Fong et al. and Crabbé et al. by allowing
the perturbation function to be learnt. This is in addition to the learnt
mask. For instance, this perturbation function can be learnt with a RNN
while Crabbé et al. only consider fixed perturbations: Gaussian blur
and fade to moving average.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="target" id="tint.attr.ExtremalMask.params.forward_func"></span><strong>forward_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.ExtremalMask.params.forward_func">¶</a> (<em>callable</em>) – The forward function of the model or any
modification of it.</p>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://arxiv.org/pdf/2106.05303">https://arxiv.org/pdf/2106.05303</a>
<a class="reference external" href="https://arxiv.org/pdf/1910.08485">https://arxiv.org/pdf/1910.08485</a></p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">ExtremalMask</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.models</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">ExtremalMask</span><span class="p">(</span><span class="n">mlp</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.ExtremalMask.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baselines</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Trainer</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_net</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="attr_models.html#tint.attr.models.ExtremalMaskNet" title="tint.attr.models.extremal_mask.ExtremalMaskNet"><span class="pre">ExtremalMaskNet</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temporal_additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_temporal_attributions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></span><a class="reference internal" href="_modules/tint/attr/extremal_mask.html#ExtremalMask.attribute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.ExtremalMask.attribute" title="Permalink to this definition">¶</a></dt>
<dd><p>Attribute method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.ExtremalMask.attribute.params.inputs"></span><strong>inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.ExtremalMask.attribute.params.inputs">¶</a> (<em>tensor</em><em> or </em><em>tuple</em><em> of </em><em>tensors</em>) – Input for which occlusion
attributions are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.
If forward_func takes multiple tensors as input, a tuple
of the input tensors should be provided. It is assumed
that for all given input tensors, dimension 0 corresponds
to the number of examples (aka batch size), and if
multiple input tensors are provided, the examples must
be aligned appropriately.</p></li>
<li><p><span class="target" id="tint.attr.ExtremalMask.attribute.params.baselines"></span><strong>baselines</strong><a class="paramlink headerlink reference internal" href="#tint.attr.ExtremalMask.attribute.params.baselines">¶</a> (<em>scalar</em><em>, </em><em>tensor</em><em>, </em><em>tuple</em><em> of </em><em>scalars</em><em> or </em><em>tensors</em><em>, </em><em>optional</em>) – <p>Baselines define reference value which replaces each
feature when occluded.
Baselines can be provided as:</p>
<ul>
<li><p>a single tensor, if inputs is a single tensor, with
exactly the same dimensions as inputs or
broadcastable to match the dimensions of inputs</p></li>
<li><p>a single scalar, if inputs is a single tensor, which will
be broadcasted for each input value in input tensor.</p></li>
<li><p>a tuple of tensors or scalars, the baseline corresponding
to each tensor in the inputs’ tuple can be:</p>
<ul>
<li><p>either a tensor with matching dimensions to
corresponding tensor in the inputs’ tuple
or the first dimension is one and the remaining
dimensions match with the corresponding
input tensor.</p></li>
<li><p>or a scalar, corresponding to a tensor in the
inputs’ tuple. This scalar value is broadcasted
for corresponding input tensor.</p></li>
</ul>
</li>
</ul>
<p>In the cases when <cite>baselines</cite> is not provided, we internally
use zero scalar corresponding to each input tensor.
Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.ExtremalMask.attribute.params.target"></span><strong>target</strong><a class="paramlink headerlink reference internal" href="#tint.attr.ExtremalMask.attribute.params.target">¶</a> (<em>int</em><em>, </em><em>tuple</em><em>, </em><em>tensor</em><em> or </em><em>list</em><em>, </em><em>optional</em>) – <p>Output indices for
which difference is computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><p>a single integer or a tensor containing a single
integer, which is applied to all input examples</p></li>
<li><p>a list of integers or a 1D tensor, with length matching
the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p></li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><p>A single tuple, which contains #output_dims - 1
elements. This target index is applied to all examples.</p></li>
<li><p>A list of tuples with length equal to the number of
examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p></li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.ExtremalMask.attribute.params.additional_forward_args"></span><strong>additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.ExtremalMask.attribute.params.additional_forward_args">¶</a> (<em>any</em><em>, </em><em>optional</em>) – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a
tuple containing multiple additional arguments including
tensors or any arbitrary python types. These arguments
are provided to forward_func in order following the
arguments in inputs.
For a tensor, the first dimension of the tensor must
correspond to the number of examples. For all other types,
the given argument is used for all forward evaluations.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.ExtremalMask.attribute.params.trainer"></span><strong>trainer</strong><a class="paramlink headerlink reference internal" href="#tint.attr.ExtremalMask.attribute.params.trainer">¶</a> (<em>Trainer</em>) – Pytorch Lightning trainer. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, a
default trainer will be provided.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.ExtremalMask.attribute.params.mask_net"></span><strong>mask_net</strong><a class="paramlink headerlink reference internal" href="#tint.attr.ExtremalMask.attribute.params.mask_net">¶</a> (<em>BayesMaskNet</em>) – A Mask model. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, a default model
will be provided.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.ExtremalMask.attribute.params.batch_size"></span><strong>batch_size</strong><a class="paramlink headerlink reference internal" href="#tint.attr.ExtremalMask.attribute.params.batch_size">¶</a> (<em>int</em>) – Batch size for Mask training.
Default: 32</p></li>
<li><p><span class="target" id="tint.attr.ExtremalMask.attribute.params.temporal_additional_forward_args"></span><strong>temporal_additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.ExtremalMask.attribute.params.temporal_additional_forward_args">¶</a> (<em>tuple</em>) – Set each
additional forward arg which is temporal.
Only used with return_temporal_attributions.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.ExtremalMask.attribute.params.return_temporal_attributions"></span><strong>return_temporal_attributions</strong><a class="paramlink headerlink reference internal" href="#tint.attr.ExtremalMask.attribute.params.return_temporal_attributions">¶</a> (<em>bool</em>) – Whether to return
attributions for all times or not.
Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The attributions with respect to each input feature.
Attributions will always be
the same size as the provided inputs, with each value
providing the attribution of the corresponding input index.
If a single tensor is provided as inputs, a single tensor is
returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><strong>attributions</strong> (<em>tensor</em> or tuple of <em>tensors</em>)</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.FeatureAblation">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">FeatureAblation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/feature_ablation.html#FeatureAblation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.FeatureAblation" title="Permalink to this definition">¶</a></dt>
<dd><p>Feature ablation.</p>
<p>A perturbation based approach to computing attribution, involving
replacing each input feature with a given baseline / reference, and
computing the difference in output. By default, each scalar value within
each input tensor is taken as a feature and replaced independently. Passing
a feature mask, allows grouping features to be ablated together. This can
be used in cases such as images, where an entire segment or region
can be ablated, measuring the importance of the segment (feature group).
Each input scalar in the group will be given the same attribution value
equal to the change in target as a result of ablating the entire feature
group.</p>
<p>The forward function can either return a scalar per example or a tensor
of a fixed sized tensor (or scalar value) for the full batch, i.e. the
output does not grow as the batch size increase. If the output is fixed
we consider this model to be an “aggregation” of the inputs. In the fixed
sized output mode we require <cite>perturbations_per_eval == 1</cite> and the
<cite>feature_mask</cite> to be either <cite>None</cite> or for all of them to have 1 as their
first dimension (i.e. a feature mask requires to be applied to all inputs).</p>
<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.FeatureAblation.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baselines</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_mask</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">perturbations_per_eval</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attributions_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></span><a class="reference internal" href="_modules/tint/attr/feature_ablation.html#FeatureAblation.attribute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.FeatureAblation.attribute" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.FeatureAblation.attribute.params.inputs"></span><strong>inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.FeatureAblation.attribute.params.inputs">¶</a> (<em>tensor</em><em> or </em><em>tuple</em><em> of </em><em>tensors</em>) – Input for which ablation
attributions are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.
If forward_func takes multiple tensors as input, a tuple
of the input tensors should be provided. It is assumed
that for all given input tensors, dimension 0 corresponds
to the number of examples (aka batch size), and if
multiple input tensors are provided, the examples must
be aligned appropriately.</p></li>
<li><p><span class="target" id="tint.attr.FeatureAblation.attribute.params.baselines"></span><strong>baselines</strong><a class="paramlink headerlink reference internal" href="#tint.attr.FeatureAblation.attribute.params.baselines">¶</a> (<em>scalar</em><em>, </em><em>tensor</em><em>, </em><em>tuple</em><em> of </em><em>scalars</em><em> or </em><em>tensors</em><em>, </em><em>optional</em>) – <p>Baselines define reference value which replaces each
feature when ablated.
Baselines can be provided as:</p>
<ul>
<li><p>a single tensor, if inputs is a single tensor, with
exactly the same dimensions as inputs or
broadcastable to match the dimensions of inputs</p></li>
<li><p>a single scalar, if inputs is a single tensor, which will
be broadcasted for each input value in input tensor.</p></li>
<li><p>a tuple of tensors or scalars, the baseline corresponding
to each tensor in the inputs’ tuple can be:</p>
<ul>
<li><p>either a tensor with matching dimensions to
corresponding tensor in the inputs’ tuple
or the first dimension is one and the remaining
dimensions match with the corresponding
input tensor.</p></li>
<li><p>or a scalar, corresponding to a tensor in the
inputs’ tuple. This scalar value is broadcasted
for corresponding input tensor.</p></li>
</ul>
</li>
</ul>
<p>In the cases when <cite>baselines</cite> is not provided, we internally
use zero scalar corresponding to each input tensor.
Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.FeatureAblation.attribute.params.target"></span><strong>target</strong><a class="paramlink headerlink reference internal" href="#tint.attr.FeatureAblation.attribute.params.target">¶</a> (<em>int</em><em>, </em><em>tuple</em><em>, </em><em>tensor</em><em> or </em><em>list</em><em>, </em><em>optional</em>) – <p>Output indices for
which gradients are computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><p>a single integer or a tensor containing a single
integer, which is applied to all input examples</p></li>
<li><p>a list of integers or a 1D tensor, with length matching
the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p></li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><p>A single tuple, which contains #output_dims - 1
elements. This target index is applied to all examples.</p></li>
<li><p>A list of tuples with length equal to the number of
examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p></li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.FeatureAblation.attribute.params.additional_forward_args"></span><strong>additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.FeatureAblation.attribute.params.additional_forward_args">¶</a> (<em>any</em><em>, </em><em>optional</em>) – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a
tuple containing multiple additional arguments including
tensors or any arbitrary python types. These arguments
are provided to forward_func in order following the
arguments in inputs.
For a tensor, the first dimension of the tensor must
correspond to the number of examples. For all other types,
the given argument is used for all forward evaluations.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.FeatureAblation.attribute.params.feature_mask"></span><strong>feature_mask</strong><a class="paramlink headerlink reference internal" href="#tint.attr.FeatureAblation.attribute.params.feature_mask">¶</a> (<em>tensor</em><em> or </em><em>tuple</em><em> of </em><em>tensors</em><em>, </em><em>optional</em>) – feature_mask defines a mask for the input, grouping
features which should be ablated together. feature_mask
should contain the same number of tensors as inputs.
Each tensor should
be the same size as the corresponding input or
broadcastable to match the input tensor. Each tensor
should contain integers in the range 0 to num_features
- 1, and indices corresponding to the same feature should
have the same value.
Note that features within each input tensor are ablated
independently (not across tensors).
If the forward function returns a single scalar per batch,
we enforce that the first dimension of each mask must be 1,
since attributions are returned batch-wise rather than per
example, so the attributions must correspond to the
same features (indices) in each input example.
If None, then a feature mask is constructed which assigns
each scalar within a tensor as a separate feature, which
is ablated independently.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.FeatureAblation.attribute.params.perturbations_per_eval"></span><strong>perturbations_per_eval</strong><a class="paramlink headerlink reference internal" href="#tint.attr.FeatureAblation.attribute.params.perturbations_per_eval">¶</a> (<em>int</em><em>, </em><em>optional</em>) – Allows ablation of multiple
features to be processed simultaneously in one call to
forward_fn.
Each forward pass will contain a maximum of
perturbations_per_eval * #examples samples.
For DataParallel models, each batch is split among the
available devices, so evaluations on each available
device contain at most
(perturbations_per_eval * #examples) / num_devices
samples.
If the forward function’s number of outputs does not
change as the batch size grows (e.g. if it outputs a
scalar value), you must set perturbations_per_eval to 1
and use a single feature mask to describe the features
for all examples in the batch.
Default: 1</p></li>
<li><p><span class="target" id="tint.attr.FeatureAblation.attribute.params.attributions_fn"></span><strong>attributions_fn</strong><a class="paramlink headerlink reference internal" href="#tint.attr.FeatureAblation.attribute.params.attributions_fn">¶</a> (<em>Callable</em><em>, </em><em>optional</em>) – Applies a function to the
attributions before performing the weighted sum.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.FeatureAblation.attribute.params.show_progress"></span><strong>show_progress</strong><a class="paramlink headerlink reference internal" href="#tint.attr.FeatureAblation.attribute.params.show_progress">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – Displays the progress of computation.
It will try to use tqdm if available for advanced features
(e.g. time estimation). Otherwise, it will fallback to
a simple output of progress.
Default: False</p></li>
<li><p><span class="target" id="tint.attr.FeatureAblation.attribute.params.**kwargs"></span><strong>**kwargs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.FeatureAblation.attribute.params.**kwargs">¶</a> (<em>Any</em><em>, </em><em>optional</em>) – Any additional arguments used by child
classes of FeatureAblation (such as Occlusion) to construct
ablations. These arguments are ignored when using
FeatureAblation directly.
Default: None</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><dl class="simple">
<dt><strong>attributions</strong> (<em>tensor</em> or tuple of <em>tensors</em>):</dt><dd><p>The attributions with respect to each input feature.
If the forward function returns
a scalar value per example, attributions will be
the same size as the provided inputs, with each value
providing the attribution of the corresponding input index.
If the forward function returns a scalar per batch, then
attribution tensor(s) will have first dimension 1 and
the remaining dimensions will match the input.
If a single tensor is provided as inputs, a single tensor is
returned. If a tuple of tensors is provided for inputs, a
tuple of corresponding sized tensors is returned.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>tensor</em> or tuple of <em>tensors</em> of <strong>attributions</strong></p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># SimpleClassifier takes a single input tensor of size Nx4x4,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># and returns an Nx3 tensor of class probabilities.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">SimpleClassifier</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Generating random input with size 2 x 4 x 4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Defining FeatureAblation interpreter</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ablator</span> <span class="o">=</span> <span class="n">FeatureAblation</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Computes ablation attribution, ablating each of the 16</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># scalar input independently.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">ablator</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Alternatively, we may want to ablate features in groups, e.g.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># grouping each 2x2 square of the inputs and ablating them together.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># This can be done by creating a feature mask as follows, which</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># defines the feature groups, e.g.:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># +---+---+---+---+</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># | 0 | 0 | 1 | 1 |</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># +---+---+---+---+</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># | 0 | 0 | 1 | 1 |</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># +---+---+---+---+</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># | 2 | 2 | 3 | 3 |</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># +---+---+---+---+</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># | 2 | 2 | 3 | 3 |</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># +---+---+---+---+</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># With this mask, all inputs with the same value are ablated</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># simultaneously, and the attribution for each input in the same</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># group (0, 1, 2, and 3) per example are the same.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The attributions can be calculated as follows:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># feature mask has dimensions 1 x 4 x 4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feature_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                            <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">ablator</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">feature_mask</span><span class="o">=</span><span class="n">feature_mask</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.Fit">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">Fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">generator</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="attr_models.html#tint.attr.models.JointFeatureGeneratorNet" title="tint.attr.models.joint_features_generator.JointFeatureGeneratorNet"><span class="pre">JointFeatureGeneratorNet</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">datamodule</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">LightningDataModule</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Trainer</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">32</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/fit.html#Fit"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.Fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Feature Importance in Time.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.Fit.params.forward_func"></span><strong>forward_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.params.forward_func">¶</a> (<em>callable</em>) – The forward function of the model or any
modification of it.</p></li>
<li><p><span class="target" id="tint.attr.Fit.params.generator"></span><strong>generator</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.params.generator">¶</a> (<a class="reference internal" href="attr_models.html#tint.attr.models.JointFeatureGeneratorNet" title="tint.attr.models.JointFeatureGeneratorNet"><em>JointFeatureGeneratorNet</em></a>) – Conditional generator model to
predict future observations as a Pytorch Lightning module.
If not provided, a default generator is created.
Default to <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><span class="target" id="tint.attr.Fit.params.datamodule"></span><strong>datamodule</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.params.datamodule">¶</a> (<em>LightningDataModule</em>) – A Pytorch Lightning data
module to train the generator. If not provided, you must provide
features. Default to <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><span class="target" id="tint.attr.Fit.params.features"></span><strong>features</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.params.features">¶</a> (<em>th.Tensor</em>) – A tensor of features to train the generator.
If not provided, you must provide a datamodule.
Default to <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><span class="target" id="tint.attr.Fit.params.trainer"></span><strong>trainer</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.params.trainer">¶</a> (<em>Trainer</em>) – A Pytorch Lightning trainer to train the generator.
If not provided, a default trainer is created. Default to <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><span class="target" id="tint.attr.Fit.params.batch_size"></span><strong>batch_size</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.params.batch_size">¶</a> (<em>int</em>) – Batch size for generator training. Default to 32</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://arxiv.org/abs/2003.02821">https://arxiv.org/abs/2003.02821</a></p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">Fit</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.models</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">Fit</span><span class="p">(</span><span class="n">mlp</span><span class="p">,</span> <span class="n">features</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.Fit.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_samples</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">distance_metric</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'kl'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multilabel</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temporal_additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_temporal_attributions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></span><a class="reference internal" href="_modules/tint/attr/fit.html#Fit.attribute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.Fit.attribute" title="Permalink to this definition">¶</a></dt>
<dd><p>attribute method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.Fit.attribute.params.inputs"></span><strong>inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.attribute.params.inputs">¶</a> (<em>tuple</em><em>, </em><em>th.Tensor</em>) – Input data.</p></li>
<li><p><span class="target" id="tint.attr.Fit.attribute.params.additional_forward_args"></span><strong>additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.attribute.params.additional_forward_args">¶</a> (<em>any</em><em>, </em><em>optional</em>) – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. Default to <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><span class="target" id="tint.attr.Fit.attribute.params.n_samples"></span><strong>n_samples</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.attribute.params.n_samples">¶</a> (<em>int</em>) – Number of Monte-Carlo samples. Default to 10</p></li>
<li><p><span class="target" id="tint.attr.Fit.attribute.params.distance_metric"></span><strong>distance_metric</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.attribute.params.distance_metric">¶</a> (<em>str</em>) – Distance metric. Default to <code class="docutils literal notranslate"><span class="pre">'kl'</span></code></p></li>
<li><p><span class="target" id="tint.attr.Fit.attribute.params.multilabel"></span><strong>multilabel</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.attribute.params.multilabel">¶</a> (<em>bool</em>) – Whether the task is single or multi-labeled.
Default to <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><span class="target" id="tint.attr.Fit.attribute.params.temporal_additional_forward_args"></span><strong>temporal_additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.attribute.params.temporal_additional_forward_args">¶</a> (<em>tuple</em>) – Set each
additional forward arg which is temporal.
Only used with return_temporal_attributions.
Default to <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><span class="target" id="tint.attr.Fit.attribute.params.return_temporal_attributions"></span><strong>return_temporal_attributions</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.attribute.params.return_temporal_attributions">¶</a> (<em>bool</em>) – Whether to return
attributions for all times or not. Default to <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><span class="target" id="tint.attr.Fit.attribute.params.show_progress"></span><strong>show_progress</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.attribute.params.show_progress">¶</a> (<em>bool</em>) – Displays the progress of computation.
Default to False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Attributions.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(th.Tensor, tuple)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.Fit.representation">
<span class="sig-name descname"><span class="pre">representation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_samples</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">distance_metric</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'kl'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multilabel</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temporal_additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/fit.html#Fit.representation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.Fit.representation" title="Permalink to this definition">¶</a></dt>
<dd><p>Get representations based on a generator and inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.Fit.representation.params.inputs"></span><strong>inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.representation.params.inputs">¶</a> (<em>th.Tensor</em>) – Input data.</p></li>
<li><p><span class="target" id="tint.attr.Fit.representation.params.additional_forward_args"></span><strong>additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.representation.params.additional_forward_args">¶</a> (<em>Any</em>) – Optional additional args to be
passed into the model. Default to <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><span class="target" id="tint.attr.Fit.representation.params.n_samples"></span><strong>n_samples</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.representation.params.n_samples">¶</a> (<em>int</em>) – Number of Monte-Carlo samples. Default to 10</p></li>
<li><p><span class="target" id="tint.attr.Fit.representation.params.distance_metric"></span><strong>distance_metric</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.representation.params.distance_metric">¶</a> (<em>str</em>) – Distance metric. Default to <code class="docutils literal notranslate"><span class="pre">'kl'</span></code></p></li>
<li><p><span class="target" id="tint.attr.Fit.representation.params.multilabel"></span><strong>multilabel</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.representation.params.multilabel">¶</a> (<em>bool</em>) – Whether the task is single or multi-labeled.
Default to <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><span class="target" id="tint.attr.Fit.representation.params.temporal_additional_forward_args"></span><strong>temporal_additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.representation.params.temporal_additional_forward_args">¶</a> (<em>tuple</em>) – Set each
additional forward arg which is temporal.
Only used with return_temporal_attributions.
Default to <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><span class="target" id="tint.attr.Fit.representation.params.show_progress"></span><strong>show_progress</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.representation.params.show_progress">¶</a> (<em>bool</em>) – Displays the progress of computation.
Default to False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>attributions.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>th.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.GeodesicIntegratedGradients">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">GeodesicIntegratedGradients</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">NearestNeighbors</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">NearestNeighbors</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">TensorOrTupleOfTensorsGeneric</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_neighbors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multiply_by_inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/geodesic_ig.html#GeodesicIntegratedGradients"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.GeodesicIntegratedGradients" title="Permalink to this definition">¶</a></dt>
<dd><p>Geodesic Integrated Gradients.</p>
<p>This method uses K Nearest Neighbors on the input data to approximate the
geodesic path between inputs and reference baselines. The input space is
seen here as a Riemannian manifold, whose metric is the inner product of
the gradient of the model:</p>
<div class="math notranslate nohighlight">
\[&lt;\nabla F(x)^T, \nabla F(x)&gt;\]</div>
<p>Using this path reduces the risk of creating artifacts compared with
the original Integrated Gradients (IG). It also supports
<code class="docutils literal notranslate"><span class="pre">internal_batch_size</span></code> for faster compute. The number of steps is also
set by default to 5, as less steps are required between two neighbors.
With this setting, and the number of neighbors set to 10, the number of
gradients to compute is 10 * 5 = 50, the same number as the original IG.</p>
<p>The shortest path is computed using Dijkstra or A* algorithms. This can
be computationally expensive for a number of inputs greater than a few
thousands.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.GeodesicIntegratedGradients.params.forward_func"></span><strong>forward_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GeodesicIntegratedGradients.params.forward_func">¶</a> (<em>callable</em>) – The forward function of the model or any
modification of it.</p></li>
<li><p><span class="target" id="tint.attr.GeodesicIntegratedGradients.params.nn"></span><strong>nn</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GeodesicIntegratedGradients.params.nn">¶</a> (<em>NearestNeighbors</em><em>, </em><em>tuple</em>) – Nearest neighbors method.
If not provided, will be created when calling __init__ or
attribute.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.GeodesicIntegratedGradients.params.data"></span><strong>data</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GeodesicIntegratedGradients.params.data">¶</a> (<em>Tensor</em><em>, </em><em>tuple</em>) – Data to fit the knn algorithm. If not provided,
the knn will be fitted when calling attribute using the provided
inputs data.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.GeodesicIntegratedGradients.params.n_neighbors"></span><strong>n_neighbors</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GeodesicIntegratedGradients.params.n_neighbors">¶</a> (<em>int</em><em>, </em><em>tuple</em>) – Number of neighbors to use by default.
Can be an integer (same for every inputs) or a tuple.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.GeodesicIntegratedGradients.params.multiply_by_inputs"></span><strong>multiply_by_inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GeodesicIntegratedGradients.params.multiply_by_inputs">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – <p>Indicates whether to factor
model inputs’ multiplier in the final attribution scores.
In the literature this is also known as local vs global
attribution. If inputs’ multiplier isn’t factored in,
then that type of attribution method is also called local
attribution. If it is, then that type of attribution
method is called global.
More detailed can be found here:
<a class="reference external" href="https://arxiv.org/abs/1711.06104">https://arxiv.org/abs/1711.06104</a></p>
<p>In case of integrated gradients, if <cite>multiply_by_inputs</cite>
is set to True, final sensitivity scores are being multiplied by
(inputs - baselines).</p>
</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">GeodesicIntegratedGradients</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.models</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">GeodesicIntegratedGradients</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">mlp</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.GeodesicIntegratedGradients.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baselines</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">BaselineType</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TargetType</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_neighbors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_steiner</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'gausslegendre'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">internal_batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_curvature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_convergence_delta</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">distance</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'geodesic'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></span><a class="reference internal" href="_modules/tint/attr/geodesic_ig.html#GeodesicIntegratedGradients.attribute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.GeodesicIntegratedGradients.attribute" title="Permalink to this definition">¶</a></dt>
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baselines</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">BaselineType</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TargetType</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_neighbors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_steiner</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'gausslegendre'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">internal_batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_curvature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_convergence_delta</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">distance</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'geodesic'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">TensorOrTupleOfTensorsGeneric</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span></dt>
<dd><p>This method attributes the output of the model with given target index
(in case it is provided, otherwise it assumes that output is a
scalar) to the inputs of the model using the approach described above.</p>
<p>In addition to that it also returns, if <cite>return_convergence_delta</cite> is
set to True, integral approximation delta based on the completeness
property of integrated gradients.</p>
<p>It also returns the curvature if <cite>return_curvature</cite> is set to True.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.GeodesicIntegratedGradients.attribute.params.inputs"></span><strong>inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GeodesicIntegratedGradients.attribute.params.inputs">¶</a> (<em>tensor</em><em> or </em><em>tuple</em><em> of </em><em>tensors</em>) – Input for which integrated
gradients are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.
If forward_func takes multiple tensors as input, a tuple
of the input tensors should be provided. It is assumed
that for all given input tensors, dimension 0 corresponds
to the number of examples, and if multiple input tensors
are provided, the examples must be aligned appropriately.</p></li>
<li><p><span class="target" id="tint.attr.GeodesicIntegratedGradients.attribute.params.baselines"></span><strong>baselines</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GeodesicIntegratedGradients.attribute.params.baselines">¶</a> (<em>scalar</em><em>, </em><em>tensor</em><em>, </em><em>tuple</em><em> of </em><em>scalars</em><em> or </em><em>tensors</em><em>, </em><em>optional</em>) – <p>Baselines define the starting point from which integral
is computed and can be provided as:</p>
<ul>
<li><p>a single tensor, if inputs is a single tensor, with
exactly the same dimensions as inputs or the first
dimension is one and the remaining dimensions match
with inputs.</p></li>
<li><p>a single scalar, if inputs is a single tensor, which will
be broadcasted for each input value in input tensor.</p></li>
<li><p>a tuple of tensors or scalars, the baseline corresponding
to each tensor in the inputs’ tuple can be:</p>
<ul>
<li><p>either a tensor with matching dimensions to
corresponding tensor in the inputs’ tuple
or the first dimension is one and the remaining
dimensions match with the corresponding
input tensor.</p></li>
<li><p>or a scalar, corresponding to a tensor in the
inputs’ tuple. This scalar value is broadcasted
for corresponding input tensor.</p></li>
</ul>
</li>
</ul>
<p>In the cases when <cite>baselines</cite> is not provided, we internally
use zero scalar corresponding to each input tensor.</p>
<p>Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.GeodesicIntegratedGradients.attribute.params.target"></span><strong>target</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GeodesicIntegratedGradients.attribute.params.target">¶</a> (<em>int</em><em>, </em><em>tuple</em><em>, </em><em>tensor</em><em> or </em><em>list</em><em>, </em><em>optional</em>) – <p>Output indices for
which gradients are computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><p>a single integer or a tensor containing a single
integer, which is applied to all input examples</p></li>
<li><p>a list of integers or a 1D tensor, with length matching
the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p></li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><p>A single tuple, which contains #output_dims - 1
elements. This target index is applied to all examples.</p></li>
<li><p>A list of tuples with length equal to the number of
examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p></li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.GeodesicIntegratedGradients.attribute.params.additional_forward_args"></span><strong>additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GeodesicIntegratedGradients.attribute.params.additional_forward_args">¶</a> (<em>any</em><em>, </em><em>optional</em>) – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a
tuple containing multiple additional arguments including
tensors or any arbitrary python types. These arguments
are provided to forward_func in order following the
arguments in inputs.
For a tensor, the first dimension of the tensor must
correspond to the number of examples. It will be
repeated for each of <cite>n_steps</cite> along the integrated
path. For all other types, the given argument is used
for all forward evaluations.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.GeodesicIntegratedGradients.attribute.params.n_neighbors"></span><strong>n_neighbors</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GeodesicIntegratedGradients.attribute.params.n_neighbors">¶</a> (<em>int</em><em>, </em><em>optional</em>) – Number of neighbors to use by default.
Must be provided if it has not been set in the init.
Can be an integer (same for every inputs) or a tuple.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.GeodesicIntegratedGradients.attribute.params.n_steps"></span><strong>n_steps</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GeodesicIntegratedGradients.attribute.params.n_steps">¶</a> (<em>int</em><em>, </em><em>optional</em>) – The number of steps used by the approximation
method. Default: 5.</p></li>
<li><p><span class="target" id="tint.attr.GeodesicIntegratedGradients.attribute.params.n_steiner"></span><strong>n_steiner</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GeodesicIntegratedGradients.attribute.params.n_steiner">¶</a> (<em>int</em><em>, </em><em>optional</em>) – Add a certain number of steiner points
into the graph. These points are added following the fixed
scheme. For more information, please refer to the section 4.1.3
of <a class="reference external" href="https://arxiv.org/pdf/2007.10430">https://arxiv.org/pdf/2007.10430</a>.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.GeodesicIntegratedGradients.attribute.params.method"></span><strong>method</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GeodesicIntegratedGradients.attribute.params.method">¶</a> (<em>string</em><em>, </em><em>optional</em>) – Method for approximating the integral,
one of <cite>riemann_right</cite>, <cite>riemann_left</cite>, <cite>riemann_middle</cite>,
<cite>riemann_trapezoid</cite> or <cite>gausslegendre</cite>.
Default: <cite>gausslegendre</cite> if no method is provided.</p></li>
<li><p><span class="target" id="tint.attr.GeodesicIntegratedGradients.attribute.params.internal_batch_size"></span><strong>internal_batch_size</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GeodesicIntegratedGradients.attribute.params.internal_batch_size">¶</a> (<em>int</em><em>, </em><em>optional</em>) – Divides total #steps * #examples
data points into chunks of size at most internal_batch_size,
which are computed (forward / backward passes)
sequentially. internal_batch_size must be at least equal to
#examples.
For DataParallel models, each batch is split among the
available devices, so evaluations on each available
device contain internal_batch_size / num_devices examples.
If internal_batch_size is None, then all evaluations are
processed in one batch.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.GeodesicIntegratedGradients.attribute.params.return_curvature"></span><strong>return_curvature</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GeodesicIntegratedGradients.attribute.params.return_curvature">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – Indicates whether to return
the curvature or not. If <cite>return_curvature</cite>
is set to True curvature will be returned in a tuple following
attributions and optionally convergence delta.
Default: False</p></li>
<li><p><span class="target" id="tint.attr.GeodesicIntegratedGradients.attribute.params.return_convergence_delta"></span><strong>return_convergence_delta</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GeodesicIntegratedGradients.attribute.params.return_convergence_delta">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – Indicates whether to return
convergence delta or not. If <cite>return_convergence_delta</cite>
is set to True convergence delta will be returned in
a tuple following attributions.
Default: False</p></li>
<li><p><span class="target" id="tint.attr.GeodesicIntegratedGradients.attribute.params.distance"></span><strong>distance</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GeodesicIntegratedGradients.attribute.params.distance">¶</a> (<em>str</em><em>, </em><em>optional</em>) – <p>Which distance to use with the A*
algorithm:</p>
<ul>
<li><p>’geodesic’: the geodesic distance using the gradients norms.</p></li>
<li><p>’euclidean’: using the plain euclidean distance between
points. This method amounts to the one described here:
<a class="reference external" href="https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02055-7">https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02055-7</a></p></li>
</ul>
<p>Default: ‘geodesic’</p>
</p></li>
<li><p><span class="target" id="tint.attr.GeodesicIntegratedGradients.attribute.params.show_progress"></span><strong>show_progress</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GeodesicIntegratedGradients.attribute.params.show_progress">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – Displays the progress of computation.
It will try to use tqdm if available for advanced features
(e.g. time estimation). Otherwise, it will fallback to
a simple output of progress.
Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul>
<li><dl class="simple">
<dt><strong>attributions</strong> (<em>tensor</em> or tuple of <em>tensors</em>):</dt><dd><p>Integrated gradients with respect to each input feature.
attributions will always be the same size as the provided
inputs, with each value providing the attribution of the
corresponding input index.
If a single tensor is provided as inputs, a single tensor is
returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>delta</strong> (<em>tensor</em>, returned if return_convergence_delta=True):</dt><dd><p>The difference between the total approximated and true
integrated gradients. This is computed using the property
that the total sum of forward_func(inputs) -
forward_func(baselines) must equal the total sum of the
integrated gradient.
Delta is calculated per example, meaning that the number of
elements in returned delta tensor is equal to the number of
examples in inputs.</p>
</dd>
</dl>
</li>
<li><dl>
<dt><strong>curvature</strong> (<em>tensor</em>, returned if return_curvature=True):</dt><dd><p>The difference between the distance along the path computed
by the A* algorithm and the euclidean distance between
inputs and baselines. This value, always positive,
returns a measure of the curvature of the input space, with
the inner product of the gradient of the model:</p>
<div class="math notranslate nohighlight">
\[&lt;\nabla F(x)^T, \nabla F(x)&gt;\]</div>
<p>as a metric. A higher value indicates a higher curvature.
This value however depends on the path and is as such only
an indication of the true curvature of the input space.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>attributions</strong> or 2-element tuple of <strong>attributions</strong>, <strong>delta</strong></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.GeodesicIntegratedGradients.compute_curvature">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">compute_curvature</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baselines</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">knns</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grads_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">paths_len</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/tint/attr/geodesic_ig.html#GeodesicIntegratedGradients.compute_curvature"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.GeodesicIntegratedGradients.compute_curvature" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the curvature of the input space, as the difference between
the euclidean distance along the path computed by the A* algorithm
and the euclidean distance between the inputs and baseline.
The curvature is always positive.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.GeodesicIntegratedGradients.has_convergence_delta">
<span class="sig-name descname"><span class="pre">has_convergence_delta</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="reference internal" href="_modules/tint/attr/geodesic_ig.html#GeodesicIntegratedGradients.has_convergence_delta"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.GeodesicIntegratedGradients.has_convergence_delta" title="Permalink to this definition">¶</a></dt>
<dd><p>This method informs the user whether the attribution algorithm provides
a convergence delta (aka an approximation error) or not. Convergence
delta may serve as a proxy of correctness of attribution algorithm’s
approximation. If deriving attribution class provides a
<cite>compute_convergence_delta</cite> method, it should
override both <cite>compute_convergence_delta</cite> and <cite>has_convergence_delta</cite> methods.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Returns whether the attribution algorithm
provides a convergence delta (aka approximation error) or not.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.LofKernelShap">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">LofKernelShap</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_neighbors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/lof.html#LofKernelShap"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.LofKernelShap" title="Permalink to this definition">¶</a></dt>
<dd><p>Local Outlier Factor Kernel Shap.</p>
<p>This method compute a Local Outlier Factor score for every perturbed data.
This score is then used to update the weight given by the similarity
function:</p>
<div class="math notranslate nohighlight">
\[new_weight(x) = similarity(x) * \frac{-1}{lof_score(x)}\]</div>
<p>If the perturbed data is considered more out of sample, the weight of
this data will be reduced.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.LofKernelShap.params.forward_func"></span><strong>forward_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.LofKernelShap.params.forward_func">¶</a> (<em>Callable</em>) – The forward function of the model or any
modification of it.</p></li>
<li><p><span class="target" id="tint.attr.LofKernelShap.params.embeddings"></span><strong>embeddings</strong><a class="paramlink headerlink reference internal" href="#tint.attr.LofKernelShap.params.embeddings">¶</a> (<em>Tensor</em>) – Tensor of embeddings to compute the LOF.</p></li>
<li><p><span class="target" id="tint.attr.LofKernelShap.params.n_neighbors"></span><strong>n_neighbors</strong><a class="paramlink headerlink reference internal" href="#tint.attr.LofKernelShap.params.n_neighbors">¶</a> (<em>int</em>) – Number of neighbors to use by default.
Default to 20</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">LofKernelShap</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.models</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">LofKernelShap</span><span class="p">(</span><span class="n">mlp</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.LofLime">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">LofLime</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_neighbors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">interpretable_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Model</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">similarity_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Callable</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">perturb_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Callable</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/lof.html#LofLime"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.LofLime" title="Permalink to this definition">¶</a></dt>
<dd><p>Local Outlier Factor Lime.</p>
<p>This method compute a Local Outlier Factor score for every perturbed data.
This score is then used to update the weight given by the similarity
function:</p>
<div class="math notranslate nohighlight">
\[new_weight(x) = similarity(x) * \frac{-1}{lof_score(x)}\]</div>
<p>If the perturbed data is considered more out of sample, the weight of
this data will be reduced.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.LofLime.params.forward_func"></span><strong>forward_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.LofLime.params.forward_func">¶</a> (<em>Callable</em>) – The forward function of the model or any
modification of it.</p></li>
<li><p><span class="target" id="tint.attr.LofLime.params.embeddings"></span><strong>embeddings</strong><a class="paramlink headerlink reference internal" href="#tint.attr.LofLime.params.embeddings">¶</a> (<em>Tensor</em>) – Tensor of embeddings to compute the LOF.</p></li>
<li><p><span class="target" id="tint.attr.LofLime.params.n_neighbors"></span><strong>n_neighbors</strong><a class="paramlink headerlink reference internal" href="#tint.attr.LofLime.params.n_neighbors">¶</a> (<em>int</em>) – Number of neighbors to use by default.
Default to 20</p></li>
<li><p><span class="target" id="tint.attr.LofLime.params.interpretable_model"></span><strong>interpretable_model</strong><a class="paramlink headerlink reference internal" href="#tint.attr.LofLime.params.interpretable_model">¶</a> (<em>optional</em><em>, </em><em>Model</em>) – <p>Model object to train
interpretable model.</p>
<p>This argument is optional and defaults to SkLearnLasso(alpha=0.01),
which is a wrapper around the Lasso linear model in SkLearn.
This requires having sklearn version &gt;= 0.23 available.</p>
<p>Other predefined interpretable linear models are provided in
captum._utils.models.linear_model.</p>
<p>Alternatively, a custom model object must provide a <cite>fit</cite> method to
train the model, given a dataloader, with batches containing
three tensors:</p>
<ul>
<li><p>interpretable_inputs: Tensor
[2D num_samples x num_interp_features],</p></li>
<li><p>expected_outputs: Tensor [1D num_samples],</p></li>
<li><p>weights: Tensor [1D num_samples]</p></li>
</ul>
<p>The model object must also provide a <cite>representation</cite> method to
access the appropriate coefficients or representation of the
interpretable model after fitting.</p>
<p>Note that calling fit multiple times should retrain the
interpretable model, each attribution call reuses
the same given interpretable model object.</p>
</p></li>
<li><p><span class="target" id="tint.attr.LofLime.params.similarity_func"></span><strong>similarity_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.LofLime.params.similarity_func">¶</a> (<em>optional</em><em>, </em><em>callable</em>) – <p>Function which takes a single sample
along with its corresponding interpretable representation
and returns the weight of the interpretable sample for
training the interpretable model.
This is often referred to as a similarity kernel.</p>
<p>This argument is optional and defaults to a function which
applies an exponential kernel to the consine distance between
the original input and perturbed input, with a kernel width
of 1.0.</p>
<p>A similarity function applying an exponential
kernel to cosine / euclidean distances can be constructed
using the provided get_exp_kernel_similarity_function in
captum.attr._core.lime.</p>
<p>Alternately, a custom callable can also be provided.
The expected signature of this callable is:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">similarity_func</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="n">original_input</span><span class="p">:</span> <span class="n">Tensor</span> <span class="ow">or</span> <span class="nb">tuple</span> <span class="n">of</span> <span class="n">Tensors</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="n">perturbed_input</span><span class="p">:</span> <span class="n">Tensor</span> <span class="ow">or</span> <span class="nb">tuple</span> <span class="n">of</span> <span class="n">Tensors</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="n">perturbed_interpretable_input</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>       <span class="n">Tensor</span> <span class="p">[</span><span class="mi">2</span><span class="n">D</span> <span class="mi">1</span> <span class="n">x</span> <span class="n">num_interp_features</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span> <span class="ow">or</span> <span class="n">Tensor</span> <span class="n">containing</span> <span class="nb">float</span> <span class="n">scalar</span>
</pre></div>
</div>
<p>perturbed_input and original_input will be the same type and
contain tensors of the same shape, with original_input
being the same as the input provided when calling attribute.</p>
<p>kwargs includes baselines, feature_mask, num_interp_features
(integer, determined from feature mask).</p>
</p></li>
<li><p><span class="target" id="tint.attr.LofLime.params.perturb_func"></span><strong>perturb_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.LofLime.params.perturb_func">¶</a> (<em>optional</em><em>, </em><em>callable</em>) – <p>Function which returns a single
sampled input, which is a binary vector of length
num_interp_features, or a generator of such tensors.</p>
<p>This function is optional, the default function returns
a binary vector where each element is selected
independently and uniformly at random. Custom
logic for selecting sampled binary vectors can
be implemented by providing a function with the
following expected signature:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">perturb_func</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="n">original_input</span><span class="p">:</span> <span class="n">Tensor</span> <span class="ow">or</span> <span class="nb">tuple</span> <span class="n">of</span> <span class="n">Tensors</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span> <span class="p">[</span><span class="n">Binary</span> <span class="mi">2</span><span class="n">D</span> <span class="n">Tensor</span> <span class="mi">1</span> <span class="n">x</span> <span class="n">num_interp_features</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span> <span class="ow">or</span> <span class="n">generator</span> <span class="n">yielding</span> <span class="n">such</span> <span class="n">tensors</span>
</pre></div>
</div>
<p>kwargs includes baselines, feature_mask, num_interp_features
(integer, determined from feature mask).</p>
</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">LofLime</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.models</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">LofLime</span><span class="p">(</span><span class="n">mlp</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.NonLinearitiesTunnel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">NonLinearitiesTunnel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">attribution_method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Attribution</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/non_linearities_tunnel.html#NonLinearitiesTunnel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.NonLinearitiesTunnel" title="Permalink to this definition">¶</a></dt>
<dd><p>Replace non linearities (or any module) with others before running
an attribution method. This tunnel is originally intended to
replace ReLU activations with Softplus to smooth the explanations.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This method will break if the forward_func contains functional
non linearities with additional arguments that need to be replaced.
For instance, replacing <code class="docutils literal notranslate"><span class="pre">F.softmax(x,</span> <span class="pre">dim=-1)</span></code> is not possible due
to the presence of the extra argument <code class="docutils literal notranslate"><span class="pre">dim</span></code>.</p>
</div>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>In order to replace any layer, a nn.Module must be passed as
forward_func. In particular, passing <code class="docutils literal notranslate"><span class="pre">model.forward</span></code> will result
in not replacing any layer in <code class="docutils literal notranslate"><span class="pre">model</span></code>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="target" id="tint.attr.NonLinearitiesTunnel.params.attribution_method"></span><strong>attribution_method</strong><a class="paramlink headerlink reference internal" href="#tint.attr.NonLinearitiesTunnel.params.attribution_method">¶</a> (<em>Attribution</em>) – An instance of any attribution
algorithm of type <cite>Attribution</cite>. E.g. Integrated Gradients,
Conductance or Saliency.</p>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://arxiv.org/abs/1906.07983">https://arxiv.org/abs/1906.07983</a></p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">captum.attr</span> <span class="kn">import</span> <span class="n">Saliency</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">NonLinearitiesTunnel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.models</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">NonLinearitiesTunnel</span><span class="p">(</span><span class="n">Saliency</span><span class="p">(</span><span class="n">mlp</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.NonLinearitiesTunnel.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">to_replace</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Module</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Module</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">ReLU()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replace_with</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Module</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Module</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">Softplus(beta=1,</span> <span class="pre">threshold=20)</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/tint/attr/non_linearities_tunnel.html#NonLinearitiesTunnel.attribute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.NonLinearitiesTunnel.attribute" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.NonLinearitiesTunnel.attribute.params.inputs"></span><strong>inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.NonLinearitiesTunnel.attribute.params.inputs">¶</a> (<em>tensor</em><em> or </em><em>tuple</em><em> of </em><em>tensors</em>) – Input for which integrated
gradients are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.
If forward_func takes multiple tensors as input, a tuple
of the input tensors should be provided. It is assumed
that for all given input tensors, dimension 0 corresponds
to the number of examples, and if multiple input tensors
are provided, the examples must be aligned appropriately.
It is also assumed that for all given input tensors,
dimension 1 corresponds to the time dimension, and if
multiple input tensors are provided, the examples must
be aligned appropriately.</p></li>
<li><p><span class="target" id="tint.attr.NonLinearitiesTunnel.attribute.params.to_replace"></span><strong>to_replace</strong><a class="paramlink headerlink reference internal" href="#tint.attr.NonLinearitiesTunnel.attribute.params.to_replace">¶</a> (<em>nn.Module</em><em>, </em><em>tuple</em><em>, </em><em>optional</em>) – Non linearities
to be  replaced. The linearities of type listed here will be
replaced by <code class="docutils literal notranslate"><span class="pre">replaced_by</span></code> non linearities before running
the attribution method. This can be an instance or a class.
If a class is passed, default attributes are used.
Default: nn.ReLU()</p></li>
<li><p><span class="target" id="tint.attr.NonLinearitiesTunnel.attribute.params.replace_with"></span><strong>replace_with</strong><a class="paramlink headerlink reference internal" href="#tint.attr.NonLinearitiesTunnel.attribute.params.replace_with">¶</a> (<em>nn.Module</em><em>, </em><em>tuple</em><em>, </em><em>optional</em>) – Non linearities
to replace the ones listed in <code class="docutils literal notranslate"><span class="pre">to_replace</span></code>.
Default: nn.Softplus()</p></li>
<li><p><span class="target" id="tint.attr.NonLinearitiesTunnel.attribute.params.**kwargs"></span><strong>**kwargs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.NonLinearitiesTunnel.attribute.params.**kwargs">¶</a> – (Any, optional): Contains a list of arguments that are
passed  to <cite>attribution_method</cite> attribution algorithm.
Any additional arguments that should be used for the
chosen attribution method should be included here.
For instance, such arguments include
<cite>additional_forward_args</cite> and <cite>baselines</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><dl class="simple">
<dt><strong>attributions</strong> (<em>tensor</em> or tuple of <em>tensors</em>):</dt><dd><p>Attribution with
respect to each input feature. attributions will always be
the same size as the provided inputs, with each value
providing the attribution of the corresponding input index.
If a single tensor is provided as inputs, a single tensor
is returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>delta</strong> (<em>float</em>, returned if return_convergence_delta=True):</dt><dd><p>Approximation error computed by the
attribution algorithm. Not all attribution algorithms
return delta value. It is computed only for some
algorithms, e.g. integrated gradients.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>attributions</strong> or 2-element tuple of <strong>attributions</strong>, <strong>delta</strong></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.NonLinearitiesTunnel.has_convergence_delta">
<span class="sig-name descname"><span class="pre">has_convergence_delta</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="reference internal" href="_modules/tint/attr/non_linearities_tunnel.html#NonLinearitiesTunnel.has_convergence_delta"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.NonLinearitiesTunnel.has_convergence_delta" title="Permalink to this definition">¶</a></dt>
<dd><p>This method informs the user whether the attribution algorithm provides
a convergence delta (aka an approximation error) or not. Convergence
delta may serve as a proxy of correctness of attribution algorithm’s
approximation. If deriving attribution class provides a
<cite>compute_convergence_delta</cite> method, it should
override both <cite>compute_convergence_delta</cite> and <cite>has_convergence_delta</cite> methods.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Returns whether the attribution algorithm
provides a convergence delta (aka approximation error) or not.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.Occlusion">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">Occlusion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/occlusion.html#Occlusion"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.Occlusion" title="Permalink to this definition">¶</a></dt>
<dd><p>A perturbation based approach to compute attribution, involving
replacing each contiguous rectangular region with a given baseline /
reference, and computing the difference in output. For features located
in multiple regions (hyperrectangles), the corresponding output differences
are averaged to compute the attribution for that feature.</p>
<p>The first patch is applied with the corner aligned with all indices 0,
and strides are applied until the entire dimension range is covered. Note
that this may cause the final patch applied in a direction to be cut-off
and thus smaller than the target occlusion shape.</p>
<p>More details regarding the occlusion (or grey-box / sliding window)
method can be found in the original paper and in the DeepExplain
implementation.
<a class="reference external" href="https://arxiv.org/abs/1311.2901">https://arxiv.org/abs/1311.2901</a>
<a class="reference external" href="https://github.com/marcoancona/DeepExplain/blob/master/deepexplain">https://github.com/marcoancona/DeepExplain/blob/master/deepexplain</a>/tensorflow/methods.py#L401</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="target" id="tint.attr.Occlusion.params.forward_func"></span><strong>forward_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Occlusion.params.forward_func">¶</a> (<em>Callable</em>) – The forward function of the model or any
modification of it.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">Occlusion</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.models</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">Occlusion</span><span class="p">(</span><span class="n">mlp</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.Occlusion.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sliding_window_shapes</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baselines</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">perturbations_per_eval</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attributions_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></span><a class="reference internal" href="_modules/tint/attr/occlusion.html#Occlusion.attribute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.Occlusion.attribute" title="Permalink to this definition">¶</a></dt>
<dd><p>Attribute method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.Occlusion.attribute.params.inputs"></span><strong>inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Occlusion.attribute.params.inputs">¶</a> (<em>tensor</em><em> or </em><em>tuple</em><em> of </em><em>tensors</em>) – Input for which occlusion
attributions are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.
If forward_func takes multiple tensors as input, a tuple
of the input tensors should be provided. It is assumed
that for all given input tensors, dimension 0 corresponds
to the number of examples (aka batch size), and if
multiple input tensors are provided, the examples must
be aligned appropriately.</p></li>
<li><p><span class="target" id="tint.attr.Occlusion.attribute.params.sliding_window_shapes"></span><strong>sliding_window_shapes</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Occlusion.attribute.params.sliding_window_shapes">¶</a> (<em>tuple</em><em> or </em><em>tuple</em><em> of </em><em>tuples</em>) – Shape of patch
(hyperrectangle) to occlude each input. For a single
input tensor, this must be a tuple of length equal to the
number of dimensions of the input tensor - 1, defining
the dimensions of the patch. If the input tensor is 1-d,
this should be an empty tuple. For multiple input tensors,
this must be a tuple containing one tuple for each input
tensor defining the dimensions of the patch for that
input tensor, as described for the single tensor case.</p></li>
<li><p><span class="target" id="tint.attr.Occlusion.attribute.params.strides"></span><strong>strides</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Occlusion.attribute.params.strides">¶</a> (<em>int</em><em> or </em><em>tuple</em><em> or </em><em>tuple</em><em> of </em><em>ints</em><em> or </em><em>tuple</em><em> of </em><em>tuples</em><em>, </em><em>optional</em>) – This defines the step by which the occlusion hyperrectangle
should be shifted by in each direction for each iteration.
For a single tensor input, this can be either a single
integer, which is used as the step size in each direction,
or a tuple of integers matching the number of dimensions
in the occlusion shape, defining the step size in the
corresponding dimension. For multiple tensor inputs, this
can be either a tuple of integers, one for each input
tensor (used for all dimensions of the corresponding
tensor), or a tuple of tuples, providing the stride per
dimension for each tensor.
To ensure that all inputs are covered by at least one
sliding window, the stride for any dimension must be
&lt;= the corresponding sliding window dimension if the
sliding window dimension is less than the input
dimension.
If None is provided, a stride of 1 is used for each
dimension of each input tensor.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.Occlusion.attribute.params.baselines"></span><strong>baselines</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Occlusion.attribute.params.baselines">¶</a> (<em>scalar</em><em>, </em><em>tensor</em><em>, </em><em>tuple</em><em> of </em><em>scalars</em><em> or </em><em>tensors</em><em>, </em><em>optional</em>) – <p>Baselines define reference value which replaces each
feature when occluded.
Baselines can be provided as:</p>
<ul>
<li><p>a single tensor, if inputs is a single tensor, with
exactly the same dimensions as inputs or
broadcastable to match the dimensions of inputs</p></li>
<li><p>a single scalar, if inputs is a single tensor, which will
be broadcasted for each input value in input tensor.</p></li>
<li><p>a tuple of tensors or scalars, the baseline corresponding
to each tensor in the inputs’ tuple can be:</p>
<ul>
<li><p>either a tensor with matching dimensions to
corresponding tensor in the inputs’ tuple
or the first dimension is one and the remaining
dimensions match with the corresponding
input tensor.</p></li>
<li><p>or a scalar, corresponding to a tensor in the
inputs’ tuple. This scalar value is broadcasted
for corresponding input tensor.</p></li>
</ul>
</li>
</ul>
<p>In the cases when <cite>baselines</cite> is not provided, we internally
use zero scalar corresponding to each input tensor.
Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.Occlusion.attribute.params.target"></span><strong>target</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Occlusion.attribute.params.target">¶</a> (<em>int</em><em>, </em><em>tuple</em><em>, </em><em>tensor</em><em> or </em><em>list</em><em>, </em><em>optional</em>) – <p>Output indices for
which difference is computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><p>a single integer or a tensor containing a single
integer, which is applied to all input examples</p></li>
<li><p>a list of integers or a 1D tensor, with length matching
the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p></li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><p>A single tuple, which contains #output_dims - 1
elements. This target index is applied to all examples.</p></li>
<li><p>A list of tuples with length equal to the number of
examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p></li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.Occlusion.attribute.params.additional_forward_args"></span><strong>additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Occlusion.attribute.params.additional_forward_args">¶</a> (<em>any</em><em>, </em><em>optional</em>) – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a
tuple containing multiple additional arguments including
tensors or any arbitrary python types. These arguments
are provided to forward_func in order following the
arguments in inputs.
For a tensor, the first dimension of the tensor must
correspond to the number of examples. For all other types,
the given argument is used for all forward evaluations.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.Occlusion.attribute.params.perturbations_per_eval"></span><strong>perturbations_per_eval</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Occlusion.attribute.params.perturbations_per_eval">¶</a> (<em>int</em><em>, </em><em>optional</em>) – Allows multiple occlusions
to be included in one batch (one call to forward_fn).
By default, perturbations_per_eval is 1, so each occlusion
is processed individually.
Each forward pass will contain a maximum of
perturbations_per_eval * #examples samples.
For DataParallel models, each batch is split among the
available devices, so evaluations on each available
device contain at most
(perturbations_per_eval * #examples) / num_devices
samples.
Default: 1</p></li>
<li><p><span class="target" id="tint.attr.Occlusion.attribute.params.attributions_fn"></span><strong>attributions_fn</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Occlusion.attribute.params.attributions_fn">¶</a> (<em>Callable</em><em>, </em><em>optional</em>) – Applies a function to the
attributions before performing the weighted sum.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.Occlusion.attribute.params.show_progress"></span><strong>show_progress</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Occlusion.attribute.params.show_progress">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – Displays the progress of computation.
It will try to use tqdm if available for advanced features
(e.g. time estimation). Otherwise, it will fallback to
a simple output of progress.
Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><dl class="simple">
<dt><strong>attributions</strong> (<em>tensor</em> or tuple of <em>tensors</em>):</dt><dd><p>The attributions with respect to each input feature.
Attributions will always be
the same size as the provided inputs, with each value
providing the attribution of the corresponding input index.
If a single tensor is provided as inputs, a single tensor is
returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>tensor</em> or tuple of <em>tensors</em> of <strong>attributions</strong></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># SimpleClassifier takes a single input tensor of size Nx4x4,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># and returns an Nx3 tensor of class probabilities.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">SimpleClassifier</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Generating random input with size 2 x 4 x 4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Defining Occlusion interpreter</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ablator</span> <span class="o">=</span> <span class="n">Occlusion</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Computes occlusion attribution, ablating each 3x3 patch,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># shifting in each direction by the default of 1.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">ablator</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">sliding_window_shapes</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.Retain">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">Retain</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Callable</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retain</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="attr_models.html#tint.attr.models.RetainNet" title="tint.attr.models.retain.RetainNet"><span class="pre">RetainNet</span></a><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">datamodule</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">LightningDataModule</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Trainer</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">32</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/retain.html#Retain"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.Retain" title="Permalink to this definition">¶</a></dt>
<dd><p>Retain explainer method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.Retain.params.forward_func"></span><strong>forward_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Retain.params.forward_func">¶</a> (<em>Callable</em>) – The forward function of the model or any
modification of it.</p></li>
<li><p><span class="target" id="tint.attr.Retain.params.retain"></span><strong>retain</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Retain.params.retain">¶</a> (<a class="reference internal" href="attr_models.html#tint.attr.models.RetainNet" title="tint.attr.models.RetainNet"><em>RetainNet</em></a>) – A Retain network as a Pytorch Lightning
module. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, a default Retain Net will be created.
Default to <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><span class="target" id="tint.attr.Retain.params.datamodule"></span><strong>datamodule</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Retain.params.datamodule">¶</a> (<em>LightningDataModule</em>) – A Pytorch Lightning data
module which will be used to train the RetainNet.
Either a datamodule or features must be provided, they cannot be
None together. Default to <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><span class="target" id="tint.attr.Retain.params.features"></span><strong>features</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Retain.params.features">¶</a> (<em>Tensor</em>) – A tensor of features which will be used to train
the RetainNet. Either a datamodule or features must be provided,
they cannot be None together. If both are provided, features is
ignored. Default to <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://arxiv.org/pdf/1608.05745">https://arxiv.org/pdf/1608.05745</a></p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">Retain</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">Retain</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">th</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">))))</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.Retain.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_temporal_attributions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></span><a class="reference internal" href="_modules/tint/attr/retain.html#Retain.attribute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.Retain.attribute" title="Permalink to this definition">¶</a></dt>
<dd><p>attribute method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.Retain.attribute.params.inputs"></span><strong>inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Retain.attribute.params.inputs">¶</a> (<em>tuple</em><em>, </em><em>th.Tensor</em>) – Input data.</p></li>
<li><p><span class="target" id="tint.attr.Retain.attribute.params.target"></span><strong>target</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Retain.attribute.params.target">¶</a> (<em>int</em><em>, </em><em>tuple</em><em>, </em><em>tensor</em><em>, </em><em>list</em>) – Output indices. Default to
<code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><span class="target" id="tint.attr.Retain.attribute.params.return_temporal_attributions"></span><strong>return_temporal_attributions</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Retain.attribute.params.return_temporal_attributions">¶</a> (<em>bool</em>) – Whether to return
attributions for all times or not. Default to <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Attributions.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>(th.Tensor, tuple)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.Retain.representation">
<span class="sig-name descname"><span class="pre">representation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/retain.html#Retain.representation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.Retain.representation" title="Permalink to this definition">¶</a></dt>
<dd><p>Get representations based on a model, inputs and potentially targets.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.Retain.representation.params.inputs"></span><strong>inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Retain.representation.params.inputs">¶</a> (<em>th.Tensor</em>) – Input data.</p></li>
<li><p><span class="target" id="tint.attr.Retain.representation.params.target"></span><strong>target</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Retain.representation.params.target">¶</a> (<em>th.Tensor</em>) – Targets. Default to <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>attributions.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>th.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.SequentialIntegratedGradients">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">SequentialIntegratedGradients</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multiply_by_inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/seq_ig.html#SequentialIntegratedGradients"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.SequentialIntegratedGradients" title="Permalink to this definition">¶</a></dt>
<dd><p>Sequential Integrated Gradients.</p>
<p>This method is the regular Integrated Gradients (IG) applied on each
component of a sequence. However, the baseline is specific to each
component: it keeps fixed the rest of the sequence while only setting the
component of interest to a reference baseline.</p>
<p>For instance, on a setence of m words, the attribution of each word is
computed by running IG with a specific baseline: fixing every other word
to their current value, and replacing the word of interest with “&lt;pad&gt;”,
an uninformative baseline.</p>
<p>This method can be computationally expensive on long sequences, as it
needs to compute IG on each component individually. It is therefore
suggested to reduce <code class="docutils literal notranslate"><span class="pre">n_steps</span></code> when using this method on long sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.SequentialIntegratedGradients.params.forward_func"></span><strong>forward_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.SequentialIntegratedGradients.params.forward_func">¶</a> (<em>callable</em>) – The forward function of the model or any
modification of it</p></li>
<li><p><span class="target" id="tint.attr.SequentialIntegratedGradients.params.multiply_by_inputs"></span><strong>multiply_by_inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.SequentialIntegratedGradients.params.multiply_by_inputs">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – <p>Indicates whether to factor
model inputs’ multiplier in the final attribution scores.
In the literature this is also known as local vs global
attribution. If inputs’ multiplier isn’t factored in,
then that type of attribution method is also called local
attribution. If it is, then that type of attribution
method is called global.
More detailed can be found here:
<a class="reference external" href="https://arxiv.org/abs/1711.06104">https://arxiv.org/abs/1711.06104</a></p>
<p>In case of integrated gradients, if <cite>multiply_by_inputs</cite>
is set to True, final sensitivity scores are being multiplied by
(inputs - baselines).</p>
</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">SequentialIntegratedGradients</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.models</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">SequentialIntegratedGradients</span><span class="p">(</span><span class="n">mlp</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.SequentialIntegratedGradients.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baselines</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">BaselineType</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TargetType</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'gausslegendre'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">internal_batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_convergence_delta</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="k"><span class="pre">False</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></span><a class="reference internal" href="_modules/tint/attr/seq_ig.html#SequentialIntegratedGradients.attribute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.SequentialIntegratedGradients.attribute" title="Permalink to this definition">¶</a></dt>
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baselines</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">BaselineType</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TargetType</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'gausslegendre'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">internal_batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_convergence_delta</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="k"><span class="pre">True</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">TensorOrTupleOfTensorsGeneric</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span></dt>
<dd><p>This method attributes the output of the model with given target index
(in case it is provided, otherwise it assumes that output is a
scalar) to the inputs of the model using the approach described above.</p>
<p>In addition to that it also returns, if <cite>return_convergence_delta</cite> is
set to True, integral approximation delta based on the completeness
property of integrated gradients.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.SequentialIntegratedGradients.attribute.params.inputs"></span><strong>inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.SequentialIntegratedGradients.attribute.params.inputs">¶</a> (<em>tensor</em><em> or </em><em>tuple</em><em> of </em><em>tensors</em>) – Input for which integrated
gradients are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.
If forward_func takes multiple tensors as input, a tuple
of the input tensors should be provided. It is assumed
that for all given input tensors, dimension 0 corresponds
to the number of examples, and if multiple input tensors
are provided, the examples must be aligned appropriately.</p></li>
<li><p><span class="target" id="tint.attr.SequentialIntegratedGradients.attribute.params.baselines"></span><strong>baselines</strong><a class="paramlink headerlink reference internal" href="#tint.attr.SequentialIntegratedGradients.attribute.params.baselines">¶</a> (<em>scalar</em><em>, </em><em>tensor</em><em>, </em><em>tuple</em><em> of </em><em>scalars</em><em> or </em><em>tensors</em><em>, </em><em>optional</em>) – <p>Baselines define the starting point from which integral
is computed and can be provided as:</p>
<ul>
<li><p>a single tensor, if inputs is a single tensor, with
exactly the same dimensions as inputs or the first
dimension is one and the remaining dimensions match
with inputs.</p></li>
<li><p>a single scalar, if inputs is a single tensor, which will
be broadcasted for each input value in input tensor.</p></li>
<li><p>a tuple of tensors or scalars, the baseline corresponding
to each tensor in the inputs’ tuple can be:</p>
<ul>
<li><p>either a tensor with matching dimensions to
corresponding tensor in the inputs’ tuple
or the first dimension is one and the remaining
dimensions match with the corresponding
input tensor.</p></li>
<li><p>or a scalar, corresponding to a tensor in the
inputs’ tuple. This scalar value is broadcasted
for corresponding input tensor.</p></li>
</ul>
</li>
</ul>
<p>In the cases when <cite>baselines</cite> is not provided, we internally
use zero scalar corresponding to each input tensor.</p>
<p>Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.SequentialIntegratedGradients.attribute.params.target"></span><strong>target</strong><a class="paramlink headerlink reference internal" href="#tint.attr.SequentialIntegratedGradients.attribute.params.target">¶</a> (<em>int</em><em>, </em><em>tuple</em><em>, </em><em>tensor</em><em> or </em><em>list</em><em>, </em><em>optional</em>) – <p>Output indices for
which gradients are computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><p>a single integer or a tensor containing a single
integer, which is applied to all input examples</p></li>
<li><p>a list of integers or a 1D tensor, with length matching
the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p></li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><p>A single tuple, which contains #output_dims - 1
elements. This target index is applied to all examples.</p></li>
<li><p>A list of tuples with length equal to the number of
examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p></li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.SequentialIntegratedGradients.attribute.params.additional_forward_args"></span><strong>additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.SequentialIntegratedGradients.attribute.params.additional_forward_args">¶</a> (<em>any</em><em>, </em><em>optional</em>) – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a
tuple containing multiple additional arguments including
tensors or any arbitrary python types. These arguments
are provided to forward_func in order following the
arguments in inputs.
For a tensor, the first dimension of the tensor must
correspond to the number of examples. It will be
repeated for each of <cite>n_steps</cite> along the integrated
path. For all other types, the given argument is used
for all forward evaluations.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.SequentialIntegratedGradients.attribute.params.n_steps"></span><strong>n_steps</strong><a class="paramlink headerlink reference internal" href="#tint.attr.SequentialIntegratedGradients.attribute.params.n_steps">¶</a> (<em>int</em><em>, </em><em>optional</em>) – The number of steps used by the approximation
method. Default: 50.</p></li>
<li><p><span class="target" id="tint.attr.SequentialIntegratedGradients.attribute.params.method"></span><strong>method</strong><a class="paramlink headerlink reference internal" href="#tint.attr.SequentialIntegratedGradients.attribute.params.method">¶</a> (<em>string</em><em>, </em><em>optional</em>) – Method for approximating the integral,
one of <cite>riemann_right</cite>, <cite>riemann_left</cite>, <cite>riemann_middle</cite>,
<cite>riemann_trapezoid</cite> or <cite>gausslegendre</cite>.
Default: <cite>gausslegendre</cite> if no method is provided.</p></li>
<li><p><span class="target" id="tint.attr.SequentialIntegratedGradients.attribute.params.internal_batch_size"></span><strong>internal_batch_size</strong><a class="paramlink headerlink reference internal" href="#tint.attr.SequentialIntegratedGradients.attribute.params.internal_batch_size">¶</a> (<em>int</em><em>, </em><em>optional</em>) – Divides total #steps * #examples
data points into chunks of size at most internal_batch_size,
which are computed (forward / backward passes)
sequentially. internal_batch_size must be at least equal to
#examples.
For DataParallel models, each batch is split among the
available devices, so evaluations on each available
device contain internal_batch_size / num_devices examples.
If internal_batch_size is None, then all evaluations are
processed in one batch.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.SequentialIntegratedGradients.attribute.params.return_convergence_delta"></span><strong>return_convergence_delta</strong><a class="paramlink headerlink reference internal" href="#tint.attr.SequentialIntegratedGradients.attribute.params.return_convergence_delta">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – Indicates whether to return
convergence delta or not. If <cite>return_convergence_delta</cite>
is set to True convergence delta will be returned in
a tuple following attributions.
Default: False</p></li>
<li><p><span class="target" id="tint.attr.SequentialIntegratedGradients.attribute.params.show_progress"></span><strong>show_progress</strong><a class="paramlink headerlink reference internal" href="#tint.attr.SequentialIntegratedGradients.attribute.params.show_progress">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – Displays the progress of
computation. It will try to use tqdm if available for
advanced features (e.g. time estimation). Otherwise, it
will fallback to a simple output of progress.
Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><dl class="simple">
<dt><strong>attributions</strong> (<em>tensor</em> or tuple of <em>tensors</em>):</dt><dd><p>Integrated gradients with respect to each input feature.
attributions will always be the same size as the provided
inputs, with each value providing the attribution of the
corresponding input index.
If a single tensor is provided as inputs, a single tensor is
returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>delta</strong> (<em>tensor</em>, returned if return_convergence_delta=True):</dt><dd><p>The difference between the total approximated and true
integrated gradients. This is computed using the property
that the total sum of forward_func(inputs) -
forward_func(baselines) must equal the total sum of the
integrated gradient.
Delta is calculated per example, meaning that the number of
elements in returned delta tensor is equal to the number of
of examples in inputs.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>attributions</strong> or 2-element tuple of <strong>attributions</strong>, <strong>delta</strong></p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># ImageClassifier takes a single input tensor of images Nx3x32x32,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># and returns an Nx10 tensor of class probabilities.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">ImageClassifier</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ig</span> <span class="o">=</span> <span class="n">IntegratedGradients</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Computes integrated gradients for class 3.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attribution</span> <span class="o">=</span> <span class="n">ig</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.SequentialIntegratedGradients.has_convergence_delta">
<span class="sig-name descname"><span class="pre">has_convergence_delta</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="reference internal" href="_modules/tint/attr/seq_ig.html#SequentialIntegratedGradients.has_convergence_delta"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.SequentialIntegratedGradients.has_convergence_delta" title="Permalink to this definition">¶</a></dt>
<dd><p>This method informs the user whether the attribution algorithm provides
a convergence delta (aka an approximation error) or not. Convergence
delta may serve as a proxy of correctness of attribution algorithm’s
approximation. If deriving attribution class provides a
<cite>compute_convergence_delta</cite> method, it should
override both <cite>compute_convergence_delta</cite> and <cite>has_convergence_delta</cite> methods.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Returns whether the attribution algorithm
provides a convergence delta (aka approximation error) or not.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.TemporalAugmentedOcclusion">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">TemporalAugmentedOcclusion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_sampling</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_temporal</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/temporal_augmented_occlusion.html#TemporalAugmentedOcclusion"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.TemporalAugmentedOcclusion" title="Permalink to this definition">¶</a></dt>
<dd><p>Temporal Augmented Occlusion.</p>
<p>This method modifies the original augmented occlusion by only perturbing
the last time, leaving the previous times unchanged. It can be used
together with <code class="docutils literal notranslate"><span class="pre">time_forward_tunnel</span></code> to compute attributions on time
series.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.TemporalAugmentedOcclusion.params.forward_func"></span><strong>forward_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalAugmentedOcclusion.params.forward_func">¶</a> (<em>callable</em>) – The forward function of the model or
any modification of it</p></li>
<li><p><span class="target" id="tint.attr.TemporalAugmentedOcclusion.params.data"></span><strong>data</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalAugmentedOcclusion.params.data">¶</a> (<em>tuple</em><em>, </em><em>Tensor</em>) – The data from which the baselines are sampled.</p></li>
<li><p><span class="target" id="tint.attr.TemporalAugmentedOcclusion.params.n_sampling"></span><strong>n_sampling</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalAugmentedOcclusion.params.n_sampling">¶</a> (<em>int</em>) – Number of sampling to run for each occlusion.
Default to 1</p></li>
<li><p><span class="target" id="tint.attr.TemporalAugmentedOcclusion.params.is_temporal"></span><strong>is_temporal</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalAugmentedOcclusion.params.is_temporal">¶</a> (<em>bool</em>) – Whether the data is temporal or not.
If <code class="docutils literal notranslate"><span class="pre">True</span></code>, the data will be ablated to the inputs
on the temporal dimension (dimension 1). Default to <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://arxiv.org/abs/2003.02821">https://arxiv.org/abs/2003.02821</a></p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">TemporalAugmentedOcclusion</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.models</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">TemporalAugmentedOcclusion</span><span class="p">(</span><span class="n">mlp</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,))</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.TemporalAugmentedOcclusion.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sliding_window_shapes</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">perturbations_per_eval</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attributions_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></span><a class="reference internal" href="_modules/tint/attr/temporal_augmented_occlusion.html#TemporalAugmentedOcclusion.attribute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.TemporalAugmentedOcclusion.attribute" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.TemporalAugmentedOcclusion.attribute.params.inputs"></span><strong>inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalAugmentedOcclusion.attribute.params.inputs">¶</a> (<em>tensor</em><em> or </em><em>tuple</em><em> of </em><em>tensors</em>) – Input for which occlusion
attributions are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.
If forward_func takes multiple tensors as input, a tuple
of the input tensors should be provided. It is assumed
that for all given input tensors, dimension 0 corresponds
to the number of examples (aka batch size), and if
multiple input tensors are provided, the examples must
be aligned appropriately.</p></li>
<li><p><span class="target" id="tint.attr.TemporalAugmentedOcclusion.attribute.params.sliding_window_shapes"></span><strong>sliding_window_shapes</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalAugmentedOcclusion.attribute.params.sliding_window_shapes">¶</a> (<em>tuple</em><em> or </em><em>tuple</em><em> of </em><em>tuples</em>) – Shape of patch
(hyperrectangle) to occlude each input. For a single
input tensor, this must be a tuple of length equal to the
number of dimensions of the input tensor - 2, defining
the dimensions of the patch. If the input tensor is 2-d,
this should be an empty tuple. For multiple input tensors,
this must be a tuple containing one tuple for each input
tensor defining the dimensions of the patch for that
input tensor, as described for the single tensor case.</p></li>
<li><p><span class="target" id="tint.attr.TemporalAugmentedOcclusion.attribute.params.strides"></span><strong>strides</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalAugmentedOcclusion.attribute.params.strides">¶</a> (<em>int</em><em> or </em><em>tuple</em><em> or </em><em>tuple</em><em> of </em><em>ints</em><em> or </em><em>tuple</em><em> of </em><em>tuples</em><em>, </em><em>optional</em>) – This defines the step by which the occlusion hyperrectangle
should be shifted by in each direction for each iteration.
For a single tensor input, this can be either a single
integer, which is used as the step size in each direction,
or a tuple of integers matching the number of dimensions
in the occlusion shape, defining the step size in the
corresponding dimension. For multiple tensor inputs, this
can be either a tuple of integers, one for each input
tensor (used for all dimensions of the corresponding
tensor), or a tuple of tuples, providing the stride per
dimension for each tensor.
To ensure that all inputs are covered by at least one
sliding window, the stride for any dimension must be
&lt;= the corresponding sliding window dimension if the
sliding window dimension is less than the input
dimension.
If None is provided, a stride of 1 is used for each
dimension of each input tensor.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.TemporalAugmentedOcclusion.attribute.params.target"></span><strong>target</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalAugmentedOcclusion.attribute.params.target">¶</a> (<em>int</em><em>, </em><em>tuple</em><em>, </em><em>tensor</em><em> or </em><em>list</em><em>, </em><em>optional</em>) – <p>Output indices for
which difference is computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><p>a single integer or a tensor containing a single
integer, which is applied to all input examples</p></li>
<li><p>a list of integers or a 1D tensor, with length matching
the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p></li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><p>A single tuple, which contains #output_dims - 1
elements. This target index is applied to all examples.</p></li>
<li><p>A list of tuples with length equal to the number of
examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p></li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.TemporalAugmentedOcclusion.attribute.params.additional_forward_args"></span><strong>additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalAugmentedOcclusion.attribute.params.additional_forward_args">¶</a> (<em>any</em><em>, </em><em>optional</em>) – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a
tuple containing multiple additional arguments including
tensors or any arbitrary python types. These arguments
are provided to forward_func in order following the
arguments in inputs.
For a tensor, the first dimension of the tensor must
correspond to the number of examples. For all other types,
the given argument is used for all forward evaluations.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.TemporalAugmentedOcclusion.attribute.params.perturbations_per_eval"></span><strong>perturbations_per_eval</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalAugmentedOcclusion.attribute.params.perturbations_per_eval">¶</a> (<em>int</em><em>, </em><em>optional</em>) – Allows multiple occlusions
to be included in one batch (one call to forward_fn).
By default, perturbations_per_eval is 1, so each occlusion
is processed individually.
Each forward pass will contain a maximum of
perturbations_per_eval * #examples samples.
For DataParallel models, each batch is split among the
available devices, so evaluations on each available
device contain at most
(perturbations_per_eval * #examples) / num_devices
samples.
Default: 1</p></li>
<li><p><span class="target" id="tint.attr.TemporalAugmentedOcclusion.attribute.params.attributions_fn"></span><strong>attributions_fn</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalAugmentedOcclusion.attribute.params.attributions_fn">¶</a> (<em>Callable</em><em>, </em><em>optional</em>) – Applies a function to the
attributions before performing the weighted sum.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.TemporalAugmentedOcclusion.attribute.params.show_progress"></span><strong>show_progress</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalAugmentedOcclusion.attribute.params.show_progress">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – Displays the progress of computation.
It will try to use tqdm if available for advanced features
(e.g. time estimation). Otherwise, it will fallback to
a simple output of progress.
Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><dl class="simple">
<dt><strong>attributions</strong> (<em>tensor</em> or tuple of <em>tensors</em>):</dt><dd><p>The attributions with respect to each input feature.
Attributions will always be
the same size as the provided inputs, with each value
providing the attribution of the corresponding input index.
If a single tensor is provided as inputs, a single tensor is
returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>tensor</em> or tuple of <em>tensors</em> of <strong>attributions</strong></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.TemporalIntegratedGradients">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">TemporalIntegratedGradients</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multiply_by_inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/temporal_ig.html#TemporalIntegratedGradients"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.TemporalIntegratedGradients" title="Permalink to this definition">¶</a></dt>
<dd><p>Temporal Integrated Gradients.</p>
<p>This method computes gradients iteratively on a time series as such:
it crops the sequence up to a time, and only moves this last time from
a baseline to its original value.</p>
<p>The number of steps per time depends on the strategy. If it is
<code class="docutils literal notranslate"><span class="pre">'fixed'</span></code>, then n_steps gradients are computed for each time.
If it is <code class="docutils literal notranslate"><span class="pre">'interval'</span></code>, the number of steps depends on the interval
between two times: the larger, the greater number of points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.TemporalIntegratedGradients.params.forward_func"></span><strong>forward_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalIntegratedGradients.params.forward_func">¶</a> (<em>callable</em>) – The forward function of the model or
any modification of it.</p></li>
<li><p><span class="target" id="tint.attr.TemporalIntegratedGradients.params.multiply_by_inputs"></span><strong>multiply_by_inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalIntegratedGradients.params.multiply_by_inputs">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – <p>Indicates whether to factor
model inputs’ multiplier in the final attribution scores.
In the literature this is also known as local vs global
attribution. If inputs’ multiplier isn’t factored in,
then that type of attribution method is also called local
attribution. If it is, then that type of attribution
method is called global.
More detailed can be found here:
<a class="reference external" href="https://arxiv.org/abs/1711.06104">https://arxiv.org/abs/1711.06104</a></p>
<p>In case of integrated gradients, if <cite>multiply_by_inputs</cite>
is set to True, final sensitivity scores are being multiplied by
(inputs - baselines).</p>
</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">TemporalIntegratedGradients</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.models</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">TemporalIntegratedGradients</span><span class="p">(</span><span class="n">mlp</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.TemporalIntegratedGradients.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baselines</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">BaselineType</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TargetType</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">times</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'gausslegendre'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'fixed'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">internal_batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_convergence_delta</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="k"><span class="pre">False</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temporal_target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temporal_additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_temporal_attributions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></span><a class="reference internal" href="_modules/tint/attr/temporal_ig.html#TemporalIntegratedGradients.attribute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.TemporalIntegratedGradients.attribute" title="Permalink to this definition">¶</a></dt>
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baselines</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">BaselineType</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TargetType</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">times</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'gausslegendre'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'fixed'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">internal_batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_convergence_delta</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="k"><span class="pre">True</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temporal_target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temporal_additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_temporal_attributions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">TensorOrTupleOfTensorsGeneric</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span></dt>
<dd><p>Attribute method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.TemporalIntegratedGradients.attribute.params.inputs"></span><strong>inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalIntegratedGradients.attribute.params.inputs">¶</a> (<em>tensor</em><em> or </em><em>tuple</em><em> of </em><em>tensors</em>) – Input for which integrated
gradients are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.
If forward_func takes multiple tensors as input, a tuple
of the input tensors should be provided. It is assumed
that for all given input tensors, dimension 0 corresponds
to the number of examples, and if multiple input tensors
are provided, the examples must be aligned appropriately.</p></li>
<li><p><span class="target" id="tint.attr.TemporalIntegratedGradients.attribute.params.baselines"></span><strong>baselines</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalIntegratedGradients.attribute.params.baselines">¶</a> (<em>scalar</em><em>, </em><em>tensor</em><em>, </em><em>tuple</em><em> of </em><em>scalars</em><em> or </em><em>tensors</em><em>, </em><em>optional</em>) – <p>Baselines define the starting point from which integral
is computed and can be provided as:</p>
<ul>
<li><p>a single tensor, if inputs is a single tensor, with
exactly the same dimensions as inputs or the first
dimension is one and the remaining dimensions match
with inputs.</p></li>
<li><p>a single scalar, if inputs is a single tensor, which will
be broadcasted for each input value in input tensor.</p></li>
<li><p>a tuple of tensors or scalars, the baseline corresponding
to each tensor in the inputs’ tuple can be:</p>
<ul>
<li><p>either a tensor with matching dimensions to
corresponding tensor in the inputs’ tuple
or the first dimension is one and the remaining
dimensions match with the corresponding
input tensor.</p></li>
<li><p>or a scalar, corresponding to a tensor in the
inputs’ tuple. This scalar value is broadcasted
for corresponding input tensor.</p></li>
</ul>
</li>
</ul>
<p>In the cases when <cite>baselines</cite> is not provided, we internally
use zero scalar corresponding to each input tensor.</p>
<p>Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.TemporalIntegratedGradients.attribute.params.target"></span><strong>target</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalIntegratedGradients.attribute.params.target">¶</a> (<em>int</em><em>, </em><em>tuple</em><em>, </em><em>tensor</em><em> or </em><em>list</em><em>, </em><em>optional</em>) – <p>Output indices for
which gradients are computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><p>a single integer or a tensor containing a single
integer, which is applied to all input examples</p></li>
<li><p>a list of integers or a 1D tensor, with length matching
the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p></li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><p>A single tuple, which contains #output_dims - 1
elements. This target index is applied to all examples.</p></li>
<li><p>A list of tuples with length equal to the number of
examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p></li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.TemporalIntegratedGradients.attribute.params.additional_forward_args"></span><strong>additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalIntegratedGradients.attribute.params.additional_forward_args">¶</a> (<em>any</em><em>, </em><em>optional</em>) – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a
tuple containing multiple additional arguments including
tensors or any arbitrary python types. These arguments
are provided to forward_func in order following the
arguments in inputs.
For a tensor, the first dimension of the tensor must
correspond to the number of examples. It will be
repeated for each of <cite>n_steps</cite> along the integrated
path. For all other types, the given argument is used
for all forward evaluations.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.TemporalIntegratedGradients.attribute.params.times"></span><strong>times</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalIntegratedGradients.attribute.params.times">¶</a> (<em>Tensor</em><em>, </em><em>optional</em>) – Tensor of times. If not provided, it is
assumed that the points are temporally equally spaced.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.TemporalIntegratedGradients.attribute.params.n_steps"></span><strong>n_steps</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalIntegratedGradients.attribute.params.n_steps">¶</a> (<em>int</em><em>, </em><em>optional</em>) – The number of steps used by the approximation
method. Default: 50.</p></li>
<li><p><span class="target" id="tint.attr.TemporalIntegratedGradients.attribute.params.method"></span><strong>method</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalIntegratedGradients.attribute.params.method">¶</a> (<em>string</em><em>, </em><em>optional</em>) – Method for approximating the integral,
one of <cite>riemann_right</cite>, <cite>riemann_left</cite>, <cite>riemann_middle</cite>,
<cite>riemann_trapezoid</cite> or <cite>gausslegendre</cite>.
Default: <cite>gausslegendre</cite> if no method is provided.</p></li>
<li><p><span class="target" id="tint.attr.TemporalIntegratedGradients.attribute.params.strategy"></span><strong>strategy</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalIntegratedGradients.attribute.params.strategy">¶</a> (<em>str</em><em>, </em><em>optinal</em>) – Strategy to distribute gradients
evaluations over time. Either <code class="docutils literal notranslate"><span class="pre">'fixed'</span></code> or <code class="docutils literal notranslate"><span class="pre">'interval'</span></code>
Default: ‘fixed’</p></li>
<li><p><span class="target" id="tint.attr.TemporalIntegratedGradients.attribute.params.internal_batch_size"></span><strong>internal_batch_size</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalIntegratedGradients.attribute.params.internal_batch_size">¶</a> (<em>int</em><em>, </em><em>optional</em>) – Divides total #steps * #examples
data points into chunks of size at most internal_batch_size,
which are computed (forward / backward passes)
sequentially. internal_batch_size must be at least equal to
#examples.
For DataParallel models, each batch is split among the
available devices, so evaluations on each available
device contain internal_batch_size / num_devices examples.
If internal_batch_size is None, then all evaluations are
processed in one batch.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.TemporalIntegratedGradients.attribute.params.return_convergence_delta"></span><strong>return_convergence_delta</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalIntegratedGradients.attribute.params.return_convergence_delta">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – Indicates whether to return
convergence delta or not. If <cite>return_convergence_delta</cite>
is set to True convergence delta will be returned in
a tuple following attributions.
Default: False</p></li>
<li><p><span class="target" id="tint.attr.TemporalIntegratedGradients.attribute.params.temporal_target"></span><strong>temporal_target</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalIntegratedGradients.attribute.params.temporal_target">¶</a> – Temporal target. Default: False</p></li>
<li><p><span class="target" id="tint.attr.TemporalIntegratedGradients.attribute.params.temporal_additional_forward_args"></span><strong>temporal_additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalIntegratedGradients.attribute.params.temporal_additional_forward_args">¶</a> (<em>tuple</em>) – Set each
additional forward arg which is temporal.
Only used with return_temporal_attributions.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.TemporalIntegratedGradients.attribute.params.return_temporal_attributions"></span><strong>return_temporal_attributions</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalIntegratedGradients.attribute.params.return_temporal_attributions">¶</a> (<em>bool</em>) – Whether to return all saliencies
for all time points or only the last one per time point.
Default: False</p></li>
<li><p><span class="target" id="tint.attr.TemporalIntegratedGradients.attribute.params.show_progress"></span><strong>show_progress</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalIntegratedGradients.attribute.params.show_progress">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – Displays the progress of
computation. It will try to use tqdm if available for
advanced features (e.g. time estimation). Otherwise, it
will fallback to a simple output of progress.
Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><dl class="simple">
<dt><strong>attributions</strong> (<em>tensor</em> or tuple of <em>tensors</em>):</dt><dd><p>Integrated gradients with respect to each input feature.
attributions will always be the same size as the provided
inputs, with each value providing the attribution of the
corresponding input index.
If a single tensor is provided as inputs, a single tensor is
returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>delta</strong> (<em>tensor</em>, returned if return_convergence_delta=True):</dt><dd><p>The difference between the total approximated and true
integrated gradients. This is computed using the property
that the total sum of forward_func(inputs) -
forward_func(baselines) must equal the total sum of the
integrated gradient.
Delta is calculated per example, meaning that the number of
elements in returned delta tensor is equal to the number of
of examples in inputs.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>attributions</strong> or 2-element tuple of <strong>attributions</strong>, <strong>delta</strong></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.TemporalOcclusion">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">TemporalOcclusion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/temporal_occlusion.html#TemporalOcclusion"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.TemporalOcclusion" title="Permalink to this definition">¶</a></dt>
<dd><p>Temporal Occlusion.</p>
<p>This method modifies the original occlusion by only perturbing the last
time, leaving the previous times unchanged. It can be used together with
<code class="docutils literal notranslate"><span class="pre">time_forward_tunnel</span></code> to compute attributions on time series.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="target" id="tint.attr.TemporalOcclusion.params.forward_func"></span><strong>forward_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalOcclusion.params.forward_func">¶</a> (<em>callable</em>) – The forward function of the model or
any modification of it.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">TemporalOcclusion</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.models</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">TemporalOcclusion</span><span class="p">(</span><span class="n">mlp</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,))</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.TemporalOcclusion.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sliding_window_shapes</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baselines</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">None</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">perturbations_per_eval</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attributions_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></span><a class="reference internal" href="_modules/tint/attr/temporal_occlusion.html#TemporalOcclusion.attribute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.TemporalOcclusion.attribute" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.TemporalOcclusion.attribute.params.inputs"></span><strong>inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalOcclusion.attribute.params.inputs">¶</a> (<em>tensor</em><em> or </em><em>tuple</em><em> of </em><em>tensors</em>) – Input for which occlusion
attributions are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.
If forward_func takes multiple tensors as input, a tuple
of the input tensors should be provided. It is assumed
that for all given input tensors, dimension 0 corresponds
to the number of examples (aka batch size), and if
multiple input tensors are provided, the examples must
be aligned appropriately.</p></li>
<li><p><span class="target" id="tint.attr.TemporalOcclusion.attribute.params.sliding_window_shapes"></span><strong>sliding_window_shapes</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalOcclusion.attribute.params.sliding_window_shapes">¶</a> (<em>tuple</em><em> or </em><em>tuple</em><em> of </em><em>tuples</em>) – Shape of patch
(hyperrectangle) to occlude each input. For a single
input tensor, this must be a tuple of length equal to the
number of dimensions of the input tensor - 2, defining
the dimensions of the patch. If the input tensor is 2-d,
this should be an empty tuple. For multiple input tensors,
this must be a tuple containing one tuple for each input
tensor defining the dimensions of the patch for that
input tensor, as described for the single tensor case.</p></li>
<li><p><span class="target" id="tint.attr.TemporalOcclusion.attribute.params.strides"></span><strong>strides</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalOcclusion.attribute.params.strides">¶</a> (<em>int</em><em> or </em><em>tuple</em><em> or </em><em>tuple</em><em> of </em><em>ints</em><em> or </em><em>tuple</em><em> of </em><em>tuples</em><em>, </em><em>optional</em>) – This defines the step by which the occlusion hyperrectangle
should be shifted by in each direction for each iteration.
For a single tensor input, this can be either a single
integer, which is used as the step size in each direction,
or a tuple of integers matching the number of dimensions
in the occlusion shape, defining the step size in the
corresponding dimension. For multiple tensor inputs, this
can be either a tuple of integers, one for each input
tensor (used for all dimensions of the corresponding
tensor), or a tuple of tuples, providing the stride per
dimension for each tensor.
To ensure that all inputs are covered by at least one
sliding window, the stride for any dimension must be
&lt;= the corresponding sliding window dimension if the
sliding window dimension is less than the input
dimension.
If None is provided, a stride of 1 is used for each
dimension of each input tensor.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.TemporalOcclusion.attribute.params.baselines"></span><strong>baselines</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalOcclusion.attribute.params.baselines">¶</a> (<em>scalar</em><em>, </em><em>tensor</em><em>, </em><em>tuple</em><em> of </em><em>scalars</em><em> or </em><em>tensors</em><em>, </em><em>optional</em>) – <p>Baselines define reference value which replaces each
feature when occluded.
Baselines can be provided as:</p>
<ul>
<li><p>a single tensor, if inputs is a single tensor, with
exactly the same dimensions as inputs or
broadcastable to match the dimensions of inputs</p></li>
<li><p>a single scalar, if inputs is a single tensor, which will
be broadcasted for each input value in input tensor.</p></li>
<li><p>a tuple of tensors or scalars, the baseline corresponding
to each tensor in the inputs’ tuple can be:</p>
<ul>
<li><p>either a tensor with matching dimensions to
corresponding tensor in the inputs’ tuple
or the first dimension is one and the remaining
dimensions match with the corresponding
input tensor.</p></li>
<li><p>or a scalar, corresponding to a tensor in the
inputs’ tuple. This scalar value is broadcasted
for corresponding input tensor.</p></li>
</ul>
</li>
</ul>
<p>In the cases when <cite>baselines</cite> is not provided, we internally
use zero scalar corresponding to each input tensor.
Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.TemporalOcclusion.attribute.params.target"></span><strong>target</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalOcclusion.attribute.params.target">¶</a> (<em>int</em><em>, </em><em>tuple</em><em>, </em><em>tensor</em><em> or </em><em>list</em><em>, </em><em>optional</em>) – <p>Output indices for
which difference is computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><p>a single integer or a tensor containing a single
integer, which is applied to all input examples</p></li>
<li><p>a list of integers or a 1D tensor, with length matching
the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p></li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><p>A single tuple, which contains #output_dims - 1
elements. This target index is applied to all examples.</p></li>
<li><p>A list of tuples with length equal to the number of
examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p></li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.TemporalOcclusion.attribute.params.additional_forward_args"></span><strong>additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalOcclusion.attribute.params.additional_forward_args">¶</a> (<em>any</em><em>, </em><em>optional</em>) – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a
tuple containing multiple additional arguments including
tensors or any arbitrary python types. These arguments
are provided to forward_func in order following the
arguments in inputs.
For a tensor, the first dimension of the tensor must
correspond to the number of examples. For all other types,
the given argument is used for all forward evaluations.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.TemporalOcclusion.attribute.params.perturbations_per_eval"></span><strong>perturbations_per_eval</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalOcclusion.attribute.params.perturbations_per_eval">¶</a> (<em>int</em><em>, </em><em>optional</em>) – Allows multiple occlusions
to be included in one batch (one call to forward_fn).
By default, perturbations_per_eval is 1, so each occlusion
is processed individually.
Each forward pass will contain a maximum of
perturbations_per_eval * #examples samples.
For DataParallel models, each batch is split among the
available devices, so evaluations on each available
device contain at most
(perturbations_per_eval * #examples) / num_devices
samples.
Default: 1</p></li>
<li><p><span class="target" id="tint.attr.TemporalOcclusion.attribute.params.attributions_fn"></span><strong>attributions_fn</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalOcclusion.attribute.params.attributions_fn">¶</a> (<em>Callable</em><em>, </em><em>optional</em>) – Applies a function to the
attributions before performing the weighted sum.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.TemporalOcclusion.attribute.params.show_progress"></span><strong>show_progress</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalOcclusion.attribute.params.show_progress">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – Displays the progress of computation.
It will try to use tqdm if available for advanced features
(e.g. time estimation). Otherwise, it will fallback to
a simple output of progress.
Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><dl class="simple">
<dt><strong>attributions</strong> (<em>tensor</em> or tuple of <em>tensors</em>):</dt><dd><p>The attributions with respect to each input feature.
Attributions will always be
the same size as the provided inputs, with each value
providing the attribution of the corresponding input index.
If a single tensor is provided as inputs, a single tensor is
returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>tensor</em> or tuple of <em>tensors</em> of <strong>attributions</strong></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.TimeForwardTunnel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">TimeForwardTunnel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">attribution_method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Attribution</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/time_forward_tunnel.html#TimeForwardTunnel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.TimeForwardTunnel" title="Permalink to this definition">¶</a></dt>
<dd><p>Time Forward Tunnel.</p>
<p>Performs interpretation method by iteratively retrieving the input data
up to a time, and computing the predictions using this data and the
forward_func.</p>
<p>The true target can be passed, otherwise it will be inferred depending on
the task.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="target" id="tint.attr.TimeForwardTunnel.params.attribution_method"></span><strong>attribution_method</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TimeForwardTunnel.params.attribution_method">¶</a> (<em>Attribution</em>) – An instance of any attribution algorithm
of type <cite>Attribution</cite>. E.g. Integrated Gradients,
Conductance or Saliency.</p>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://arxiv.org/abs/2003.02821">https://arxiv.org/abs/2003.02821</a></p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">captum.attr</span> <span class="kn">import</span> <span class="n">Saliency</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">TimeForwardTunnel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.models</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">TimeForwardTunnel</span><span class="p">(</span><span class="n">Saliency</span><span class="p">(</span><span class="n">mlp</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.TimeForwardTunnel.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'none'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temporal_target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temporal_additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_temporal_attributions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/tint/attr/time_forward_tunnel.html#TimeForwardTunnel.attribute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.TimeForwardTunnel.attribute" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.TimeForwardTunnel.attribute.params.inputs"></span><strong>inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TimeForwardTunnel.attribute.params.inputs">¶</a> (<em>tensor</em><em> or </em><em>tuple</em><em> of </em><em>tensors</em>) – Input for which integrated
gradients are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.
If forward_func takes multiple tensors as input, a tuple
of the input tensors should be provided. It is assumed
that for all given input tensors, dimension 0 corresponds
to the number of examples, and if multiple input tensors
are provided, the examples must be aligned appropriately.
It is also assumed that for all given input tensors,
dimension 1 corresponds to the time dimension, and if
multiple input tensors are provided, the examples must
be aligned appropriately.</p></li>
<li><p><span class="target" id="tint.attr.TimeForwardTunnel.attribute.params.task"></span><strong>task</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TimeForwardTunnel.attribute.params.task">¶</a> (<em>str</em>) – Type of task done by the model. Either <code class="docutils literal notranslate"><span class="pre">'binary'</span></code>,
<code class="docutils literal notranslate"><span class="pre">'multilabel'</span></code>, <code class="docutils literal notranslate"><span class="pre">'multiclass'</span></code> or <code class="docutils literal notranslate"><span class="pre">'regression'</span></code>.
Default to <code class="docutils literal notranslate"><span class="pre">'binary'</span></code></p></li>
<li><p><span class="target" id="tint.attr.TimeForwardTunnel.attribute.params.threshold"></span><strong>threshold</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TimeForwardTunnel.attribute.params.threshold">¶</a> (<em>float</em>) – Threshold for the multilabel task.
Default to 0.5</p></li>
<li><p><span class="target" id="tint.attr.TimeForwardTunnel.attribute.params.temporal_target"></span><strong>temporal_target</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TimeForwardTunnel.attribute.params.temporal_target">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – Determine if the targe is
temporal and needs to be cut.
Default: False</p></li>
<li><p><span class="target" id="tint.attr.TimeForwardTunnel.attribute.params.temporal_additional_forward_args"></span><strong>temporal_additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TimeForwardTunnel.attribute.params.temporal_additional_forward_args">¶</a> (<em>tuple</em><em>, </em><em>optional</em>) – For each
additional forward arg, determine if it is temporal
or not.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.TimeForwardTunnel.attribute.params.return_temporal_attributions"></span><strong>return_temporal_attributions</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TimeForwardTunnel.attribute.params.return_temporal_attributions">¶</a> (<em>bool</em>) – Whether to return all saliencies
for all time points or only the last one per time point.
Default: False</p></li>
<li><p><span class="target" id="tint.attr.TimeForwardTunnel.attribute.params.show_progress"></span><strong>show_progress</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TimeForwardTunnel.attribute.params.show_progress">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – Displays the progress of computation.
It will try to use tqdm if available for advanced features
(e.g. time estimation). Otherwise, it will fallback to
a simple output of progress.
Default: False</p></li>
<li><p><span class="target" id="tint.attr.TimeForwardTunnel.attribute.params.**kwargs"></span><strong>**kwargs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TimeForwardTunnel.attribute.params.**kwargs">¶</a> – (Any, optional): Contains a list of arguments that are
passed  to <cite>attribution_method</cite> attribution algorithm.
Any additional arguments that should be used for the
chosen attribution method should be included here.
For instance, such arguments include
<cite>additional_forward_args</cite> and <cite>baselines</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><dl class="simple">
<dt><strong>attributions</strong> (<em>tensor</em> or tuple of <em>tensors</em>):</dt><dd><p>Attribution with
respect to each input feature. attributions will always be
the same size as the provided inputs, with each value
providing the attribution of the corresponding input index.
If a single tensor is provided as inputs, a single tensor
is returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>delta</strong> (<em>float</em>, returned if return_convergence_delta=True):</dt><dd><p>Approximation error computed by the
attribution algorithm. Not all attribution algorithms
return delta value. It is computed only for some
algorithms, e.g. integrated gradients.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>attributions</strong> or 2-element tuple of <strong>attributions</strong>, <strong>delta</strong></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.TimeForwardTunnel.has_convergence_delta">
<span class="sig-name descname"><span class="pre">has_convergence_delta</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="reference internal" href="_modules/tint/attr/time_forward_tunnel.html#TimeForwardTunnel.has_convergence_delta"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.TimeForwardTunnel.has_convergence_delta" title="Permalink to this definition">¶</a></dt>
<dd><p>This method informs the user whether the attribution algorithm provides
a convergence delta (aka an approximation error) or not. Convergence
delta may serve as a proxy of correctness of attribution algorithm’s
approximation. If deriving attribution class provides a
<cite>compute_convergence_delta</cite> method, it should
override both <cite>compute_convergence_delta</cite> and <cite>has_convergence_delta</cite> methods.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Returns whether the attribution algorithm
provides a convergence delta (aka approximation error) or not.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="attr_models.html" class="btn btn-neutral float-right" title="Attribution Models" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="install.html" class="btn btn-neutral float-left" title="Installation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2022, Joseph Enguehard.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>