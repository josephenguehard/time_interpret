<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Attribution Methods &mdash; Time Interpret 0.3.0 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="_static/sphinx_paramlinks.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
        <script src="_static/clipboard.min.js"></script>
        <script src="_static/copybutton.js"></script>
        <script src="_static/toggleprompt.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Attribution Models" href="attr_models.html" />
    <link rel="prev" title="Installation" href="install.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            Time Interpret
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="install.html">Installation</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Attribution Methods</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#summary">Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-tint.attr">Detailed classes and methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.AugmentedOcclusion"><code class="docutils literal notranslate"><span class="pre">AugmentedOcclusion</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.AugmentedOcclusion.attribute"><code class="docutils literal notranslate"><span class="pre">AugmentedOcclusion.attribute()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.BayesKernelShap"><code class="docutils literal notranslate"><span class="pre">BayesKernelShap</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.BayesKernelShap.attribute"><code class="docutils literal notranslate"><span class="pre">BayesKernelShap.attribute()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.BayesLime"><code class="docutils literal notranslate"><span class="pre">BayesLime</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.BayesLime.attribute"><code class="docutils literal notranslate"><span class="pre">BayesLime.attribute()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.DiscretetizedIntegratedGradients"><code class="docutils literal notranslate"><span class="pre">DiscretetizedIntegratedGradients</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.DiscretetizedIntegratedGradients.attribute"><code class="docutils literal notranslate"><span class="pre">DiscretetizedIntegratedGradients.attribute()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.DynaMask"><code class="docutils literal notranslate"><span class="pre">DynaMask</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.DynaMask.attribute"><code class="docutils literal notranslate"><span class="pre">DynaMask.attribute()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.ExtremalMask"><code class="docutils literal notranslate"><span class="pre">ExtremalMask</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.ExtremalMask.attribute"><code class="docutils literal notranslate"><span class="pre">ExtremalMask.attribute()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.FeatureAblation"><code class="docutils literal notranslate"><span class="pre">FeatureAblation</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.FeatureAblation.attribute"><code class="docutils literal notranslate"><span class="pre">FeatureAblation.attribute()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.Fit"><code class="docutils literal notranslate"><span class="pre">Fit</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.Fit.attribute"><code class="docutils literal notranslate"><span class="pre">Fit.attribute()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.Fit.representation"><code class="docutils literal notranslate"><span class="pre">Fit.representation()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.GeodesicIntegratedGradients"><code class="docutils literal notranslate"><span class="pre">GeodesicIntegratedGradients</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.GeodesicIntegratedGradients.attribute"><code class="docutils literal notranslate"><span class="pre">GeodesicIntegratedGradients.attribute()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.GeodesicIntegratedGradients.compute_curvature"><code class="docutils literal notranslate"><span class="pre">GeodesicIntegratedGradients.compute_curvature()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.GeodesicIntegratedGradients.has_convergence_delta"><code class="docutils literal notranslate"><span class="pre">GeodesicIntegratedGradients.has_convergence_delta()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.GuidedIntegratedGradients"><code class="docutils literal notranslate"><span class="pre">GuidedIntegratedGradients</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.GuidedIntegratedGradients.attribute"><code class="docutils literal notranslate"><span class="pre">GuidedIntegratedGradients.attribute()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.GuidedIntegratedGradients.has_convergence_delta"><code class="docutils literal notranslate"><span class="pre">GuidedIntegratedGradients.has_convergence_delta()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.LofKernelShap"><code class="docutils literal notranslate"><span class="pre">LofKernelShap</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.LofLime"><code class="docutils literal notranslate"><span class="pre">LofLime</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.NonLinearitiesTunnel"><code class="docutils literal notranslate"><span class="pre">NonLinearitiesTunnel</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.NonLinearitiesTunnel.attribute"><code class="docutils literal notranslate"><span class="pre">NonLinearitiesTunnel.attribute()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.NonLinearitiesTunnel.has_convergence_delta"><code class="docutils literal notranslate"><span class="pre">NonLinearitiesTunnel.has_convergence_delta()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.Occlusion"><code class="docutils literal notranslate"><span class="pre">Occlusion</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.Occlusion.attribute"><code class="docutils literal notranslate"><span class="pre">Occlusion.attribute()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.Retain"><code class="docutils literal notranslate"><span class="pre">Retain</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.Retain.attribute"><code class="docutils literal notranslate"><span class="pre">Retain.attribute()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.Retain.representation"><code class="docutils literal notranslate"><span class="pre">Retain.representation()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.SequentialIntegratedGradients"><code class="docutils literal notranslate"><span class="pre">SequentialIntegratedGradients</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.SequentialIntegratedGradients.attribute"><code class="docutils literal notranslate"><span class="pre">SequentialIntegratedGradients.attribute()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.SequentialIntegratedGradients.has_convergence_delta"><code class="docutils literal notranslate"><span class="pre">SequentialIntegratedGradients.has_convergence_delta()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.TSRTunnel"><code class="docutils literal notranslate"><span class="pre">TSRTunnel</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.TSRTunnel.attribute"><code class="docutils literal notranslate"><span class="pre">TSRTunnel.attribute()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.TSRTunnel.has_convergence_delta"><code class="docutils literal notranslate"><span class="pre">TSRTunnel.has_convergence_delta()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.TemporalAugmentedOcclusion"><code class="docutils literal notranslate"><span class="pre">TemporalAugmentedOcclusion</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.TemporalAugmentedOcclusion.attribute"><code class="docutils literal notranslate"><span class="pre">TemporalAugmentedOcclusion.attribute()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.TemporalIntegratedGradients"><code class="docutils literal notranslate"><span class="pre">TemporalIntegratedGradients</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.TemporalIntegratedGradients.attribute"><code class="docutils literal notranslate"><span class="pre">TemporalIntegratedGradients.attribute()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.TemporalOcclusion"><code class="docutils literal notranslate"><span class="pre">TemporalOcclusion</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.TemporalOcclusion.attribute"><code class="docutils literal notranslate"><span class="pre">TemporalOcclusion.attribute()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#tint.attr.TimeForwardTunnel"><code class="docutils literal notranslate"><span class="pre">TimeForwardTunnel</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.TimeForwardTunnel.attribute"><code class="docutils literal notranslate"><span class="pre">TimeForwardTunnel.attribute()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#tint.attr.TimeForwardTunnel.has_convergence_delta"><code class="docutils literal notranslate"><span class="pre">TimeForwardTunnel.has_convergence_delta()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="attr_models.html">Attribution Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="datasets.html">Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="metrics.html">Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="metrics_weights.html">Metrics Weights</a></li>
<li class="toctree-l1"><a class="reference internal" href="white_box_metrics.html">White Box Metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="models.html">Models</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Time Interpret</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Attribution Methods</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/attr.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="attribution-methods">
<h1>Attribution Methods<a class="headerlink" href="#attribution-methods" title="Permalink to this heading"></a></h1>
<p>time_interpret expands on Captum by providing time series specific
attribution methods. These methods are listed below:</p>
<section id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this heading"></a></h2>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#tint.attr.AugmentedOcclusion" title="tint.attr.AugmentedOcclusion"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.AugmentedOcclusion</span></code></a>(forward_func, data)</p></td>
<td><p>Augmented Occlusion by sampling the baseline from a bootstrapped distribution.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tint.attr.BayesKernelShap" title="tint.attr.BayesKernelShap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.BayesKernelShap</span></code></a>(forward_func[, ...])</p></td>
<td><p>Bayesian version of KernelShap.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tint.attr.BayesLime" title="tint.attr.BayesLime"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.BayesLime</span></code></a>(forward_func[, ...])</p></td>
<td><p>Bayesian version of Lime.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tint.attr.DiscretetizedIntegratedGradients" title="tint.attr.DiscretetizedIntegratedGradients"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.DiscretetizedIntegratedGradients</span></code></a>(...)</p></td>
<td><p>Discretetized Integrated Gradients.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tint.attr.DynaMask" title="tint.attr.DynaMask"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.DynaMask</span></code></a>(forward_func)</p></td>
<td><p>Dynamic masks.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tint.attr.ExtremalMask" title="tint.attr.ExtremalMask"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.ExtremalMask</span></code></a>(forward_func)</p></td>
<td><p>Extremal masks.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tint.attr.FeatureAblation" title="tint.attr.FeatureAblation"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.FeatureAblation</span></code></a>(forward_func)</p></td>
<td><p>A perturbation based approach to computing attribution, involving replacing each input feature with a given baseline / reference, and computing the difference in output.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tint.attr.Fit" title="tint.attr.Fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.Fit</span></code></a>(forward_func[, generator, ...])</p></td>
<td><p>Feature Importance in Time.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tint.attr.GeodesicIntegratedGradients" title="tint.attr.GeodesicIntegratedGradients"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.GeodesicIntegratedGradients</span></code></a>(...[, ...])</p></td>
<td><p>Geodesic Integrated Gradients.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tint.attr.GuidedIntegratedGradients" title="tint.attr.GuidedIntegratedGradients"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.GuidedIntegratedGradients</span></code></a>(forward_func)</p></td>
<td><p>Guided Integrated Gradients.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tint.attr.LofKernelShap" title="tint.attr.LofKernelShap"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.LofKernelShap</span></code></a>(forward_func, embeddings)</p></td>
<td><p>Local Outlier Factor Kernel Shap.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tint.attr.LofLime" title="tint.attr.LofLime"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.LofLime</span></code></a>(forward_func, embeddings)</p></td>
<td><p>Local Outlier Factor Lime.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tint.attr.NonLinearitiesTunnel" title="tint.attr.NonLinearitiesTunnel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.NonLinearitiesTunnel</span></code></a>(...)</p></td>
<td><p>Replace non linearities (or any module) with others before running an attribution method.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tint.attr.Occlusion" title="tint.attr.Occlusion"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.Occlusion</span></code></a>(forward_func)</p></td>
<td><p>A perturbation based approach to compute attribution, involving replacing each contiguous rectangular region with a given baseline / reference, and computing the difference in output.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tint.attr.Retain" title="tint.attr.Retain"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.Retain</span></code></a>([forward_func, retain, ...])</p></td>
<td><p>Retain explainer method.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tint.attr.SequentialIntegratedGradients" title="tint.attr.SequentialIntegratedGradients"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.SequentialIntegratedGradients</span></code></a>(...)</p></td>
<td><p>Sequential Integrated Gradients.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tint.attr.TemporalAugmentedOcclusion" title="tint.attr.TemporalAugmentedOcclusion"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.TemporalAugmentedOcclusion</span></code></a>(...[, ...])</p></td>
<td><p>Temporal Augmented Occlusion.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tint.attr.TemporalIntegratedGradients" title="tint.attr.TemporalIntegratedGradients"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.TemporalIntegratedGradients</span></code></a>(...[, ...])</p></td>
<td><p>Temporal Integrated Gradients.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tint.attr.TemporalOcclusion" title="tint.attr.TemporalOcclusion"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.TemporalOcclusion</span></code></a>(forward_func)</p></td>
<td><p>Temporal Occlusion.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#tint.attr.TimeForwardTunnel" title="tint.attr.TimeForwardTunnel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.TimeForwardTunnel</span></code></a>(attribution_method)</p></td>
<td><p>Time Forward Tunnel.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#tint.attr.TSRTunnel" title="tint.attr.TSRTunnel"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tint.attr.TSRTunnel</span></code></a>(attribution_method)</p></td>
<td><p>Two-step temporal saliency rescaling Tunnel.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="module-tint.attr">
<span id="detailed-classes-and-methods"></span><h2>Detailed classes and methods<a class="headerlink" href="#module-tint.attr" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.AugmentedOcclusion">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">AugmentedOcclusion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_sampling</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_temporal</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/augmented_occlusion.html#AugmentedOcclusion"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.AugmentedOcclusion" title="Permalink to this definition"></a></dt>
<dd><p>Augmented Occlusion by sampling the baseline from a bootstrapped
distribution.</p>
<p>Instead of replacing occulted data by zero, this method samples data from
a distribution, which replace occulted data. The resulted occulted data
should be closer to the actual data as a result, limiting the amount of
out of distribution samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.AugmentedOcclusion.params.forward_func"></span><strong>forward_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.AugmentedOcclusion.params.forward_func">¶</a> (<em>callable</em>) – The forward function of the model or
any modification of it.</p></li>
<li><p><span class="target" id="tint.attr.AugmentedOcclusion.params.data"></span><strong>data</strong><a class="paramlink headerlink reference internal" href="#tint.attr.AugmentedOcclusion.params.data">¶</a> (<em>tuple</em><em>, </em><em>Tensor</em>) – The data from which the baselines are sampled.
The shape of the data must be the same as the inputs, except
on the first dimension.</p></li>
<li><p><span class="target" id="tint.attr.AugmentedOcclusion.params.n_sampling"></span><strong>n_sampling</strong><a class="paramlink headerlink reference internal" href="#tint.attr.AugmentedOcclusion.params.n_sampling">¶</a> (<em>int</em>) – Number of sampling to run for each occlusion.
Default: 1</p></li>
<li><p><span class="target" id="tint.attr.AugmentedOcclusion.params.is_temporal"></span><strong>is_temporal</strong><a class="paramlink headerlink reference internal" href="#tint.attr.AugmentedOcclusion.params.is_temporal">¶</a> (<em>bool</em>) – Whether the data is temporal or not.
If <code class="docutils literal notranslate"><span class="pre">True</span></code>, the data will be ablated to the inputs
on the temporal dimension (dimension 1).
Default: False</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://arxiv.org/abs/2003.02821">What went wrong and when? Instance-wise Feature Importance for Time-series Models</a></p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">AugmentedOcclusion</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.models</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">AugmentedOcclusion</span><span class="p">(</span><span class="n">mlp</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.AugmentedOcclusion.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sliding_window_shapes</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">perturbations_per_eval</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attributions_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></span><a class="reference internal" href="_modules/tint/attr/augmented_occlusion.html#AugmentedOcclusion.attribute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.AugmentedOcclusion.attribute" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.AugmentedOcclusion.attribute.params.inputs"></span><strong>inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.AugmentedOcclusion.attribute.params.inputs">¶</a> (<em>tensor</em><em> or </em><em>tuple</em><em> of </em><em>tensors</em>) – Input for which occlusion
attributions are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.
If forward_func takes multiple tensors as input, a tuple
of the input tensors should be provided. It is assumed
that for all given input tensors, dimension 0 corresponds
to the number of examples (aka batch size), and if
multiple input tensors are provided, the examples must
be aligned appropriately.</p></li>
<li><p><span class="target" id="tint.attr.AugmentedOcclusion.attribute.params.sliding_window_shapes"></span><strong>sliding_window_shapes</strong><a class="paramlink headerlink reference internal" href="#tint.attr.AugmentedOcclusion.attribute.params.sliding_window_shapes">¶</a> (<em>tuple</em><em> or </em><em>tuple</em><em> of </em><em>tuples</em>) – Shape of patch
(hyperrectangle) to occlude each input. For a single
input tensor, this must be a tuple of length equal to the
number of dimensions of the input tensor - 1, defining
the dimensions of the patch. If the input tensor is 1-d,
this should be an empty tuple. For multiple input tensors,
this must be a tuple containing one tuple for each input
tensor defining the dimensions of the patch for that
input tensor, as described for the single tensor case.</p></li>
<li><p><span class="target" id="tint.attr.AugmentedOcclusion.attribute.params.strides"></span><strong>strides</strong><a class="paramlink headerlink reference internal" href="#tint.attr.AugmentedOcclusion.attribute.params.strides">¶</a> (<em>int</em><em> or </em><em>tuple</em><em> or </em><em>tuple</em><em> of </em><em>ints</em><em> or </em><em>tuple</em><em> of </em><em>tuples</em><em>, </em><em>optional</em>) – This defines the step by which the occlusion hyperrectangle
should be shifted by in each direction for each iteration.
For a single tensor input, this can be either a single
integer, which is used as the step size in each direction,
or a tuple of integers matching the number of dimensions
in the occlusion shape, defining the step size in the
corresponding dimension. For multiple tensor inputs, this
can be either a tuple of integers, one for each input
tensor (used for all dimensions of the corresponding
tensor), or a tuple of tuples, providing the stride per
dimension for each tensor.
To ensure that all inputs are covered by at least one
sliding window, the stride for any dimension must be
&lt;= the corresponding sliding window dimension if the
sliding window dimension is less than the input
dimension.
If None is provided, a stride of 1 is used for each
dimension of each input tensor.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.AugmentedOcclusion.attribute.params.target"></span><strong>target</strong><a class="paramlink headerlink reference internal" href="#tint.attr.AugmentedOcclusion.attribute.params.target">¶</a> (<em>int</em><em>, </em><em>tuple</em><em>, </em><em>tensor</em><em> or </em><em>list</em><em>, </em><em>optional</em>) – <p>Output indices for
which difference is computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><p>a single integer or a tensor containing a single
integer, which is applied to all input examples</p></li>
<li><p>a list of integers or a 1D tensor, with length matching
the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p></li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><p>A single tuple, which contains #output_dims - 1
elements. This target index is applied to all examples.</p></li>
<li><p>A list of tuples with length equal to the number of
examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p></li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.AugmentedOcclusion.attribute.params.additional_forward_args"></span><strong>additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.AugmentedOcclusion.attribute.params.additional_forward_args">¶</a> (<em>any</em><em>, </em><em>optional</em>) – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a
tuple containing multiple additional arguments including
tensors or any arbitrary python types. These arguments
are provided to forward_func in order following the
arguments in inputs.
For a tensor, the first dimension of the tensor must
correspond to the number of examples. For all other types,
the given argument is used for all forward evaluations.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.AugmentedOcclusion.attribute.params.perturbations_per_eval"></span><strong>perturbations_per_eval</strong><a class="paramlink headerlink reference internal" href="#tint.attr.AugmentedOcclusion.attribute.params.perturbations_per_eval">¶</a> (<em>int</em><em>, </em><em>optional</em>) – Allows multiple occlusions
to be included in one batch (one call to forward_fn).
By default, perturbations_per_eval is 1, so each occlusion
is processed individually.
Each forward pass will contain a maximum of
perturbations_per_eval * #examples samples.
For DataParallel models, each batch is split among the
available devices, so evaluations on each available
device contain at most
(perturbations_per_eval * #examples) / num_devices
samples.
Default: 1</p></li>
<li><p><span class="target" id="tint.attr.AugmentedOcclusion.attribute.params.attributions_fn"></span><strong>attributions_fn</strong><a class="paramlink headerlink reference internal" href="#tint.attr.AugmentedOcclusion.attribute.params.attributions_fn">¶</a> (<em>Callable</em><em>, </em><em>optional</em>) – Applies a function to the
attributions before performing the weighted sum.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.AugmentedOcclusion.attribute.params.show_progress"></span><strong>show_progress</strong><a class="paramlink headerlink reference internal" href="#tint.attr.AugmentedOcclusion.attribute.params.show_progress">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – Displays the progress of
computation. It will try to use tqdm if available for
advanced features (e.g. time estimation). Otherwise, it
will fallback to a simple output of progress.
Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><dl class="simple">
<dt><strong>attributions</strong> (<em>tensor</em> or tuple of <em>tensors</em>):</dt><dd><p>The attributions with respect to each input feature.
Attributions will always be
the same size as the provided inputs, with each value
providing the attribution of the corresponding input index.
If a single tensor is provided as inputs, a single tensor
is returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>tensor</em> or tuple of <em>tensors</em> of <strong>attributions</strong></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.BayesKernelShap">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">BayesKernelShap</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">interpretable_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Model</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">percent</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">95</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/bayes.html#BayesKernelShap"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.BayesKernelShap" title="Permalink to this definition"></a></dt>
<dd><p>Bayesian version of KernelShap.</p>
<p>This method replace the linear regression of the original KernelShap with
a bayesian linear regression, allowing to model uncertainty in
explainability.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.BayesKernelShap.params.forward_func"></span><strong>forward_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.BayesKernelShap.params.forward_func">¶</a> (<em>callable</em>) – The forward function of the model or any
modification of it.</p></li>
<li><p><span class="target" id="tint.attr.BayesKernelShap.params.interpretable_model"></span><strong>interpretable_model</strong><a class="paramlink headerlink reference internal" href="#tint.attr.BayesKernelShap.params.interpretable_model">¶</a> (<em>Model</em>) – <p>Model object to train interpretable model.</p>
<p>This argument is optional and defaults to SkLearnBayesianRidge(),
which is a wrapper around the Bayesian Ridge in SkLearn.
This requires having sklearn version &gt;= 0.23 available.</p>
<p>Other predefined interpretable linear models are provided in
tint.attr.models.bayes_linear.</p>
<p>Alternatively, a custom model object must provide a <cite>fit</cite> method to
train the model, given a dataloader, with batches containing
three tensors:</p>
<ul>
<li><p>interpretable_inputs: Tensor
[2D num_samples x num_interp_features],</p></li>
<li><p>expected_outputs: Tensor [1D num_samples],</p></li>
<li><p>weights: Tensor [1D num_samples]</p></li>
</ul>
<p>The model object must also provide a <cite>representation</cite> method to
access the appropriate coefficients or representation of the
interpretable model after fitting.</p>
<p>Note that calling fit multiple times should retrain the
interpretable model, each attribution call reuses
the same given interpretable model object.</p>
<p>Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.BayesKernelShap.params.percent"></span><strong>percent</strong><a class="paramlink headerlink reference internal" href="#tint.attr.BayesKernelShap.params.percent">¶</a> (<em>int</em>) – <p>Percentage for the credible intervals. Must be between
0 and 100. Only used when no custom interpretable model is
passed. Otherwise, you must specify the percentage for
credible interval in the model definition:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr.models</span> <span class="kn">import</span> <span class="n">BLRRegression</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">BLRRegression</span><span class="p">(</span><span class="n">percent</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">BayesKernelShap</span><span class="p">(</span><span class="n">mlp</span><span class="p">,</span> <span class="n">interpretable_model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
<p>Default: 95</p>
</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://arxiv.org/abs/2008.05030">Reliable Post hoc Explanations: Modeling Uncertainty in Explainability</a></p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">BayesKernelShap</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.models</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">BayesKernelShap</span><span class="p">(</span><span class="n">mlp</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span><span class="p">,</span> <span class="n">credible_int</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.BayesKernelShap.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baselines</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_mask</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_samples</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">25</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">perturbations_per_eval</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_input_shape</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></span><a class="reference internal" href="_modules/tint/attr/bayes.html#BayesKernelShap.attribute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.BayesKernelShap.attribute" title="Permalink to this definition"></a></dt>
<dd><p>This method attributes the output of the model with given target index
(in case it is provided, otherwise it assumes that output is a
scalar) to the inputs of the model using the approach described above,
training an interpretable model based on KernelSHAP and returning a
representation of the interpretable model.</p>
<p>It is recommended to only provide a single example as input (tensors
with first dimension or batch size = 1). This is because LIME / KernelShap
is generally used for sample-based interpretability, training a separate
interpretable model to explain a model’s prediction on each individual example.</p>
<p>A batch of inputs can also be provided as inputs, similar to
other perturbation-based attribution methods. In this case, if forward_fn
returns a scalar per example, attributions will be computed for each
example independently, with a separate interpretable model trained for each
example. Note that provided similarity and perturbation functions will be
provided each example separately (first dimension = 1) in this case.
If forward_fn returns a scalar per batch (e.g. loss), attributions will
still be computed using a single interpretable model for the full batch.
In this case, similarity and perturbation functions will be provided the
same original input containing the full batch.</p>
<p>The number of interpretable features is determined from the provided
feature mask, or if none is provided, from the default feature mask,
which considers each scalar input as a separate feature. It is
generally recommended to provide a feature mask which groups features
into a small number of interpretable features / components (e.g.
superpixels in images).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.BayesKernelShap.attribute.params.inputs"></span><strong>inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.BayesKernelShap.attribute.params.inputs">¶</a> (<em>Tensor</em><em> or </em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>...</em><em>]</em>) – Input for which KernelShap
is computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.
If forward_func takes multiple tensors as input, a tuple
of the input tensors should be provided. It is assumed
that for all given input tensors, dimension 0 corresponds
to the number of examples, and if multiple input tensors
are provided, the examples must be aligned appropriately.</p></li>
<li><p><span class="target" id="tint.attr.BayesKernelShap.attribute.params.baselines"></span><strong>baselines</strong><a class="paramlink headerlink reference internal" href="#tint.attr.BayesKernelShap.attribute.params.baselines">¶</a> (<em>scalar</em><em>, </em><em>Tensor</em><em>, </em><em>tuple</em><em> of </em><em>scalar</em><em>, or </em><em>Tensor</em><em>, </em><em>optional</em>) – <p>Baselines define the reference value which replaces each
feature when the corresponding interpretable feature
is set to 0.
Baselines can be provided as:</p>
<ul>
<li><p>a single tensor, if inputs is a single tensor, with
exactly the same dimensions as inputs or the first
dimension is one and the remaining dimensions match
with inputs.</p></li>
<li><p>a single scalar, if inputs is a single tensor, which will
be broadcasted for each input value in input tensor.</p></li>
<li><p>a tuple of tensors or scalars, the baseline corresponding
to each tensor in the inputs’ tuple can be:</p>
<ul>
<li><p>either a tensor with matching dimensions to
corresponding tensor in the inputs’ tuple
or the first dimension is one and the remaining
dimensions match with the corresponding
input tensor.</p></li>
<li><p>or a scalar, corresponding to a tensor in the
inputs’ tuple. This scalar value is broadcasted
for corresponding input tensor.</p></li>
</ul>
</li>
</ul>
<p>In the cases when <cite>baselines</cite> is not provided, we internally
use zero scalar corresponding to each input tensor.
Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.BayesKernelShap.attribute.params.target"></span><strong>target</strong><a class="paramlink headerlink reference internal" href="#tint.attr.BayesKernelShap.attribute.params.target">¶</a> (<em>int</em><em>, </em><em>tuple</em><em>, </em><em>Tensor</em><em>, or </em><em>list</em><em>, </em><em>optional</em>) – <p>Output indices for
which surrogate model is trained
(for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><p>a single integer or a tensor containing a single
integer, which is applied to all input examples</p></li>
<li><p>a list of integers or a 1D tensor, with length matching
the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p></li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><p>A single tuple, which contains #output_dims - 1
elements. This target index is applied to all examples.</p></li>
<li><p>A list of tuples with length equal to the number of
examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p></li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.BayesKernelShap.attribute.params.additional_forward_args"></span><strong>additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.BayesKernelShap.attribute.params.additional_forward_args">¶</a> (<em>Any</em><em>, </em><em>optional</em>) – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a
tuple containing multiple additional arguments including
tensors or any arbitrary python types. These arguments
are provided to forward_func in order following the
arguments in inputs.
For a tensor, the first dimension of the tensor must
correspond to the number of examples. It will be
repeated for each of <cite>n_steps</cite> along the integrated
path. For all other types, the given argument is used
for all forward evaluations.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.BayesKernelShap.attribute.params.feature_mask"></span><strong>feature_mask</strong><a class="paramlink headerlink reference internal" href="#tint.attr.BayesKernelShap.attribute.params.feature_mask">¶</a> (<em>Tensor</em><em> or </em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>...</em><em>]</em><em>, </em><em>optional</em>) – feature_mask defines a mask for the input, grouping
features which correspond to the same
interpretable feature. feature_mask
should contain the same number of tensors as inputs.
Each tensor should
be the same size as the corresponding input or
broadcastable to match the input tensor. Values across
all tensors should be integers in the range 0 to
num_interp_features - 1, and indices corresponding to the
same feature should have the same value.
Note that features are grouped across tensors
(unlike feature ablation and occlusion), so
if the same index is used in different tensors, those
features are still grouped and added simultaneously.
If None, then a feature mask is constructed which assigns
each scalar within a tensor as a separate feature.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.BayesKernelShap.attribute.params.n_samples"></span><strong>n_samples</strong><a class="paramlink headerlink reference internal" href="#tint.attr.BayesKernelShap.attribute.params.n_samples">¶</a> (<em>int</em><em>, </em><em>optional</em>) – The number of samples of the original
model used to train the surrogate interpretable model.
Default: <cite>50</cite> if <cite>n_samples</cite> is not provided.</p></li>
<li><p><span class="target" id="tint.attr.BayesKernelShap.attribute.params.perturbations_per_eval"></span><strong>perturbations_per_eval</strong><a class="paramlink headerlink reference internal" href="#tint.attr.BayesKernelShap.attribute.params.perturbations_per_eval">¶</a> (<em>int</em><em>, </em><em>optional</em>) – Allows multiple samples
to be processed simultaneously in one call to forward_fn.
Each forward pass will contain a maximum of
perturbations_per_eval * #examples samples.
For DataParallel models, each batch is split among the
available devices, so evaluations on each available
device contain at most
(perturbations_per_eval * #examples) / num_devices
samples.
If the forward function returns a single scalar per batch,
perturbations_per_eval must be set to 1.
Default: 1</p></li>
<li><p><span class="target" id="tint.attr.BayesKernelShap.attribute.params.return_input_shape"></span><strong>return_input_shape</strong><a class="paramlink headerlink reference internal" href="#tint.attr.BayesKernelShap.attribute.params.return_input_shape">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – Determines whether the returned
tensor(s) only contain the coefficients for each interp-
retable feature from the trained surrogate model, or
whether the returned attributions match the input shape.
When return_input_shape is True, the return type of attribute
matches the input shape, with each element containing the
coefficient of the corresponding interpretable feature.
All elements with the same value in the feature mask
will contain the same coefficient in the returned
attributions. If return_input_shape is False, a 1D
tensor is returned, containing only the coefficients
of the trained interpretable model, with length
num_interp_features.</p></li>
<li><p><span class="target" id="tint.attr.BayesKernelShap.attribute.params.show_progress"></span><strong>show_progress</strong><a class="paramlink headerlink reference internal" href="#tint.attr.BayesKernelShap.attribute.params.show_progress">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – Displays the progress of computation.
It will try to use tqdm if available for advanced features
(e.g. time estimation). Otherwise, it will fallback to
a simple output of progress.
Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><dl class="simple">
<dt><strong>attributions</strong> (<em>tensor</em> or tuple of <em>tensors</em>):</dt><dd><p>The attributions with respect to each input feature.
If return_input_shape = True, attributions will be
the same size as the provided inputs, with each value
providing the coefficient of the corresponding
interpretale feature.
If return_input_shape is False, a 1D
tensor is returned, containing only the coefficients
of the trained interpreatable models, with length
num_interp_features.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>credible_intervals</strong> (<em>tensor</em> or tuple of <em>tensors</em>):</dt><dd><p>The credible intervals associated with each attribution.
If return_input_shape = True, credible intervals will be
the same size as the provided inputs, with each value
providing the coefficient of the corresponding
interpretale feature.
If return_input_shape is False, a 1D
tensor is returned, containing only the credible intervals
of the trained interpreatable models, with length
num_interp_features.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>2-element tuple of <strong>attributions</strong>, <strong>credible_intervals</strong></p>
</dd>
</dl>
<dl>
<dt>Examples::</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># SimpleClassifier takes a single input tensor of size Nx4x4,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># and returns an Nx3 tensor of class probabilities.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">SimpleClassifier</span><span class="p">()</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Generating random input with size 1 x 4 x 4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Defining KernelShap interpreter</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ks</span> <span class="o">=</span> <span class="n">KernelShap</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Computes attribution, with each of the 4 x 4 = 16</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># features as a separate interpretable feature</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">ks</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Alternatively, we can group each 2x2 square of the inputs</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># as one &#39;interpretable&#39; feature and perturb them together.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># This can be done by creating a feature mask as follows, which</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># defines the feature groups, e.g.:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># +---+---+---+---+</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># | 0 | 0 | 1 | 1 |</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># +---+---+---+---+</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># | 0 | 0 | 1 | 1 |</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># +---+---+---+---+</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># | 2 | 2 | 3 | 3 |</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># +---+---+---+---+</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># | 2 | 2 | 3 | 3 |</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># +---+---+---+---+</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># With this mask, all inputs with the same value are set to their</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># baseline value, when the corresponding binary interpretable</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># feature is set to 0.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The attributions can be calculated as follows:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># feature mask has dimensions 1 x 4 x 4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feature_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                            <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]]])</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Computes KernelSHAP attributions with feature mask.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">ks</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">feature_mask</span><span class="o">=</span><span class="n">feature_mask</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.BayesLime">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">BayesLime</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">interpretable_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Model</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">similarity_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">perturb_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">percent</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">95</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/bayes.html#BayesLime"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.BayesLime" title="Permalink to this definition"></a></dt>
<dd><p>Bayesian version of Lime.</p>
<p>This method replace the linear regression of the original Lime with a
bayesian linear regression, allowing to model uncertainty in
explainability.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.BayesLime.params.forward_func"></span><strong>forward_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.BayesLime.params.forward_func">¶</a> (<em>callable</em>) – The forward function of the model or any
modification of it.</p></li>
<li><p><span class="target" id="tint.attr.BayesLime.params.interpretable_model"></span><strong>interpretable_model</strong><a class="paramlink headerlink reference internal" href="#tint.attr.BayesLime.params.interpretable_model">¶</a> (<em>Model</em>) – <p>Model object to train interpretable model.</p>
<p>This argument is optional and defaults to SkLearnBayesianRidge(),
which is a wrapper around the Bayesian Ridge in SkLearn.
This requires having sklearn version &gt;= 0.23 available.</p>
<p>Other predefined interpretable linear models are provided in
tint.attr.models.bayes_linear.</p>
<p>Alternatively, a custom model object must provide a <cite>fit</cite> method to
train the model, given a dataloader, with batches containing
three tensors:</p>
<ul>
<li><p>interpretable_inputs: Tensor
[2D num_samples x num_interp_features],</p></li>
<li><p>expected_outputs: Tensor [1D num_samples],</p></li>
<li><p>weights: Tensor [1D num_samples]</p></li>
</ul>
<p>The model object must also provide a <cite>representation</cite> method to
access the appropriate coefficients or representation of the
interpretable model after fitting.</p>
<p>Note that calling fit multiple times should retrain the
interpretable model, each attribution call reuses
the same given interpretable model object.</p>
<p>Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.BayesLime.params.similarity_func"></span><strong>similarity_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.BayesLime.params.similarity_func">¶</a> (<em>Callable</em><em>, </em><em>optional</em>) – <p>Function which takes a single sample
along with its corresponding interpretable representation
and returns the weight of the interpretable sample for
training the interpretable model.
This is often referred to as a similarity kernel.</p>
<p>This argument is optional and defaults to a function which
applies an exponential kernel to the cosine distance between
the original input and perturbed input, with a kernel width
of 1.0.</p>
<p>A similarity function applying an exponential
kernel to cosine / euclidean distances can be constructed
using the provided get_exp_kernel_similarity_function in
captum.attr._core.lime.</p>
<p>Alternately, a custom callable can also be provided.
The expected signature of this callable is:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">similarity_func</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="n">original_input</span><span class="p">:</span> <span class="n">Tensor</span> <span class="ow">or</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="n">perturbed_input</span><span class="p">:</span> <span class="n">Tensor</span> <span class="ow">or</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="n">perturbed_interpretable_input</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>       <span class="n">Tensor</span> <span class="p">[</span><span class="mi">2</span><span class="n">D</span> <span class="mi">1</span> <span class="n">x</span> <span class="n">num_interp_features</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span> <span class="ow">or</span> <span class="n">Tensor</span> <span class="n">containing</span> <span class="nb">float</span> <span class="n">scalar</span>
</pre></div>
</div>
<p>perturbed_input and original_input will be the same type and
contain tensors of the same shape, with original_input
being the same as the input provided when calling attribute.</p>
<p>kwargs includes baselines, feature_mask, num_interp_features
(integer, determined from feature mask).</p>
</p></li>
<li><p><span class="target" id="tint.attr.BayesLime.params.perturb_func"></span><strong>perturb_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.BayesLime.params.perturb_func">¶</a> (<em>Callable</em><em>, </em><em>optional</em>) – <p>Function which returns a single
sampled input, which is a binary vector of length
num_interp_features, or a generator of such tensors.</p>
<p>This function is optional, the default function returns
a binary vector where each element is selected
independently and uniformly at random. Custom
logic for selecting sampled binary vectors can
be implemented by providing a function with the
following expected signature:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">perturb_func</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="n">original_input</span><span class="p">:</span> <span class="n">Tensor</span> <span class="ow">or</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span> <span class="p">[</span><span class="n">Binary</span> <span class="mi">2</span><span class="n">D</span> <span class="n">Tensor</span> <span class="mi">1</span> <span class="n">x</span> <span class="n">num_interp_features</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span> <span class="ow">or</span> <span class="n">generator</span> <span class="n">yielding</span> <span class="n">such</span> <span class="n">tensors</span>
</pre></div>
</div>
<p>kwargs includes baselines, feature_mask, num_interp_features
(integer, determined from feature mask).</p>
</p></li>
<li><p><span class="target" id="tint.attr.BayesLime.params.percent"></span><strong>percent</strong><a class="paramlink headerlink reference internal" href="#tint.attr.BayesLime.params.percent">¶</a> (<em>int</em>) – <p>Percentage for the credible intervals. Must be between
0 and 100. Only used when no custom interpretable model is
passed. Otherwise, you must specify the percentage for
credible interval in the model definition:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr.models</span> <span class="kn">import</span> <span class="n">BLRRegression</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">BLRRegression</span><span class="p">(</span><span class="n">percent</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">BayesLime</span><span class="p">(</span><span class="n">mlp</span><span class="p">,</span> <span class="n">interpretable_model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
<p>Default: 95</p>
</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://arxiv.org/abs/2008.05030">Reliable Post hoc Explanations: Modeling Uncertainty in Explainability</a></p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">BayesLime</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.models</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">BayesLime</span><span class="p">(</span><span class="n">mlp</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span><span class="p">,</span> <span class="n">credible_int</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.BayesLime.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baselines</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_mask</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_samples</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">25</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">perturbations_per_eval</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_input_shape</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></span><a class="reference internal" href="_modules/tint/attr/bayes.html#BayesLime.attribute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.BayesLime.attribute" title="Permalink to this definition"></a></dt>
<dd><p>This method attributes the output of the model with given target index
(in case it is provided, otherwise it assumes that output is a
scalar) to the inputs of the model using the approach described above,
training an interpretable model and returning a representation of the
interpretable model.</p>
<p>It is recommended to only provide a single example as input (tensors
with first dimension or batch size = 1). This is because LIME is generally
used for sample-based interpretability, training a separate interpretable
model to explain a model’s prediction on each individual example.</p>
<p>A batch of inputs can also be provided as inputs, similar to
other perturbation-based attribution methods. In this case, if forward_fn
returns a scalar per example, attributions will be computed for each
example independently, with a separate interpretable model trained for each
example. Note that provided similarity and perturbation functions will be
provided each example separately (first dimension = 1) in this case.
If forward_fn returns a scalar per batch (e.g. loss), attributions will
still be computed using a single interpretable model for the full batch.
In this case, similarity and perturbation functions will be provided the
same original input containing the full batch.</p>
<p>The number of interpretable features is determined from the provided
feature mask, or if none is provided, from the default feature mask,
which considers each scalar input as a separate feature. It is
generally recommended to provide a feature mask which groups features
into a small number of interpretable features / components (e.g.
superpixels in images).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.BayesLime.attribute.params.inputs"></span><strong>inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.BayesLime.attribute.params.inputs">¶</a> (<em>Tensor</em><em> or </em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>...</em><em>]</em>) – Input for which LIME
is computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.
If forward_func takes multiple tensors as input, a tuple
of the input tensors should be provided. It is assumed
that for all given input tensors, dimension 0 corresponds
to the number of examples, and if multiple input tensors
are provided, the examples must be aligned appropriately.</p></li>
<li><p><span class="target" id="tint.attr.BayesLime.attribute.params.baselines"></span><strong>baselines</strong><a class="paramlink headerlink reference internal" href="#tint.attr.BayesLime.attribute.params.baselines">¶</a> (<em>scalar</em><em>, </em><em>Tensor</em><em>, </em><em>tuple</em><em> of </em><em>scalar</em><em>, or </em><em>Tensor</em><em>, </em><em>optional</em>) – <p>Baselines define reference value which replaces each
feature when the corresponding interpretable feature
is set to 0.
Baselines can be provided as:</p>
<ul>
<li><p>a single tensor, if inputs is a single tensor, with
exactly the same dimensions as inputs or the first
dimension is one and the remaining dimensions match
with inputs.</p></li>
<li><p>a single scalar, if inputs is a single tensor, which will
be broadcasted for each input value in input tensor.</p></li>
<li><p>a tuple of tensors or scalars, the baseline corresponding
to each tensor in the inputs’ tuple can be:</p>
<ul>
<li><p>either a tensor with matching dimensions to
corresponding tensor in the inputs’ tuple
or the first dimension is one and the remaining
dimensions match with the corresponding
input tensor.</p></li>
<li><p>or a scalar, corresponding to a tensor in the
inputs’ tuple. This scalar value is broadcasted
for corresponding input tensor.</p></li>
</ul>
</li>
</ul>
<p>In the cases when <cite>baselines</cite> is not provided, we internally
use zero scalar corresponding to each input tensor.
Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.BayesLime.attribute.params.target"></span><strong>target</strong><a class="paramlink headerlink reference internal" href="#tint.attr.BayesLime.attribute.params.target">¶</a> (<em>int</em><em>, </em><em>tuple</em><em>, </em><em>Tensor</em><em>, or </em><em>list</em><em>, </em><em>optional</em>) – <p>Output indices for
which surrogate model is trained
(for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><p>a single integer or a tensor containing a single
integer, which is applied to all input examples</p></li>
<li><p>a list of integers or a 1D tensor, with length matching
the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p></li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><p>A single tuple, which contains #output_dims - 1
elements. This target index is applied to all examples.</p></li>
<li><p>A list of tuples with length equal to the number of
examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p></li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.BayesLime.attribute.params.additional_forward_args"></span><strong>additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.BayesLime.attribute.params.additional_forward_args">¶</a> (<em>Any</em><em>, </em><em>optional</em>) – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a
tuple containing multiple additional arguments including
tensors or any arbitrary python types. These arguments
are provided to forward_func in order following the
arguments in inputs.
For a tensor, the first dimension of the tensor must
correspond to the number of examples. It will be
repeated for each of <cite>n_steps</cite> along the integrated
path. For all other types, the given argument is used
for all forward evaluations.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.BayesLime.attribute.params.feature_mask"></span><strong>feature_mask</strong><a class="paramlink headerlink reference internal" href="#tint.attr.BayesLime.attribute.params.feature_mask">¶</a> (<em>Tensor</em><em> or </em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>...</em><em>]</em><em>, </em><em>optional</em>) – feature_mask defines a mask for the input, grouping
features which correspond to the same
interpretable feature. feature_mask
should contain the same number of tensors as inputs.
Each tensor should
be the same size as the corresponding input or
broadcastable to match the input tensor. Values across
all tensors should be integers in the range 0 to
num_interp_features - 1, and indices corresponding to the
same feature should have the same value.
Note that features are grouped across tensors
(unlike feature ablation and occlusion), so
if the same index is used in different tensors, those
features are still grouped and added simultaneously.
If None, then a feature mask is constructed which assigns
each scalar within a tensor as a separate feature.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.BayesLime.attribute.params.n_samples"></span><strong>n_samples</strong><a class="paramlink headerlink reference internal" href="#tint.attr.BayesLime.attribute.params.n_samples">¶</a> (<em>int</em><em>, </em><em>optional</em>) – The number of samples of the original
model used to train the surrogate interpretable model.
Default: <cite>50</cite> if <cite>n_samples</cite> is not provided.</p></li>
<li><p><span class="target" id="tint.attr.BayesLime.attribute.params.perturbations_per_eval"></span><strong>perturbations_per_eval</strong><a class="paramlink headerlink reference internal" href="#tint.attr.BayesLime.attribute.params.perturbations_per_eval">¶</a> (<em>int</em><em>, </em><em>optional</em>) – Allows multiple samples
to be processed simultaneously in one call to forward_fn.
Each forward pass will contain a maximum of
perturbations_per_eval * #examples samples.
For DataParallel models, each batch is split among the
available devices, so evaluations on each available
device contain at most
(perturbations_per_eval * #examples) / num_devices
samples.
If the forward function returns a single scalar per batch,
perturbations_per_eval must be set to 1.
Default: 1</p></li>
<li><p><span class="target" id="tint.attr.BayesLime.attribute.params.return_input_shape"></span><strong>return_input_shape</strong><a class="paramlink headerlink reference internal" href="#tint.attr.BayesLime.attribute.params.return_input_shape">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – Determines whether the returned
tensor(s) only contain the coefficients for each interp-
retable feature from the trained surrogate model, or
whether the returned attributions match the input shape.
When return_input_shape is True, the return type of attribute
matches the input shape, with each element containing the
coefficient of the corresponding interpretale feature.
All elements with the same value in the feature mask
will contain the same coefficient in the returned
attributions. If return_input_shape is False, a 1D
tensor is returned, containing only the coefficients
of the trained interpreatable models, with length
num_interp_features.</p></li>
<li><p><span class="target" id="tint.attr.BayesLime.attribute.params.show_progress"></span><strong>show_progress</strong><a class="paramlink headerlink reference internal" href="#tint.attr.BayesLime.attribute.params.show_progress">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – Displays the progress of computation.
It will try to use tqdm if available for advanced features
(e.g. time estimation). Otherwise, it will fallback to
a simple output of progress.
Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><dl class="simple">
<dt><strong>attributions</strong> (<em>tensor</em> or tuple of <em>tensors</em>):</dt><dd><p>The attributions with respect to each input feature.
If return_input_shape = True, attributions will be
the same size as the provided inputs, with each value
providing the coefficient of the corresponding
interpretale feature.
If return_input_shape is False, a 1D
tensor is returned, containing only the coefficients
of the trained interpreatable models, with length
num_interp_features.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>credible_intervals</strong> (<em>tensor</em> or tuple of <em>tensors</em>):</dt><dd><p>The credible intervals associated with each attribution.
If return_input_shape = True, credible intervals will be
the same size as the provided inputs, with each value
providing the coefficient of the corresponding
interpretale feature.
If return_input_shape is False, a 1D
tensor is returned, containing only the credible intervals
of the trained interpreatable models, with length
num_interp_features.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>2-element tuple of <strong>attributions</strong>, <strong>credible_intervals</strong></p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># SimpleClassifier takes a single input tensor of size Nx4x4,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># and returns an Nx3 tensor of class probabilities.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">SimpleClassifier</span><span class="p">()</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Generating random input with size 1 x 4 x 4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Defining Lime interpreter</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lime</span> <span class="o">=</span> <span class="n">Lime</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Computes attribution, with each of the 4 x 4 = 16</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># features as a separate interpretable feature</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">lime</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Alternatively, we can group each 2x2 square of the inputs</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># as one &#39;interpretable&#39; feature and perturb them together.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># This can be done by creating a feature mask as follows, which</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># defines the feature groups, e.g.:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># +---+---+---+---+</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># | 0 | 0 | 1 | 1 |</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># +---+---+---+---+</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># | 0 | 0 | 1 | 1 |</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># +---+---+---+---+</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># | 2 | 2 | 3 | 3 |</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># +---+---+---+---+</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># | 2 | 2 | 3 | 3 |</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># +---+---+---+---+</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># With this mask, all inputs with the same value are set to their</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># baseline value, when the corresponding binary interpretable</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># feature is set to 0.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The attributions can be calculated as follows:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># feature mask has dimensions 1 x 4 x 4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feature_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                            <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]]])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Computes interpretable model and returning attributions</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># matching input shape.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">lime</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">feature_mask</span><span class="o">=</span><span class="n">feature_mask</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.DiscretetizedIntegratedGradients">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">DiscretetizedIntegratedGradients</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multiply_by_inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/discretised_ig.html#DiscretetizedIntegratedGradients"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.DiscretetizedIntegratedGradients" title="Permalink to this definition"></a></dt>
<dd><p>Discretetized Integrated Gradients.</p>
<p>This method discretizes the path between an input and a reference
baseline. It was developed for text data and language models, to handle
the discreteness of the word embedding space.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.DiscretetizedIntegratedGradients.params.forward_func"></span><strong>forward_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.DiscretetizedIntegratedGradients.params.forward_func">¶</a> (<em>callable</em>) – The forward function of the model or any
modification of it</p></li>
<li><p><span class="target" id="tint.attr.DiscretetizedIntegratedGradients.params.multiply_by_inputs"></span><strong>multiply_by_inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.DiscretetizedIntegratedGradients.params.multiply_by_inputs">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – <p>Indicates whether to factor
model inputs’ multiplier in the final attribution scores.
In the literature this is also known as local vs global
attribution. If inputs’ multiplier isn’t factored in,
then that type of attribution method is also called local
attribution. If it is, then that type of attribution
method is called global.
More detailed can be found here:
<a class="reference external" href="https://arxiv.org/abs/1711.06104">https://arxiv.org/abs/1711.06104</a></p>
<p>In case of integrated gradients, if <cite>multiply_by_inputs</cite>
is set to True, final sensitivity scores are being multiplied by
(inputs - baselines).</p>
</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<ol class="arabic simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/2108.13654">Discretized Integrated Gradients for Explaining Language Models</a></p></li>
<li><p><a class="reference external" href="https://github.com/INK-USC/DIG">https://github.com/INK-USC/DIG</a></p></li>
</ol>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">DiscretetizedIntegratedGradients</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.models</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">DiscretetizedIntegratedGradients</span><span class="p">(</span><span class="n">mlp</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.DiscretetizedIntegratedGradients.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scaled_features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_convergence_delta</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">TensorOrTupleOfTensorsGeneric</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">TensorOrTupleOfTensorsGeneric</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/tint/attr/discretised_ig.html#DiscretetizedIntegratedGradients.attribute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.DiscretetizedIntegratedGradients.attribute" title="Permalink to this definition"></a></dt>
<dd><p>Attribute method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.DiscretetizedIntegratedGradients.attribute.params.scaled_features"></span><strong>scaled_features</strong><a class="paramlink headerlink reference internal" href="#tint.attr.DiscretetizedIntegratedGradients.attribute.params.scaled_features">¶</a> – (tensor, tuple):  Input for which integrated
gradients are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.
If forward_func takes multiple tensors as input, a tuple
of the input tensors should be provided. It is assumed
that for all given input tensors, dimension 0 corresponds
to the number of examples, and if multiple input tensors
are provided, the examples must be aligned appropriately.</p></li>
<li><p><span class="target" id="tint.attr.DiscretetizedIntegratedGradients.attribute.params.target"></span><strong>target</strong><a class="paramlink headerlink reference internal" href="#tint.attr.DiscretetizedIntegratedGradients.attribute.params.target">¶</a> (<em>int</em><em>, </em><em>int</em><em>, </em><em>tuple</em><em>, </em><em>tensor</em><em>, </em><em>list</em>) – <p>Output indices for
which gradients are computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><p>a single integer or a tensor containing a single
integer, which is applied to all input examples</p></li>
<li><p>a list of integers or a 1D tensor, with length matching
the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p></li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><p>A single tuple, which contains #output_dims - 1
elements. This target index is applied to all examples.</p></li>
<li><p>A list of tuples with length equal to the number of
examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p></li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.DiscretetizedIntegratedGradients.attribute.params.additional_forward_args"></span><strong>additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.DiscretetizedIntegratedGradients.attribute.params.additional_forward_args">¶</a> (<em>Any</em>) – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a
tuple containing multiple additional arguments including
tensors or any arbitrary python types. These arguments
are provided to forward_func in order following the
arguments in inputs.
For a tensor, the first dimension of the tensor must
correspond to the number of examples. It will be
repeated for each of <cite>n_steps</cite> along the integrated
path. For all other types, the given argument is used
for all forward evaluations.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.DiscretetizedIntegratedGradients.attribute.params.n_steps"></span><strong>n_steps</strong><a class="paramlink headerlink reference internal" href="#tint.attr.DiscretetizedIntegratedGradients.attribute.params.n_steps">¶</a> – The number of steps used by the approximation
method. Default: 50.</p></li>
<li><p><span class="target" id="tint.attr.DiscretetizedIntegratedGradients.attribute.params.return_convergence_delta"></span><strong>return_convergence_delta</strong><a class="paramlink headerlink reference internal" href="#tint.attr.DiscretetizedIntegratedGradients.attribute.params.return_convergence_delta">¶</a> – Indicates whether to return
convergence delta or not. If <cite>return_convergence_delta</cite>
is set to True convergence delta will be returned in
a tuple following attributions.
Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><dl class="simple">
<dt><strong>attributions</strong> (<em>tensor</em> or tuple of <em>tensors</em>):</dt><dd><p>Integrated gradients with respect to each input feature.
attributions will always be the same size as the provided
inputs, with each value providing the attribution of the
corresponding input index.
If a single tensor is provided as inputs, a single tensor is
returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>delta</strong> (<em>tensor</em>, returned if return_convergence_delta=True):</dt><dd><p>The difference between the total approximated and true
integrated gradients. This is computed using the property
that the total sum of forward_func(inputs) -
forward_func(baselines) must equal the total sum of the
integrated gradient.
Delta is calculated per example, meaning that the number of
elements in returned delta tensor is equal to the number of
of examples in inputs.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>attributions</strong> or 2-element tuple of <strong>attributions</strong>, <strong>delta</strong></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.DynaMask">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">DynaMask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/dynamic_masks.html#DynaMask"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.DynaMask" title="Permalink to this definition"></a></dt>
<dd><p>Dynamic masks.</p>
<p>This method aims to explain time series data, by learning a mask
representing features importance. This method was inspired from
Fong et al., and can be used in “preservation game” mode: trying to keep
the closest predictions, compared with unperturebed data, with the
minimal number of features, or in “deletion game” mode, trying to get the
furthest predictions by removing the minimal number of features.</p>
<p>This implementation batchify the original method by leanrning in parallel
multiple inputs and multiple <code class="docutils literal notranslate"><span class="pre">keep_ratio</span></code> (called <code class="docutils literal notranslate"><span class="pre">mask_group</span></code> in the
original implementation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="target" id="tint.attr.DynaMask.params.forward_func"></span><strong>forward_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.DynaMask.params.forward_func">¶</a> (<em>callable</em>) – The forward function of the model or any
modification of it.</p>
</dd>
</dl>
<p class="rubric">References</p>
<ol class="arabic simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/2106.05303">Explaining Time Series Predictions with Dynamic Masks</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1910.08485">Understanding Deep Networks via Extremal Perturbations and Smooth Masks</a></p></li>
</ol>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">DynaMask</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.models</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">DynaMask</span><span class="p">(</span><span class="n">mlp</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.DynaMask.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Trainer</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_net</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="attr_models.html#tint.attr.models.MaskNet" title="tint.attr.models.mask.MaskNet"><span class="pre">MaskNet</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temporal_additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_temporal_attributions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_best_ratio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></span><a class="reference internal" href="_modules/tint/attr/dynamic_masks.html#DynaMask.attribute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.DynaMask.attribute" title="Permalink to this definition"></a></dt>
<dd><p>Attribute method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.DynaMask.attribute.params.inputs"></span><strong>inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.DynaMask.attribute.params.inputs">¶</a> (<em>tensor</em><em> or </em><em>tuple</em><em> of </em><em>tensors</em>) – Input for which integrated
gradients are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.
If forward_func takes multiple tensors as input, a tuple
of the input tensors should be provided. It is assumed
that for all given input tensors, dimension 0 corresponds
to the number of examples, and if multiple input tensors
are provided, the examples must be aligned appropriately.</p></li>
<li><p><span class="target" id="tint.attr.DynaMask.attribute.params.additional_forward_args"></span><strong>additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.DynaMask.attribute.params.additional_forward_args">¶</a> (<em>any</em><em>, </em><em>optional</em>) – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a
tuple containing multiple additional arguments including
tensors or any arbitrary python types. These arguments
are provided to forward_func in order following the
arguments in inputs.
For a tensor, the first dimension of the tensor must
correspond to the number of examples. It will be
repeated for each of <cite>n_steps</cite> along the integrated
path. For all other types, the given argument is used
for all forward evaluations.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.DynaMask.attribute.params.trainer"></span><strong>trainer</strong><a class="paramlink headerlink reference internal" href="#tint.attr.DynaMask.attribute.params.trainer">¶</a> (<em>Trainer</em>) – Pytorch Lightning trainer. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, a
default trainer will be provided.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.DynaMask.attribute.params.mask_net"></span><strong>mask_net</strong><a class="paramlink headerlink reference internal" href="#tint.attr.DynaMask.attribute.params.mask_net">¶</a> (<a class="reference internal" href="attr_models.html#tint.attr.models.MaskNet" title="tint.attr.models.MaskNet"><em>MaskNet</em></a>) – A Mask model. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, a default model
will be provided.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.DynaMask.attribute.params.batch_size"></span><strong>batch_size</strong><a class="paramlink headerlink reference internal" href="#tint.attr.DynaMask.attribute.params.batch_size">¶</a> (<em>int</em>) – Batch size for Mask training.
Default: 32</p></li>
<li><p><span class="target" id="tint.attr.DynaMask.attribute.params.temporal_additional_forward_args"></span><strong>temporal_additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.DynaMask.attribute.params.temporal_additional_forward_args">¶</a> (<em>tuple</em>) – Set each
additional forward arg which is temporal.
Only used with return_temporal_attributions.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.DynaMask.attribute.params.return_temporal_attributions"></span><strong>return_temporal_attributions</strong><a class="paramlink headerlink reference internal" href="#tint.attr.DynaMask.attribute.params.return_temporal_attributions">¶</a> (<em>bool</em>) – Whether to return
attributions for all times or not.
Default: False</p></li>
<li><p><span class="target" id="tint.attr.DynaMask.attribute.params.return_best_ratio"></span><strong>return_best_ratio</strong><a class="paramlink headerlink reference internal" href="#tint.attr.DynaMask.attribute.params.return_best_ratio">¶</a> (<em>bool</em>) – Whether to return the best keep_ratio
or not.
Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The attributions with respect to each input feature.
Attributions will always be
the same size as the provided inputs, with each value
providing the attribution of the corresponding input index.
If a single tensor is provided as inputs, a single tensor is
returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><strong>attributions</strong> (<em>tensor</em> or tuple of <em>tensors</em>)</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.ExtremalMask">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">ExtremalMask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/extremal_mask.html#ExtremalMask"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.ExtremalMask" title="Permalink to this definition"></a></dt>
<dd><p>Extremal masks.</p>
<p>This method extends the work of Fong et al. and Crabbé et al. by allowing
the perturbation function to be learnt. This is in addition to the learnt
mask. For instance, this perturbation function can be learnt with a RNN
while Crabbé et al. only consider fixed perturbations: Gaussian blur
and fade to moving average.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="target" id="tint.attr.ExtremalMask.params.forward_func"></span><strong>forward_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.ExtremalMask.params.forward_func">¶</a> (<em>callable</em>) – The forward function of the model or any
modification of it.</p>
</dd>
</dl>
<p class="rubric">References</p>
<ol class="arabic simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/2305.18840">Learning Perturbations to Explain Time Series Predictions</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1910.08485">Understanding Deep Networks via Extremal Perturbations and Smooth Masks</a></p></li>
</ol>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">ExtremalMask</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.models</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">ExtremalMask</span><span class="p">(</span><span class="n">mlp</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.ExtremalMask.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baselines</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Trainer</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_net</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="attr_models.html#tint.attr.models.ExtremalMaskNet" title="tint.attr.models.extremal_mask.ExtremalMaskNet"><span class="pre">ExtremalMaskNet</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temporal_additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_temporal_attributions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></span><a class="reference internal" href="_modules/tint/attr/extremal_mask.html#ExtremalMask.attribute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.ExtremalMask.attribute" title="Permalink to this definition"></a></dt>
<dd><p>Attribute method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.ExtremalMask.attribute.params.inputs"></span><strong>inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.ExtremalMask.attribute.params.inputs">¶</a> (<em>tensor</em><em> or </em><em>tuple</em><em> of </em><em>tensors</em>) – Input for which occlusion
attributions are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.
If forward_func takes multiple tensors as input, a tuple
of the input tensors should be provided. It is assumed
that for all given input tensors, dimension 0 corresponds
to the number of examples (aka batch size), and if
multiple input tensors are provided, the examples must
be aligned appropriately.</p></li>
<li><p><span class="target" id="tint.attr.ExtremalMask.attribute.params.baselines"></span><strong>baselines</strong><a class="paramlink headerlink reference internal" href="#tint.attr.ExtremalMask.attribute.params.baselines">¶</a> (<em>scalar</em><em>, </em><em>tensor</em><em>, </em><em>tuple</em><em> of </em><em>scalars</em><em> or </em><em>tensors</em><em>, </em><em>optional</em>) – <p>Baselines define reference value which replaces each
feature when occluded.
Baselines can be provided as:</p>
<ul>
<li><p>a single tensor, if inputs is a single tensor, with
exactly the same dimensions as inputs or
broadcastable to match the dimensions of inputs</p></li>
<li><p>a single scalar, if inputs is a single tensor, which will
be broadcasted for each input value in input tensor.</p></li>
<li><p>a tuple of tensors or scalars, the baseline corresponding
to each tensor in the inputs’ tuple can be:</p>
<ul>
<li><p>either a tensor with matching dimensions to
corresponding tensor in the inputs’ tuple
or the first dimension is one and the remaining
dimensions match with the corresponding
input tensor.</p></li>
<li><p>or a scalar, corresponding to a tensor in the
inputs’ tuple. This scalar value is broadcasted
for corresponding input tensor.</p></li>
</ul>
</li>
</ul>
<p>In the cases when <cite>baselines</cite> is not provided, we internally
use zero scalar corresponding to each input tensor.
Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.ExtremalMask.attribute.params.target"></span><strong>target</strong><a class="paramlink headerlink reference internal" href="#tint.attr.ExtremalMask.attribute.params.target">¶</a> (<em>int</em><em>, </em><em>tuple</em><em>, </em><em>tensor</em><em> or </em><em>list</em><em>, </em><em>optional</em>) – <p>Output indices for
which difference is computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><p>a single integer or a tensor containing a single
integer, which is applied to all input examples</p></li>
<li><p>a list of integers or a 1D tensor, with length matching
the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p></li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><p>A single tuple, which contains #output_dims - 1
elements. This target index is applied to all examples.</p></li>
<li><p>A list of tuples with length equal to the number of
examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p></li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.ExtremalMask.attribute.params.additional_forward_args"></span><strong>additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.ExtremalMask.attribute.params.additional_forward_args">¶</a> (<em>any</em><em>, </em><em>optional</em>) – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a
tuple containing multiple additional arguments including
tensors or any arbitrary python types. These arguments
are provided to forward_func in order following the
arguments in inputs.
For a tensor, the first dimension of the tensor must
correspond to the number of examples. For all other types,
the given argument is used for all forward evaluations.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.ExtremalMask.attribute.params.trainer"></span><strong>trainer</strong><a class="paramlink headerlink reference internal" href="#tint.attr.ExtremalMask.attribute.params.trainer">¶</a> (<em>Trainer</em>) – Pytorch Lightning trainer. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, a
default trainer will be provided.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.ExtremalMask.attribute.params.mask_net"></span><strong>mask_net</strong><a class="paramlink headerlink reference internal" href="#tint.attr.ExtremalMask.attribute.params.mask_net">¶</a> (<em>BayesMaskNet</em>) – A Mask model. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, a default model
will be provided.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.ExtremalMask.attribute.params.batch_size"></span><strong>batch_size</strong><a class="paramlink headerlink reference internal" href="#tint.attr.ExtremalMask.attribute.params.batch_size">¶</a> (<em>int</em>) – Batch size for Mask training.
Default: 32</p></li>
<li><p><span class="target" id="tint.attr.ExtremalMask.attribute.params.temporal_additional_forward_args"></span><strong>temporal_additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.ExtremalMask.attribute.params.temporal_additional_forward_args">¶</a> (<em>tuple</em>) – Set each
additional forward arg which is temporal.
Only used with return_temporal_attributions.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.ExtremalMask.attribute.params.return_temporal_attributions"></span><strong>return_temporal_attributions</strong><a class="paramlink headerlink reference internal" href="#tint.attr.ExtremalMask.attribute.params.return_temporal_attributions">¶</a> (<em>bool</em>) – Whether to return
attributions for all times or not.
Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The attributions with respect to each input feature.
Attributions will always be
the same size as the provided inputs, with each value
providing the attribution of the corresponding input index.
If a single tensor is provided as inputs, a single tensor is
returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><strong>attributions</strong> (<em>tensor</em> or tuple of <em>tensors</em>)</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.FeatureAblation">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">FeatureAblation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/feature_ablation.html#FeatureAblation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.FeatureAblation" title="Permalink to this definition"></a></dt>
<dd><p>A perturbation based approach to computing attribution, involving
replacing each input feature with a given baseline / reference, and
computing the difference in output. By default, each scalar value within
each input tensor is taken as a feature and replaced independently. Passing
a feature mask, allows grouping features to be ablated together. This can
be used in cases such as images, where an entire segment or region
can be ablated, measuring the importance of the segment (feature group).
Each input scalar in the group will be given the same attribution value
equal to the change in target as a result of ablating the entire feature
group.</p>
<p>The forward function can either return a scalar per example or a tensor
of a fixed sized tensor (or scalar value) for the full batch, i.e. the
output does not grow as the batch size increase. If the output is fixed
we consider this model to be an “aggregation” of the inputs. In the fixed
sized output mode we require <cite>perturbations_per_eval == 1</cite> and the
<cite>feature_mask</cite> to be either <cite>None</cite> or for all of them to have 1 as their
first dimension (i.e. a feature mask requires to be applied to all inputs).</p>
<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.FeatureAblation.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baselines</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">feature_mask</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">perturbations_per_eval</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attributions_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kwargs_run_forward</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></span><a class="reference internal" href="_modules/tint/attr/feature_ablation.html#FeatureAblation.attribute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.FeatureAblation.attribute" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.FeatureAblation.attribute.params.inputs"></span><strong>inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.FeatureAblation.attribute.params.inputs">¶</a> (<em>Tensor</em><em> or </em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>...</em><em>]</em>) – Input for which ablation
attributions are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.
If forward_func takes multiple tensors as input, a tuple
of the input tensors should be provided. It is assumed
that for all given input tensors, dimension 0 corresponds
to the number of examples (aka batch size), and if
multiple input tensors are provided, the examples must
be aligned appropriately.</p></li>
<li><p><span class="target" id="tint.attr.FeatureAblation.attribute.params.baselines"></span><strong>baselines</strong><a class="paramlink headerlink reference internal" href="#tint.attr.FeatureAblation.attribute.params.baselines">¶</a> (<em>scalar</em><em>, </em><em>Tensor</em><em>, </em><em>tuple</em><em> of </em><em>scalar</em><em>, or </em><em>Tensor</em><em>, </em><em>optional</em>) – <p>Baselines define reference value which replaces each
feature when ablated.
Baselines can be provided as:</p>
<ul>
<li><p>a single tensor, if inputs is a single tensor, with
exactly the same dimensions as inputs or
broadcastable to match the dimensions of inputs</p></li>
<li><p>a single scalar, if inputs is a single tensor, which will
be broadcasted for each input value in input tensor.</p></li>
<li><p>a tuple of tensors or scalars, the baseline corresponding
to each tensor in the inputs’ tuple can be:</p>
<ul>
<li><p>either a tensor with matching dimensions to
corresponding tensor in the inputs’ tuple
or the first dimension is one and the remaining
dimensions match with the corresponding
input tensor.</p></li>
<li><p>or a scalar, corresponding to a tensor in the
inputs’ tuple. This scalar value is broadcasted
for corresponding input tensor.</p></li>
</ul>
</li>
</ul>
<p>In the cases when <cite>baselines</cite> is not provided, we internally
use zero scalar corresponding to each input tensor.
Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.FeatureAblation.attribute.params.target"></span><strong>target</strong><a class="paramlink headerlink reference internal" href="#tint.attr.FeatureAblation.attribute.params.target">¶</a> (<em>int</em><em>, </em><em>tuple</em><em>, </em><em>Tensor</em><em>, or </em><em>list</em><em>, </em><em>optional</em>) – <p>Output indices for
which gradients are computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><p>a single integer or a tensor containing a single
integer, which is applied to all input examples</p></li>
<li><p>a list of integers or a 1D tensor, with length matching
the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p></li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><p>A single tuple, which contains #output_dims - 1
elements. This target index is applied to all examples.</p></li>
<li><p>A list of tuples with length equal to the number of
examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p></li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.FeatureAblation.attribute.params.additional_forward_args"></span><strong>additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.FeatureAblation.attribute.params.additional_forward_args">¶</a> (<em>Any</em><em>, </em><em>optional</em>) – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a
tuple containing multiple additional arguments including
tensors or any arbitrary python types. These arguments
are provided to forward_func in order following the
arguments in inputs.
For a tensor, the first dimension of the tensor must
correspond to the number of examples. For all other types,
the given argument is used for all forward evaluations.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.FeatureAblation.attribute.params.feature_mask"></span><strong>feature_mask</strong><a class="paramlink headerlink reference internal" href="#tint.attr.FeatureAblation.attribute.params.feature_mask">¶</a> (<em>Tensor</em><em> or </em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>...</em><em>]</em><em>, </em><em>optional</em>) – feature_mask defines a mask for the input, grouping
features which should be ablated together. feature_mask
should contain the same number of tensors as inputs.
Each tensor should
be the same size as the corresponding input or
broadcastable to match the input tensor. Each tensor
should contain integers in the range 0 to num_features
- 1, and indices corresponding to the same feature should
have the same value.
Note that features within each input tensor are ablated
independently (not across tensors).
If the forward function returns a single scalar per batch,
we enforce that the first dimension of each mask must be 1,
since attributions are returned batch-wise rather than per
example, so the attributions must correspond to the
same features (indices) in each input example.
If None, then a feature mask is constructed which assigns
each scalar within a tensor as a separate feature, which
is ablated independently.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.FeatureAblation.attribute.params.perturbations_per_eval"></span><strong>perturbations_per_eval</strong><a class="paramlink headerlink reference internal" href="#tint.attr.FeatureAblation.attribute.params.perturbations_per_eval">¶</a> (<em>int</em><em>, </em><em>optional</em>) – Allows ablation of multiple
features to be processed simultaneously in one call to
forward_fn.
Each forward pass will contain a maximum of
perturbations_per_eval * #examples samples.
For DataParallel models, each batch is split among the
available devices, so evaluations on each available
device contain at most
(perturbations_per_eval * #examples) / num_devices
samples.
If the forward function’s number of outputs does not
change as the batch size grows (e.g. if it outputs a
scalar value), you must set perturbations_per_eval to 1
and use a single feature mask to describe the features
for all examples in the batch.
Default: 1</p></li>
<li><p><span class="target" id="tint.attr.FeatureAblation.attribute.params.attributions_fn"></span><strong>attributions_fn</strong><a class="paramlink headerlink reference internal" href="#tint.attr.FeatureAblation.attribute.params.attributions_fn">¶</a> (<em>Callable</em><em>, </em><em>optional</em>) – Applies a function to the
attributions before performing the weighted sum.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.FeatureAblation.attribute.params.show_progress"></span><strong>show_progress</strong><a class="paramlink headerlink reference internal" href="#tint.attr.FeatureAblation.attribute.params.show_progress">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – Displays the progress of computation.
It will try to use tqdm if available for advanced features
(e.g. time estimation). Otherwise, it will fallback to
a simple output of progress.
Default: False</p></li>
<li><p><span class="target" id="tint.attr.FeatureAblation.attribute.params.kwargs_run_forward"></span><strong>kwargs_run_forward</strong><a class="paramlink headerlink reference internal" href="#tint.attr.FeatureAblation.attribute.params.kwargs_run_forward">¶</a> (<em>Any</em><em>, </em><em>optional</em>) – Any additional arguments to pass
to the _run_forward method.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.FeatureAblation.attribute.params.**kwargs"></span><strong>**kwargs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.FeatureAblation.attribute.params.**kwargs">¶</a> (<em>Any</em><em>, </em><em>optional</em>) – Any additional arguments used by child
classes of FeatureAblation (such as Occlusion) to construct
ablations. These arguments are ignored when using
FeatureAblation directly.
Default: None</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><dl class="simple">
<dt><strong>attributions</strong> (<em>Tensor</em> or <em>tuple[Tensor, …]</em>):</dt><dd><p>The attributions with respect to each input feature.
If the forward function returns
a scalar value per example, attributions will be
the same size as the provided inputs, with each value
providing the attribution of the corresponding input index.
If the forward function returns a scalar per batch, then
attribution tensor(s) will have first dimension 1 and
the remaining dimensions will match the input.
If a single tensor is provided as inputs, a single tensor is
returned. If a tuple of tensors is provided for inputs, a
tuple of corresponding sized tensors is returned.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>Tensor</em> or <em>tuple[Tensor, …]</em> of <strong>attributions</strong></p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># SimpleClassifier takes a single input tensor of size Nx4x4,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># and returns an Nx3 tensor of class probabilities.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">SimpleClassifier</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Generating random input with size 2 x 4 x 4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Defining FeatureAblation interpreter</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ablator</span> <span class="o">=</span> <span class="n">FeatureAblation</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Computes ablation attribution, ablating each of the 16</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># scalar input independently.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">ablator</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Alternatively, we may want to ablate features in groups, e.g.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># grouping each 2x2 square of the inputs and ablating them together.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># This can be done by creating a feature mask as follows, which</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># defines the feature groups, e.g.:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># +---+---+---+---+</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># | 0 | 0 | 1 | 1 |</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># +---+---+---+---+</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># | 0 | 0 | 1 | 1 |</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># +---+---+---+---+</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># | 2 | 2 | 3 | 3 |</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># +---+---+---+---+</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># | 2 | 2 | 3 | 3 |</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># +---+---+---+---+</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># With this mask, all inputs with the same value are ablated</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># simultaneously, and the attribution for each input in the same</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># group (0, 1, 2, and 3) per example are the same.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># The attributions can be calculated as follows:</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># feature mask has dimensions 1 x 4 x 4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">feature_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                            <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">ablator</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">feature_mask</span><span class="o">=</span><span class="n">feature_mask</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.Fit">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">Fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">generator</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="attr_models.html#tint.attr.models.JointFeatureGeneratorNet" title="tint.attr.models.joint_features_generator.JointFeatureGeneratorNet"><span class="pre">JointFeatureGeneratorNet</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">datamodule</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">LightningDataModule</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Trainer</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">32</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/fit.html#Fit"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.Fit" title="Permalink to this definition"></a></dt>
<dd><p>Feature Importance in Time.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.Fit.params.forward_func"></span><strong>forward_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.params.forward_func">¶</a> (<em>callable</em>) – The forward function of the model or any
modification of it.</p></li>
<li><p><span class="target" id="tint.attr.Fit.params.generator"></span><strong>generator</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.params.generator">¶</a> (<a class="reference internal" href="attr_models.html#tint.attr.models.JointFeatureGeneratorNet" title="tint.attr.models.JointFeatureGeneratorNet"><em>JointFeatureGeneratorNet</em></a>) – Conditional generator model to
predict future observations as a Pytorch Lightning module.
If not provided, a default generator is created.
Default to <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><span class="target" id="tint.attr.Fit.params.datamodule"></span><strong>datamodule</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.params.datamodule">¶</a> (<em>LightningDataModule</em>) – A Pytorch Lightning data
module to train the generator. If not provided, you must provide
features. Default to <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><span class="target" id="tint.attr.Fit.params.features"></span><strong>features</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.params.features">¶</a> (<em>th.Tensor</em>) – A tensor of features to train the generator.
If not provided, you must provide a datamodule.
Default to <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><span class="target" id="tint.attr.Fit.params.trainer"></span><strong>trainer</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.params.trainer">¶</a> (<em>Trainer</em>) – A Pytorch Lightning trainer to train the generator.
If not provided, a default trainer is created. Default to <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><span class="target" id="tint.attr.Fit.params.batch_size"></span><strong>batch_size</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.params.batch_size">¶</a> (<em>int</em>) – Batch size for generator training. Default to 32</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://arxiv.org/abs/2003.02821">What went wrong and when? Instance-wise Feature Importance for Time-series Models</a></p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">Fit</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.models</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">Fit</span><span class="p">(</span><span class="n">mlp</span><span class="p">,</span> <span class="n">features</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.Fit.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_samples</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">distance_metric</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'kl'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multilabel</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temporal_additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_temporal_attributions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></span><a class="reference internal" href="_modules/tint/attr/fit.html#Fit.attribute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.Fit.attribute" title="Permalink to this definition"></a></dt>
<dd><p>attribute method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.Fit.attribute.params.inputs"></span><strong>inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.attribute.params.inputs">¶</a> (<em>tensor</em><em> or </em><em>tuple</em><em> of </em><em>tensors</em>) – Input for which integrated
gradients are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.
If forward_func takes multiple tensors as input, a tuple
of the input tensors should be provided. It is assumed
that for all given input tensors, dimension 0 corresponds
to the number of examples, and if multiple input tensors
are provided, the examples must be aligned appropriately.</p></li>
<li><p><span class="target" id="tint.attr.Fit.attribute.params.additional_forward_args"></span><strong>additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.attribute.params.additional_forward_args">¶</a> (<em>any</em><em>, </em><em>optional</em>) – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a
tuple containing multiple additional arguments including
tensors or any arbitrary python types. These arguments
are provided to forward_func in order following the
arguments in inputs.
For a tensor, the first dimension of the tensor must
correspond to the number of examples. It will be
repeated for each of <cite>n_steps</cite> along the integrated
path. For all other types, the given argument is used
for all forward evaluations.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.Fit.attribute.params.n_samples"></span><strong>n_samples</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.attribute.params.n_samples">¶</a> (<em>int</em>) – Number of Monte-Carlo samples.
Default: 10</p></li>
<li><p><span class="target" id="tint.attr.Fit.attribute.params.distance_metric"></span><strong>distance_metric</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.attribute.params.distance_metric">¶</a> (<em>str</em>) – Distance metric.
Default to ‘kl’</p></li>
<li><p><span class="target" id="tint.attr.Fit.attribute.params.multilabel"></span><strong>multilabel</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.attribute.params.multilabel">¶</a> (<em>bool</em>) – Whether the task is single or multi-labeled.
Default: False</p></li>
<li><p><span class="target" id="tint.attr.Fit.attribute.params.temporal_additional_forward_args"></span><strong>temporal_additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.attribute.params.temporal_additional_forward_args">¶</a> (<em>tuple</em>) – Set each
additional forward arg which is temporal.
Only used with return_temporal_attributions.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.Fit.attribute.params.return_temporal_attributions"></span><strong>return_temporal_attributions</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.attribute.params.return_temporal_attributions">¶</a> (<em>bool</em>) – Whether to return
attributions for all times or not.
Default: False</p></li>
<li><p><span class="target" id="tint.attr.Fit.attribute.params.show_progress"></span><strong>show_progress</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.attribute.params.show_progress">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – Displays the progress of computation.
It will try to use tqdm if available for advanced features
(e.g. time estimation). Otherwise, it will fallback to
a simple output of progress.
Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The attributions with respect to each input feature.
Attributions will always be
the same size as the provided inputs, with each value
providing the attribution of the corresponding input index.
If a single tensor is provided as inputs, a single tensor is
returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><strong>attributions</strong> (<em>tensor</em> or tuple of <em>tensors</em>)</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.Fit.representation">
<span class="sig-name descname"><span class="pre">representation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_samples</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">distance_metric</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'kl'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multilabel</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temporal_additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/fit.html#Fit.representation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.Fit.representation" title="Permalink to this definition"></a></dt>
<dd><p>Get representations based on a generator and inputs.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.Fit.representation.params.inputs"></span><strong>inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.representation.params.inputs">¶</a> (<em>th.Tensor</em>) – Input data.</p></li>
<li><p><span class="target" id="tint.attr.Fit.representation.params.additional_forward_args"></span><strong>additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.representation.params.additional_forward_args">¶</a> (<em>Any</em>) – Optional additional args to be
passed into the model. Default to <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><span class="target" id="tint.attr.Fit.representation.params.n_samples"></span><strong>n_samples</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.representation.params.n_samples">¶</a> (<em>int</em>) – Number of Monte-Carlo samples. Default to 10</p></li>
<li><p><span class="target" id="tint.attr.Fit.representation.params.distance_metric"></span><strong>distance_metric</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.representation.params.distance_metric">¶</a> (<em>str</em>) – Distance metric. Default to <code class="docutils literal notranslate"><span class="pre">'kl'</span></code></p></li>
<li><p><span class="target" id="tint.attr.Fit.representation.params.multilabel"></span><strong>multilabel</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.representation.params.multilabel">¶</a> (<em>bool</em>) – Whether the task is single or multi-labeled.
Default to <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><span class="target" id="tint.attr.Fit.representation.params.temporal_additional_forward_args"></span><strong>temporal_additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.representation.params.temporal_additional_forward_args">¶</a> (<em>tuple</em>) – Set each
additional forward arg which is temporal.
Only used with return_temporal_attributions.
Default to <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><span class="target" id="tint.attr.Fit.representation.params.show_progress"></span><strong>show_progress</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Fit.representation.params.show_progress">¶</a> (<em>bool</em>) – Displays the progress of computation.
Default to False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>attributions.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>th.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.GeodesicIntegratedGradients">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">GeodesicIntegratedGradients</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">NearestNeighbors</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">NearestNeighbors</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_neighbors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multiply_by_inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/geodesic_ig.html#GeodesicIntegratedGradients"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.GeodesicIntegratedGradients" title="Permalink to this definition"></a></dt>
<dd><p>Geodesic Integrated Gradients.</p>
<p>This method uses K Nearest Neighbors on the input data to approximate the
geodesic path between inputs and reference baselines. The input space is
seen here as a Riemannian manifold, whose metric is the inner product of
the gradient of the model:</p>
<div class="math notranslate nohighlight">
\[&lt;\nabla F(x)^T, \nabla F(x)&gt;\]</div>
<p>Using this path reduces the risk of creating artifacts compared with
the original Integrated Gradients (IG). It also supports
<code class="docutils literal notranslate"><span class="pre">internal_batch_size</span></code> for faster compute. The number of steps is also
set by default to 5, as less steps are required between two neighbors.
With this setting, and the number of neighbors set to 10, the number of
gradients to compute is 10 * 5 = 50, the same number as the original IG.</p>
<p>The shortest path is computed using Dijkstra or A* algorithms. This can
be computationally expensive for a number of inputs greater than a few
thousands.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.GeodesicIntegratedGradients.params.forward_func"></span><strong>forward_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GeodesicIntegratedGradients.params.forward_func">¶</a> (<em>callable</em>) – The forward function of the model or any
modification of it.</p></li>
<li><p><span class="target" id="tint.attr.GeodesicIntegratedGradients.params.nn"></span><strong>nn</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GeodesicIntegratedGradients.params.nn">¶</a> (<em>NearestNeighbors</em><em>, </em><em>tuple</em>) – Nearest neighbors method.
If not provided, will be created when calling __init__ or
attribute.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.GeodesicIntegratedGradients.params.data"></span><strong>data</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GeodesicIntegratedGradients.params.data">¶</a> (<em>Tensor</em><em>, </em><em>tuple</em>) – Data to fit the knn algorithm. If not provided,
the knn will be fitted when calling attribute using the provided
inputs data.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.GeodesicIntegratedGradients.params.n_neighbors"></span><strong>n_neighbors</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GeodesicIntegratedGradients.params.n_neighbors">¶</a> (<em>int</em><em>, </em><em>tuple</em>) – Number of neighbors to use by default.
Can be an integer (same for every inputs) or a tuple.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.GeodesicIntegratedGradients.params.multiply_by_inputs"></span><strong>multiply_by_inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GeodesicIntegratedGradients.params.multiply_by_inputs">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – <p>Indicates whether to factor
model inputs’ multiplier in the final attribution scores.
In the literature this is also known as local vs global
attribution. If inputs’ multiplier isn’t factored in,
then that type of attribution method is also called local
attribution. If it is, then that type of attribution
method is called global.
More detailed can be found here:
<a class="reference external" href="https://arxiv.org/abs/1711.06104">https://arxiv.org/abs/1711.06104</a></p>
<p>In case of integrated gradients, if <cite>multiply_by_inputs</cite>
is set to True, final sensitivity scores are being multiplied by
(inputs - baselines).</p>
</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">GeodesicIntegratedGradients</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.models</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">GeodesicIntegratedGradients</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">mlp</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.GeodesicIntegratedGradients.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baselines</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">BaselineType</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TargetType</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_neighbors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_steiner</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'gausslegendre'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">internal_batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_curvature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_convergence_delta</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">distance</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'geodesic'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></span><a class="reference internal" href="_modules/tint/attr/geodesic_ig.html#GeodesicIntegratedGradients.attribute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.GeodesicIntegratedGradients.attribute" title="Permalink to this definition"></a></dt>
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baselines</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">BaselineType</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TargetType</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_neighbors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_steiner</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'gausslegendre'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">internal_batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_curvature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_convergence_delta</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">distance</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'geodesic'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">TensorOrTupleOfTensorsGeneric</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span></dt>
<dd><p>This method attributes the output of the model with given target index
(in case it is provided, otherwise it assumes that output is a
scalar) to the inputs of the model using the approach described above.</p>
<p>In addition to that it also returns, if <cite>return_convergence_delta</cite> is
set to True, integral approximation delta based on the completeness
property of integrated gradients.</p>
<p>It also returns the curvature if <cite>return_curvature</cite> is set to True.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.GeodesicIntegratedGradients.attribute.params.inputs"></span><strong>inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GeodesicIntegratedGradients.attribute.params.inputs">¶</a> (<em>tensor</em><em> or </em><em>tuple</em><em> of </em><em>tensors</em>) – Input for which integrated
gradients are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.
If forward_func takes multiple tensors as input, a tuple
of the input tensors should be provided. It is assumed
that for all given input tensors, dimension 0 corresponds
to the number of examples, and if multiple input tensors
are provided, the examples must be aligned appropriately.</p></li>
<li><p><span class="target" id="tint.attr.GeodesicIntegratedGradients.attribute.params.baselines"></span><strong>baselines</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GeodesicIntegratedGradients.attribute.params.baselines">¶</a> (<em>scalar</em><em>, </em><em>tensor</em><em>, </em><em>tuple</em><em> of </em><em>scalars</em><em> or </em><em>tensors</em><em>, </em><em>optional</em>) – <p>Baselines define the starting point from which integral
is computed and can be provided as:</p>
<ul>
<li><p>a single tensor, if inputs is a single tensor, with
exactly the same dimensions as inputs or the first
dimension is one and the remaining dimensions match
with inputs.</p></li>
<li><p>a single scalar, if inputs is a single tensor, which will
be broadcasted for each input value in input tensor.</p></li>
<li><p>a tuple of tensors or scalars, the baseline corresponding
to each tensor in the inputs’ tuple can be:</p>
<ul>
<li><p>either a tensor with matching dimensions to
corresponding tensor in the inputs’ tuple
or the first dimension is one and the remaining
dimensions match with the corresponding
input tensor.</p></li>
<li><p>or a scalar, corresponding to a tensor in the
inputs’ tuple. This scalar value is broadcasted
for corresponding input tensor.</p></li>
</ul>
</li>
</ul>
<p>In the cases when <cite>baselines</cite> is not provided, we internally
use zero scalar corresponding to each input tensor.</p>
<p>Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.GeodesicIntegratedGradients.attribute.params.target"></span><strong>target</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GeodesicIntegratedGradients.attribute.params.target">¶</a> (<em>int</em><em>, </em><em>tuple</em><em>, </em><em>tensor</em><em> or </em><em>list</em><em>, </em><em>optional</em>) – <p>Output indices for
which gradients are computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><p>a single integer or a tensor containing a single
integer, which is applied to all input examples</p></li>
<li><p>a list of integers or a 1D tensor, with length matching
the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p></li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><p>A single tuple, which contains #output_dims - 1
elements. This target index is applied to all examples.</p></li>
<li><p>A list of tuples with length equal to the number of
examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p></li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.GeodesicIntegratedGradients.attribute.params.additional_forward_args"></span><strong>additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GeodesicIntegratedGradients.attribute.params.additional_forward_args">¶</a> (<em>any</em><em>, </em><em>optional</em>) – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a
tuple containing multiple additional arguments including
tensors or any arbitrary python types. These arguments
are provided to forward_func in order following the
arguments in inputs.
For a tensor, the first dimension of the tensor must
correspond to the number of examples. It will be
repeated for each of <cite>n_steps</cite> along the integrated
path. For all other types, the given argument is used
for all forward evaluations.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.GeodesicIntegratedGradients.attribute.params.n_neighbors"></span><strong>n_neighbors</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GeodesicIntegratedGradients.attribute.params.n_neighbors">¶</a> (<em>int</em><em>, </em><em>optional</em>) – Number of neighbors to use by default.
Must be provided if it has not been set in the init.
Can be an integer (same for every inputs) or a tuple.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.GeodesicIntegratedGradients.attribute.params.n_steps"></span><strong>n_steps</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GeodesicIntegratedGradients.attribute.params.n_steps">¶</a> (<em>int</em><em>, </em><em>optional</em>) – The number of steps used by the approximation
method. Default: 5.</p></li>
<li><p><span class="target" id="tint.attr.GeodesicIntegratedGradients.attribute.params.n_steiner"></span><strong>n_steiner</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GeodesicIntegratedGradients.attribute.params.n_steiner">¶</a> (<em>int</em><em>, </em><em>optional</em>) – Add a certain number of steiner points
into the graph. These points are added following the fixed
scheme. For more information, please refer to the section 4.1.3
of <a class="reference external" href="https://arxiv.org/pdf/2007.10430">https://arxiv.org/pdf/2007.10430</a>.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.GeodesicIntegratedGradients.attribute.params.method"></span><strong>method</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GeodesicIntegratedGradients.attribute.params.method">¶</a> (<em>string</em><em>, </em><em>optional</em>) – Method for approximating the integral,
one of <cite>riemann_right</cite>, <cite>riemann_left</cite>, <cite>riemann_middle</cite>,
<cite>riemann_trapezoid</cite> or <cite>gausslegendre</cite>.
Default: <cite>gausslegendre</cite> if no method is provided.</p></li>
<li><p><span class="target" id="tint.attr.GeodesicIntegratedGradients.attribute.params.internal_batch_size"></span><strong>internal_batch_size</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GeodesicIntegratedGradients.attribute.params.internal_batch_size">¶</a> (<em>int</em><em>, </em><em>optional</em>) – Divides total #steps * #examples
data points into chunks of size at most internal_batch_size,
which are computed (forward / backward passes)
sequentially. internal_batch_size must be at least equal to
#examples.
For DataParallel models, each batch is split among the
available devices, so evaluations on each available
device contain internal_batch_size / num_devices examples.
If internal_batch_size is None, then all evaluations are
processed in one batch.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.GeodesicIntegratedGradients.attribute.params.return_curvature"></span><strong>return_curvature</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GeodesicIntegratedGradients.attribute.params.return_curvature">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – Indicates whether to return
the curvature or not. If <cite>return_curvature</cite>
is set to True curvature will be returned in a tuple following
attributions and optionally convergence delta.
Default: False</p></li>
<li><p><span class="target" id="tint.attr.GeodesicIntegratedGradients.attribute.params.return_convergence_delta"></span><strong>return_convergence_delta</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GeodesicIntegratedGradients.attribute.params.return_convergence_delta">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – Indicates whether to return
convergence delta or not. If <cite>return_convergence_delta</cite>
is set to True convergence delta will be returned in
a tuple following attributions.
Default: False</p></li>
<li><p><span class="target" id="tint.attr.GeodesicIntegratedGradients.attribute.params.distance"></span><strong>distance</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GeodesicIntegratedGradients.attribute.params.distance">¶</a> (<em>str</em><em>, </em><em>optional</em>) – <p>Which distance to use with the A*
algorithm:</p>
<ul>
<li><p>’geodesic’: the geodesic distance using the gradients norms.</p></li>
<li><p>’euclidean’: using the plain euclidean distance between
points. This method amounts to the one described here:
<a class="reference external" href="https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02055-7">https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02055-7</a></p></li>
</ul>
<p>Default: ‘geodesic’</p>
</p></li>
<li><p><span class="target" id="tint.attr.GeodesicIntegratedGradients.attribute.params.show_progress"></span><strong>show_progress</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GeodesicIntegratedGradients.attribute.params.show_progress">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – Displays the progress of computation.
It will try to use tqdm if available for advanced features
(e.g. time estimation). Otherwise, it will fallback to
a simple output of progress.
Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul>
<li><dl class="simple">
<dt><strong>attributions</strong> (<em>tensor</em> or tuple of <em>tensors</em>):</dt><dd><p>Integrated gradients with respect to each input feature.
attributions will always be the same size as the provided
inputs, with each value providing the attribution of the
corresponding input index.
If a single tensor is provided as inputs, a single tensor is
returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>delta</strong> (<em>tensor</em>, returned if return_convergence_delta=True):</dt><dd><p>The difference between the total approximated and true
integrated gradients. This is computed using the property
that the total sum of forward_func(inputs) -
forward_func(baselines) must equal the total sum of the
integrated gradient.
Delta is calculated per example, meaning that the number of
elements in returned delta tensor is equal to the number of
examples in inputs.</p>
</dd>
</dl>
</li>
<li><dl>
<dt><strong>curvature</strong> (<em>tensor</em>, returned if return_curvature=True):</dt><dd><p>The difference between the distance along the path computed
by the A* algorithm and the euclidean distance between
inputs and baselines. This value, always positive,
returns a measure of the curvature of the input space, with
the inner product of the gradient of the model:</p>
<div class="math notranslate nohighlight">
\[&lt;\nabla F(x)^T, \nabla F(x)&gt;\]</div>
<p>as a metric. A higher value indicates a higher curvature.
This value however depends on the path and is as such only
an indication of the true curvature of the input space.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>attributions</strong> or tuple with <strong>attributions</strong>, <strong>delta</strong> (optional) or /and curvature (optional)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.GeodesicIntegratedGradients.compute_curvature">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">compute_curvature</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baselines</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">knns</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grads_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">paths_len</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/tint/attr/geodesic_ig.html#GeodesicIntegratedGradients.compute_curvature"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.GeodesicIntegratedGradients.compute_curvature" title="Permalink to this definition"></a></dt>
<dd><p>Compute the curvature of the input space, as the difference between
the euclidean distance along the path computed by the A* algorithm
and the euclidean distance between the inputs and baseline.
The curvature is always positive.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.GeodesicIntegratedGradients.has_convergence_delta">
<span class="sig-name descname"><span class="pre">has_convergence_delta</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="reference internal" href="_modules/tint/attr/geodesic_ig.html#GeodesicIntegratedGradients.has_convergence_delta"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.GeodesicIntegratedGradients.has_convergence_delta" title="Permalink to this definition"></a></dt>
<dd><p>This method informs the user whether the attribution algorithm provides
a convergence delta (aka an approximation error) or not. Convergence
delta may serve as a proxy of correctness of attribution algorithm’s
approximation. If deriving attribution class provides a
<cite>compute_convergence_delta</cite> method, it should
override both <cite>compute_convergence_delta</cite> and <cite>has_convergence_delta</cite> methods.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Returns whether the attribution algorithm
provides a convergence delta (aka approximation error) or not.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.GuidedIntegratedGradients">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">GuidedIntegratedGradients</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multiply_by_inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/guided_ig.html#GuidedIntegratedGradients"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.GuidedIntegratedGradients" title="Permalink to this definition"></a></dt>
<dd><p>Guided Integrated Gradients.</p>
<p>This method greedily search for a path which avoids high-gradients regions.
For this, it selects a <code class="docutils literal notranslate"><span class="pre">fraction</span></code> of the data corresponding to the lowest
gradients, and move this subset of the current point on the path closer to
the input data, starting from a baseline. This process is repeated
<code class="docutils literal notranslate"><span class="pre">n_guided_steps</span></code> times. Moreover, it anchors the resulting path to the
straight line between inputs and baselines by forcing the path to cross
points on this line. The number of anchor points is controlled by the
<code class="docutils literal notranslate"><span class="pre">n_anchors</span></code> parameter.</p>
<p>Similarly to IntegratedGradients, it is possible to provide an
<code class="docutils literal notranslate"><span class="pre">internal_batch_size</span></code> to reduce memory usage. The convergence delta
can also be returned.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.GuidedIntegratedGradients.params.forward_func"></span><strong>forward_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GuidedIntegratedGradients.params.forward_func">¶</a> (<em>Callable</em>) – The forward function of the model or any
modification of it</p></li>
<li><p><span class="target" id="tint.attr.GuidedIntegratedGradients.params.multiply_by_inputs"></span><strong>multiply_by_inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GuidedIntegratedGradients.params.multiply_by_inputs">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – <p>Indicates whether to factor
model inputs’ multiplier in the final attribution scores.
In the literature this is also known as local vs global
attribution. If inputs’ multiplier isn’t factored in,
then that type of attribution method is also called local
attribution. If it is, then that type of attribution
method is called global.
More detailed can be found here:
<a class="reference external" href="https://arxiv.org/abs/1711.06104">https://arxiv.org/abs/1711.06104</a></p>
<p>In case of integrated gradients, if <cite>multiply_by_inputs</cite>
is set to True, final sensitivity scores are being multiplied by
(inputs - baselines).</p>
</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><cite>Guided Integrated Gradients: an Adaptive Path Method for Removing Noise &lt;https://arxiv.org/abs/2106.09788&gt;</cite></p>
<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.GuidedIntegratedGradients.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baselines</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">BaselineType</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TargetType</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_anchors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_guided_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fraction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">internal_batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_convergence_delta</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="k"><span class="pre">False</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></span><a class="reference internal" href="_modules/tint/attr/guided_ig.html#GuidedIntegratedGradients.attribute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.GuidedIntegratedGradients.attribute" title="Permalink to this definition"></a></dt>
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baselines</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">BaselineType</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TargetType</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_anchors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_guided_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fraction</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">internal_batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_convergence_delta</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="k"><span class="pre">True</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">TensorOrTupleOfTensorsGeneric</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span></dt>
<dd><p>This method attributes the output of the model with given target index
(in case it is provided, otherwise it assumes that output is a
scalar) to the inputs of the model using the approach described above.</p>
<p>In addition to that it also returns, if <cite>return_convergence_delta</cite> is
set to True, integral approximation delta based on the completeness
property of integrated gradients.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.GuidedIntegratedGradients.attribute.params.inputs"></span><strong>inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GuidedIntegratedGradients.attribute.params.inputs">¶</a> (<em>Tensor</em><em> or </em><em>tuple</em><em>[</em><em>Tensor</em><em>, </em><em>...</em><em>]</em>) – Input for which integrated
gradients are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.
If forward_func takes multiple tensors as input, a tuple
of the input tensors should be provided. It is assumed
that for all given input tensors, dimension 0 corresponds
to the number of examples, and if multiple input tensors
are provided, the examples must be aligned appropriately.</p></li>
<li><p><span class="target" id="tint.attr.GuidedIntegratedGradients.attribute.params.baselines"></span><strong>baselines</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GuidedIntegratedGradients.attribute.params.baselines">¶</a> (<em>scalar</em><em>, </em><em>Tensor</em><em>, </em><em>tuple</em><em> of </em><em>scalar</em><em>, or </em><em>Tensor</em><em>, </em><em>optional</em>) – <p>Baselines define the starting point from which integral
is computed and can be provided as:</p>
<ul>
<li><p>a single tensor, if inputs is a single tensor, with
exactly the same dimensions as inputs or the first
dimension is one and the remaining dimensions match
with inputs.</p></li>
<li><p>a single scalar, if inputs is a single tensor, which will
be broadcasted for each input value in input tensor.</p></li>
<li><p>a tuple of tensors or scalars, the baseline corresponding
to each tensor in the inputs’ tuple can be:</p>
<ul>
<li><p>either a tensor with matching dimensions to
corresponding tensor in the inputs’ tuple
or the first dimension is one and the remaining
dimensions match with the corresponding
input tensor.</p></li>
<li><p>or a scalar, corresponding to a tensor in the
inputs’ tuple. This scalar value is broadcasted
for corresponding input tensor.</p></li>
</ul>
</li>
</ul>
<p>In the cases when <cite>baselines</cite> is not provided, we internally
use zero scalar corresponding to each input tensor.</p>
<p>Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.GuidedIntegratedGradients.attribute.params.target"></span><strong>target</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GuidedIntegratedGradients.attribute.params.target">¶</a> (<em>int</em><em>, </em><em>tuple</em><em>, </em><em>Tensor</em><em>, or </em><em>list</em><em>, </em><em>optional</em>) – <p>Output indices for
which gradients are computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><p>a single integer or a tensor containing a single
integer, which is applied to all input examples</p></li>
<li><p>a list of integers or a 1D tensor, with length matching
the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p></li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><p>A single tuple, which contains #output_dims - 1
elements. This target index is applied to all examples.</p></li>
<li><p>A list of tuples with length equal to the number of
examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p></li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.GuidedIntegratedGradients.attribute.params.additional_forward_args"></span><strong>additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GuidedIntegratedGradients.attribute.params.additional_forward_args">¶</a> (<em>Any</em><em>, </em><em>optional</em>) – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a
tuple containing multiple additional arguments including
tensors or any arbitrary python types. These arguments
are provided to forward_func in order following the
arguments in inputs.
For a tensor, the first dimension of the tensor must
correspond to the number of examples. It will be
repeated for each of <cite>n_steps</cite> along the integrated
path. For all other types, the given argument is used
for all forward evaluations.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.GuidedIntegratedGradients.attribute.params.n_anchors"></span><strong>n_anchors</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GuidedIntegratedGradients.attribute.params.n_anchors">¶</a> (<em>int</em><em>, </em><em>optional</em>) – The number of anchor points used by the
method. Default: 2</p></li>
<li><p><span class="target" id="tint.attr.GuidedIntegratedGradients.attribute.params.n_guided_steps"></span><strong>n_guided_steps</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GuidedIntegratedGradients.attribute.params.n_guided_steps">¶</a> (<em>int</em><em>, </em><em>optional</em>) – The number of steps to compute the path
between two anchor points. Default: 50</p></li>
<li><p><span class="target" id="tint.attr.GuidedIntegratedGradients.attribute.params.fraction"></span><strong>fraction</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GuidedIntegratedGradients.attribute.params.fraction">¶</a> (<em>float</em><em>, </em><em>optional</em>) – Fraction of features (we use 10%) with the
lowest absolute gradient values to be selected by the algorithm.
Default: 0.1</p></li>
<li><p><span class="target" id="tint.attr.GuidedIntegratedGradients.attribute.params.internal_batch_size"></span><strong>internal_batch_size</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GuidedIntegratedGradients.attribute.params.internal_batch_size">¶</a> (<em>int</em><em>, </em><em>optional</em>) – Divides total #steps * #examples
data points into chunks of size at most internal_batch_size,
which are computed (forward / backward passes)
sequentially. internal_batch_size must be at least equal to
#examples.
For DataParallel models, each batch is split among the
available devices, so evaluations on each available
device contain internal_batch_size / num_devices examples.
If internal_batch_size is None, then all evaluations are
processed in one batch.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.GuidedIntegratedGradients.attribute.params.return_convergence_delta"></span><strong>return_convergence_delta</strong><a class="paramlink headerlink reference internal" href="#tint.attr.GuidedIntegratedGradients.attribute.params.return_convergence_delta">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – Indicates whether to return
convergence delta or not. If <cite>return_convergence_delta</cite>
is set to True convergence delta will be returned in
a tuple following attributions.
Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><dl class="simple">
<dt><strong>attributions</strong> (<em>Tensor</em> or <em>tuple[Tensor, …]</em>):</dt><dd><p>Integrated gradients with respect to each input feature.
attributions will always be the same size as the provided
inputs, with each value providing the attribution of the
corresponding input index.
If a single tensor is provided as inputs, a single tensor is
returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>delta</strong> (<em>Tensor</em>, returned if return_convergence_delta=True):</dt><dd><p>The difference between the total approximated and true
integrated gradients. This is computed using the property
that the total sum of forward_func(inputs) -
forward_func(baselines) must equal the total sum of the
integrated gradient.
Delta is calculated per example, meaning that the number of
elements in returned delta tensor is equal to the number of
examples in inputs.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>attributions</strong> or 2-element tuple of <strong>attributions</strong>, <strong>delta</strong></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.GuidedIntegratedGradients.has_convergence_delta">
<span class="sig-name descname"><span class="pre">has_convergence_delta</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="reference internal" href="_modules/tint/attr/guided_ig.html#GuidedIntegratedGradients.has_convergence_delta"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.GuidedIntegratedGradients.has_convergence_delta" title="Permalink to this definition"></a></dt>
<dd><p>This method informs the user whether the attribution algorithm provides
a convergence delta (aka an approximation error) or not. Convergence
delta may serve as a proxy of correctness of attribution algorithm’s
approximation. If deriving attribution class provides a
<cite>compute_convergence_delta</cite> method, it should
override both <cite>compute_convergence_delta</cite> and <cite>has_convergence_delta</cite> methods.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Returns whether the attribution algorithm
provides a convergence delta (aka approximation error) or not.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.LofKernelShap">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">LofKernelShap</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_neighbors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/lof.html#LofKernelShap"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.LofKernelShap" title="Permalink to this definition"></a></dt>
<dd><p>Local Outlier Factor Kernel Shap.</p>
<p>This method compute a Local Outlier Factor score for every perturbed data.
This score is then used to update the weight given by the similarity
function:</p>
<div class="math notranslate nohighlight">
\[\textrm{new_weight}(x) = \textrm{similarity}(x) * \frac{-1}{\textrm{lof_score}(x)}\]</div>
<p>If the perturbed data is considered more out of sample, the weight of
this data will be reduced.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.LofKernelShap.params.forward_func"></span><strong>forward_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.LofKernelShap.params.forward_func">¶</a> (<em>Callable</em>) – The forward function of the model or any
modification of it.</p></li>
<li><p><span class="target" id="tint.attr.LofKernelShap.params.embeddings"></span><strong>embeddings</strong><a class="paramlink headerlink reference internal" href="#tint.attr.LofKernelShap.params.embeddings">¶</a> (<em>Tensor</em>) – Tensor of embeddings to compute the LOF.</p></li>
<li><p><span class="target" id="tint.attr.LofKernelShap.params.n_neighbors"></span><strong>n_neighbors</strong><a class="paramlink headerlink reference internal" href="#tint.attr.LofKernelShap.params.n_neighbors">¶</a> (<em>int</em>) – Number of neighbors to use by default.
Default to 20</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://arxiv.org/abs/2306.02968">Time Interpret: a Unified Model Interpretability Library for Time Series</a></p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">LofKernelShap</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.models</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">LofKernelShap</span><span class="p">(</span><span class="n">mlp</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.LofLime">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">LofLime</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embeddings</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_neighbors</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">interpretable_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Model</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">similarity_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">perturb_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/lof.html#LofLime"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.LofLime" title="Permalink to this definition"></a></dt>
<dd><p>Local Outlier Factor Lime.</p>
<p>This method compute a Local Outlier Factor score for every perturbed data.
This score is then used to update the weight given by the similarity
function:</p>
<div class="math notranslate nohighlight">
\[\textrm{new_weight}(x) = \textrm{similarity}(x) * \frac{-1}{\textrm{lof_score}(x)}\]</div>
<p>If the perturbed data is considered more out of sample, the weight of
this data will be reduced.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.LofLime.params.forward_func"></span><strong>forward_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.LofLime.params.forward_func">¶</a> (<em>Callable</em>) – The forward function of the model or any
modification of it.</p></li>
<li><p><span class="target" id="tint.attr.LofLime.params.embeddings"></span><strong>embeddings</strong><a class="paramlink headerlink reference internal" href="#tint.attr.LofLime.params.embeddings">¶</a> (<em>Tensor</em>) – Tensor of embeddings to compute the LOF.</p></li>
<li><p><span class="target" id="tint.attr.LofLime.params.n_neighbors"></span><strong>n_neighbors</strong><a class="paramlink headerlink reference internal" href="#tint.attr.LofLime.params.n_neighbors">¶</a> (<em>int</em>) – Number of neighbors to use by default.
Default to 20</p></li>
<li><p><span class="target" id="tint.attr.LofLime.params.interpretable_model"></span><strong>interpretable_model</strong><a class="paramlink headerlink reference internal" href="#tint.attr.LofLime.params.interpretable_model">¶</a> (<em>optional</em><em>, </em><em>Model</em>) – <p>Model object to train
interpretable model.</p>
<p>This argument is optional and defaults to SkLearnLasso(alpha=0.01),
which is a wrapper around the Lasso linear model in SkLearn.
This requires having sklearn version &gt;= 0.23 available.</p>
<p>Other predefined interpretable linear models are provided in
captum._utils.models.linear_model.</p>
<p>Alternatively, a custom model object must provide a <cite>fit</cite> method to
train the model, given a dataloader, with batches containing
three tensors:</p>
<ul>
<li><p>interpretable_inputs: Tensor
[2D num_samples x num_interp_features],</p></li>
<li><p>expected_outputs: Tensor [1D num_samples],</p></li>
<li><p>weights: Tensor [1D num_samples]</p></li>
</ul>
<p>The model object must also provide a <cite>representation</cite> method to
access the appropriate coefficients or representation of the
interpretable model after fitting.</p>
<p>Note that calling fit multiple times should retrain the
interpretable model, each attribution call reuses
the same given interpretable model object.</p>
</p></li>
<li><p><span class="target" id="tint.attr.LofLime.params.similarity_func"></span><strong>similarity_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.LofLime.params.similarity_func">¶</a> (<em>optional</em><em>, </em><em>callable</em>) – <p>Function which takes a single sample
along with its corresponding interpretable representation
and returns the weight of the interpretable sample for
training the interpretable model.
This is often referred to as a similarity kernel.</p>
<p>This argument is optional and defaults to a function which
applies an exponential kernel to the consine distance between
the original input and perturbed input, with a kernel width
of 1.0.</p>
<p>A similarity function applying an exponential
kernel to cosine / euclidean distances can be constructed
using the provided get_exp_kernel_similarity_function in
captum.attr._core.lime.</p>
<p>Alternately, a custom callable can also be provided.
The expected signature of this callable is:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">similarity_func</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="n">original_input</span><span class="p">:</span> <span class="n">Tensor</span> <span class="ow">or</span> <span class="nb">tuple</span> <span class="n">of</span> <span class="n">Tensors</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="n">perturbed_input</span><span class="p">:</span> <span class="n">Tensor</span> <span class="ow">or</span> <span class="nb">tuple</span> <span class="n">of</span> <span class="n">Tensors</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="n">perturbed_interpretable_input</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>       <span class="n">Tensor</span> <span class="p">[</span><span class="mi">2</span><span class="n">D</span> <span class="mi">1</span> <span class="n">x</span> <span class="n">num_interp_features</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span> <span class="ow">or</span> <span class="n">Tensor</span> <span class="n">containing</span> <span class="nb">float</span> <span class="n">scalar</span>
</pre></div>
</div>
<p>perturbed_input and original_input will be the same type and
contain tensors of the same shape, with original_input
being the same as the input provided when calling attribute.</p>
<p>kwargs includes baselines, feature_mask, num_interp_features
(integer, determined from feature mask).</p>
</p></li>
<li><p><span class="target" id="tint.attr.LofLime.params.perturb_func"></span><strong>perturb_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.LofLime.params.perturb_func">¶</a> (<em>optional</em><em>, </em><em>callable</em>) – <p>Function which returns a single
sampled input, which is a binary vector of length
num_interp_features, or a generator of such tensors.</p>
<p>This function is optional, the default function returns
a binary vector where each element is selected
independently and uniformly at random. Custom
logic for selecting sampled binary vectors can
be implemented by providing a function with the
following expected signature:</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">perturb_func</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="n">original_input</span><span class="p">:</span> <span class="n">Tensor</span> <span class="ow">or</span> <span class="nb">tuple</span> <span class="n">of</span> <span class="n">Tensors</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span> <span class="p">[</span><span class="n">Binary</span> <span class="mi">2</span><span class="n">D</span> <span class="n">Tensor</span> <span class="mi">1</span> <span class="n">x</span> <span class="n">num_interp_features</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span> <span class="ow">or</span> <span class="n">generator</span> <span class="n">yielding</span> <span class="n">such</span> <span class="n">tensors</span>
</pre></div>
</div>
<p>kwargs includes baselines, feature_mask, num_interp_features
(integer, determined from feature mask).</p>
</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://arxiv.org/abs/2306.02968">Time Interpret: a Unified Model Interpretability Library for Time Series</a></p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">LofLime</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.models</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">LofLime</span><span class="p">(</span><span class="n">mlp</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.NonLinearitiesTunnel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">NonLinearitiesTunnel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">attribution_method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Attribution</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/non_linearities_tunnel.html#NonLinearitiesTunnel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.NonLinearitiesTunnel" title="Permalink to this definition"></a></dt>
<dd><p>Replace non linearities (or any module) with others before running
an attribution method. This tunnel is originally intended to
replace ReLU activations with Softplus to smooth the explanations.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This method will break if the forward_func contains functional
non linearities with additional arguments that need to be replaced.
For instance, replacing <code class="docutils literal notranslate"><span class="pre">F.softmax(x,</span> <span class="pre">dim=-1)</span></code> is not possible due
to the presence of the extra argument <code class="docutils literal notranslate"><span class="pre">dim</span></code>.</p>
</div>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>In order to replace any layer, a nn.Module must be passed as
forward_func. In particular, passing <code class="docutils literal notranslate"><span class="pre">model.forward</span></code> will result
in not replacing any layer in <code class="docutils literal notranslate"><span class="pre">model</span></code>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="target" id="tint.attr.NonLinearitiesTunnel.params.attribution_method"></span><strong>attribution_method</strong><a class="paramlink headerlink reference internal" href="#tint.attr.NonLinearitiesTunnel.params.attribution_method">¶</a> (<em>Attribution</em>) – An instance of any attribution
algorithm of type <cite>Attribution</cite>. E.g. Integrated Gradients,
Conductance or Saliency.</p>
</dd>
</dl>
<p class="rubric">References</p>
<ol class="arabic simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/2306.02968">Time Interpret: a Unified Model Interpretability Library for Time Series</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1906.07983">Explanations can be manipulated and geometry is to blame</a></p></li>
</ol>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">captum.attr</span> <span class="kn">import</span> <span class="n">Saliency</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">NonLinearitiesTunnel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.models</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">NonLinearitiesTunnel</span><span class="p">(</span><span class="n">Saliency</span><span class="p">(</span><span class="n">mlp</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.NonLinearitiesTunnel.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">to_replace</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Module</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">ReLU()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">replace_with</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Module</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">Softplus(beta=1,</span> <span class="pre">threshold=20)</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/tint/attr/non_linearities_tunnel.html#NonLinearitiesTunnel.attribute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.NonLinearitiesTunnel.attribute" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.NonLinearitiesTunnel.attribute.params.inputs"></span><strong>inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.NonLinearitiesTunnel.attribute.params.inputs">¶</a> (<em>tensor</em><em> or </em><em>tuple</em><em> of </em><em>tensors</em>) – Input for which integrated
gradients are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.
If forward_func takes multiple tensors as input, a tuple
of the input tensors should be provided. It is assumed
that for all given input tensors, dimension 0 corresponds
to the number of examples, and if multiple input tensors
are provided, the examples must be aligned appropriately.
It is also assumed that for all given input tensors,
dimension 1 corresponds to the time dimension, and if
multiple input tensors are provided, the examples must
be aligned appropriately.</p></li>
<li><p><span class="target" id="tint.attr.NonLinearitiesTunnel.attribute.params.to_replace"></span><strong>to_replace</strong><a class="paramlink headerlink reference internal" href="#tint.attr.NonLinearitiesTunnel.attribute.params.to_replace">¶</a> (<em>nn.Module</em><em>, </em><em>tuple</em><em>, </em><em>optional</em>) – Non linearities
to be  replaced. The linearities of type listed here will be
replaced by <code class="docutils literal notranslate"><span class="pre">replaced_by</span></code> non linearities before running
the attribution method. This can be an instance or a class.
If a class is passed, default attributes are used.
Default: nn.ReLU()</p></li>
<li><p><span class="target" id="tint.attr.NonLinearitiesTunnel.attribute.params.replace_with"></span><strong>replace_with</strong><a class="paramlink headerlink reference internal" href="#tint.attr.NonLinearitiesTunnel.attribute.params.replace_with">¶</a> (<em>nn.Module</em><em>, </em><em>tuple</em><em>, </em><em>optional</em>) – Non linearities
to replace the ones listed in <code class="docutils literal notranslate"><span class="pre">to_replace</span></code>.
Default: nn.Softplus()</p></li>
<li><p><span class="target" id="tint.attr.NonLinearitiesTunnel.attribute.params.**kwargs"></span><strong>**kwargs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.NonLinearitiesTunnel.attribute.params.**kwargs">¶</a> – (Any, optional): Contains a list of arguments that are
passed  to <cite>attribution_method</cite> attribution algorithm.
Any additional arguments that should be used for the
chosen attribution method should be included here.
For instance, such arguments include
<cite>additional_forward_args</cite> and <cite>baselines</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><dl class="simple">
<dt><strong>attributions</strong> (<em>tensor</em> or tuple of <em>tensors</em>):</dt><dd><p>Attribution with
respect to each input feature. attributions will always be
the same size as the provided inputs, with each value
providing the attribution of the corresponding input index.
If a single tensor is provided as inputs, a single tensor
is returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>delta</strong> (<em>float</em>, returned if return_convergence_delta=True):</dt><dd><p>Approximation error computed by the
attribution algorithm. Not all attribution algorithms
return delta value. It is computed only for some
algorithms, e.g. integrated gradients.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>attributions</strong> or 2-element tuple of <strong>attributions</strong>, <strong>delta</strong></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.NonLinearitiesTunnel.has_convergence_delta">
<span class="sig-name descname"><span class="pre">has_convergence_delta</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="reference internal" href="_modules/tint/attr/non_linearities_tunnel.html#NonLinearitiesTunnel.has_convergence_delta"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.NonLinearitiesTunnel.has_convergence_delta" title="Permalink to this definition"></a></dt>
<dd><p>This method informs the user whether the attribution algorithm provides
a convergence delta (aka an approximation error) or not. Convergence
delta may serve as a proxy of correctness of attribution algorithm’s
approximation. If deriving attribution class provides a
<cite>compute_convergence_delta</cite> method, it should
override both <cite>compute_convergence_delta</cite> and <cite>has_convergence_delta</cite> methods.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Returns whether the attribution algorithm
provides a convergence delta (aka approximation error) or not.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.Occlusion">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">Occlusion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/occlusion.html#Occlusion"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.Occlusion" title="Permalink to this definition"></a></dt>
<dd><p>A perturbation based approach to compute attribution, involving
replacing each contiguous rectangular region with a given baseline /
reference, and computing the difference in output. For features located
in multiple regions (hyperrectangles), the corresponding output differences
are averaged to compute the attribution for that feature.</p>
<p>The first patch is applied with the corner aligned with all indices 0,
and strides are applied until the entire dimension range is covered. Note
that this may cause the final patch applied in a direction to be cut-off
and thus smaller than the target occlusion shape.</p>
<p>More details regarding the occlusion (or grey-box / sliding window)
method can be found in the original paper and in the DeepExplain
implementation.
<a class="reference external" href="https://arxiv.org/abs/1311.2901">https://arxiv.org/abs/1311.2901</a>
<a class="reference external" href="https://github.com/marcoancona/DeepExplain/blob/master/deepexplain">https://github.com/marcoancona/DeepExplain/blob/master/deepexplain</a>/tensorflow/methods.py#L401</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="target" id="tint.attr.Occlusion.params.forward_func"></span><strong>forward_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Occlusion.params.forward_func">¶</a> (<em>Callable</em>) – The forward function of the model or any
modification of it.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">Occlusion</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.models</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">Occlusion</span><span class="p">(</span><span class="n">mlp</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.Occlusion.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sliding_window_shapes</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baselines</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">perturbations_per_eval</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attributions_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kwargs_run_forward</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></span><a class="reference internal" href="_modules/tint/attr/occlusion.html#Occlusion.attribute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.Occlusion.attribute" title="Permalink to this definition"></a></dt>
<dd><p>Attribute method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.Occlusion.attribute.params.inputs"></span><strong>inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Occlusion.attribute.params.inputs">¶</a> (<em>tensor</em><em> or </em><em>tuple</em><em> of </em><em>tensors</em>) – Input for which occlusion
attributions are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.
If forward_func takes multiple tensors as input, a tuple
of the input tensors should be provided. It is assumed
that for all given input tensors, dimension 0 corresponds
to the number of examples (aka batch size), and if
multiple input tensors are provided, the examples must
be aligned appropriately.</p></li>
<li><p><span class="target" id="tint.attr.Occlusion.attribute.params.sliding_window_shapes"></span><strong>sliding_window_shapes</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Occlusion.attribute.params.sliding_window_shapes">¶</a> (<em>tuple</em><em> or </em><em>tuple</em><em> of </em><em>tuples</em>) – Shape of patch
(hyperrectangle) to occlude each input. For a single
input tensor, this must be a tuple of length equal to the
number of dimensions of the input tensor - 1, defining
the dimensions of the patch. If the input tensor is 1-d,
this should be an empty tuple. For multiple input tensors,
this must be a tuple containing one tuple for each input
tensor defining the dimensions of the patch for that
input tensor, as described for the single tensor case.</p></li>
<li><p><span class="target" id="tint.attr.Occlusion.attribute.params.strides"></span><strong>strides</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Occlusion.attribute.params.strides">¶</a> (<em>int</em><em> or </em><em>tuple</em><em> or </em><em>tuple</em><em> of </em><em>ints</em><em> or </em><em>tuple</em><em> of </em><em>tuples</em><em>, </em><em>optional</em>) – This defines the step by which the occlusion hyperrectangle
should be shifted by in each direction for each iteration.
For a single tensor input, this can be either a single
integer, which is used as the step size in each direction,
or a tuple of integers matching the number of dimensions
in the occlusion shape, defining the step size in the
corresponding dimension. For multiple tensor inputs, this
can be either a tuple of integers, one for each input
tensor (used for all dimensions of the corresponding
tensor), or a tuple of tuples, providing the stride per
dimension for each tensor.
To ensure that all inputs are covered by at least one
sliding window, the stride for any dimension must be
&lt;= the corresponding sliding window dimension if the
sliding window dimension is less than the input
dimension.
If None is provided, a stride of 1 is used for each
dimension of each input tensor.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.Occlusion.attribute.params.baselines"></span><strong>baselines</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Occlusion.attribute.params.baselines">¶</a> (<em>scalar</em><em>, </em><em>tensor</em><em>, </em><em>tuple</em><em> of </em><em>scalars</em><em> or </em><em>tensors</em><em>, </em><em>optional</em>) – <p>Baselines define reference value which replaces each
feature when occluded.
Baselines can be provided as:</p>
<ul>
<li><p>a single tensor, if inputs is a single tensor, with
exactly the same dimensions as inputs or
broadcastable to match the dimensions of inputs</p></li>
<li><p>a single scalar, if inputs is a single tensor, which will
be broadcasted for each input value in input tensor.</p></li>
<li><p>a tuple of tensors or scalars, the baseline corresponding
to each tensor in the inputs’ tuple can be:</p>
<ul>
<li><p>either a tensor with matching dimensions to
corresponding tensor in the inputs’ tuple
or the first dimension is one and the remaining
dimensions match with the corresponding
input tensor.</p></li>
<li><p>or a scalar, corresponding to a tensor in the
inputs’ tuple. This scalar value is broadcasted
for corresponding input tensor.</p></li>
</ul>
</li>
</ul>
<p>In the cases when <cite>baselines</cite> is not provided, we internally
use zero scalar corresponding to each input tensor.
Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.Occlusion.attribute.params.target"></span><strong>target</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Occlusion.attribute.params.target">¶</a> (<em>int</em><em>, </em><em>tuple</em><em>, </em><em>Tensor</em><em>, or </em><em>list</em><em>, </em><em>optional</em>) – <p>Output indices for
which difference is computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><p>a single integer or a tensor containing a single
integer, which is applied to all input examples</p></li>
<li><p>a list of integers or a 1D tensor, with length matching
the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p></li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><p>A single tuple, which contains #output_dims - 1
elements. This target index is applied to all examples.</p></li>
<li><p>A list of tuples with length equal to the number of
examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p></li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.Occlusion.attribute.params.additional_forward_args"></span><strong>additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Occlusion.attribute.params.additional_forward_args">¶</a> (<em>any</em><em>, </em><em>optional</em>) – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a
tuple containing multiple additional arguments including
tensors or any arbitrary python types. These arguments
are provided to forward_func in order following the
arguments in inputs.
For a tensor, the first dimension of the tensor must
correspond to the number of examples. For all other types,
the given argument is used for all forward evaluations.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.Occlusion.attribute.params.perturbations_per_eval"></span><strong>perturbations_per_eval</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Occlusion.attribute.params.perturbations_per_eval">¶</a> (<em>int</em><em>, </em><em>optional</em>) – Allows multiple occlusions
to be included in one batch (one call to forward_fn).
By default, perturbations_per_eval is 1, so each occlusion
is processed individually.
Each forward pass will contain a maximum of
perturbations_per_eval * #examples samples.
For DataParallel models, each batch is split among the
available devices, so evaluations on each available
device contain at most
(perturbations_per_eval * #examples) / num_devices
samples.
Default: 1</p></li>
<li><p><span class="target" id="tint.attr.Occlusion.attribute.params.attributions_fn"></span><strong>attributions_fn</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Occlusion.attribute.params.attributions_fn">¶</a> (<em>Callable</em><em>, </em><em>optional</em>) – Applies a function to the
attributions before performing the weighted sum.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.Occlusion.attribute.params.show_progress"></span><strong>show_progress</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Occlusion.attribute.params.show_progress">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – Displays the progress of computation.
It will try to use tqdm if available for advanced features
(e.g. time estimation). Otherwise, it will fallback to
a simple output of progress.
Default: False</p></li>
<li><p><span class="target" id="tint.attr.Occlusion.attribute.params.kwargs_run_forward"></span><strong>kwargs_run_forward</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Occlusion.attribute.params.kwargs_run_forward">¶</a> (<em>Any</em><em>, </em><em>optional</em>) – Any additional arguments to pass
to the _run_forward method.
Default: None</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><dl class="simple">
<dt><strong>attributions</strong> (<em>tensor</em> or tuple of <em>tensors</em>):</dt><dd><p>The attributions with respect to each input feature.
Attributions will always be
the same size as the provided inputs, with each value
providing the attribution of the corresponding input index.
If a single tensor is provided as inputs, a single tensor is
returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>tensor</em> or tuple of <em>tensors</em> of <strong>attributions</strong></p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># SimpleClassifier takes a single input tensor of size Nx4x4,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># and returns an Nx3 tensor of class probabilities.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">SimpleClassifier</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Generating random input with size 2 x 4 x 4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Defining Occlusion interpreter</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ablator</span> <span class="o">=</span> <span class="n">Occlusion</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Computes occlusion attribution, ablating each 3x3 patch,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># shifting in each direction by the default of 1.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">ablator</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">sliding_window_shapes</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.Retain">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">Retain</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">retain</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="attr_models.html#tint.attr.models.RetainNet" title="tint.attr.models.retain.RetainNet"><span class="pre">RetainNet</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">datamodule</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">LightningDataModule</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Trainer</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">32</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/retain.html#Retain"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.Retain" title="Permalink to this definition"></a></dt>
<dd><p>Retain explainer method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.Retain.params.forward_func"></span><strong>forward_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Retain.params.forward_func">¶</a> (<em>Callable</em>) – The forward function of the model or any
modification of it.</p></li>
<li><p><span class="target" id="tint.attr.Retain.params.retain"></span><strong>retain</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Retain.params.retain">¶</a> (<a class="reference internal" href="attr_models.html#tint.attr.models.RetainNet" title="tint.attr.models.RetainNet"><em>RetainNet</em></a>) – A Retain network as a Pytorch Lightning
module. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, a default Retain Net will be created.
Default to <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><span class="target" id="tint.attr.Retain.params.datamodule"></span><strong>datamodule</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Retain.params.datamodule">¶</a> (<em>LightningDataModule</em>) – A Pytorch Lightning data
module which will be used to train the RetainNet.
Either a datamodule or features must be provided, they cannot be
None together. Default to <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><span class="target" id="tint.attr.Retain.params.features"></span><strong>features</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Retain.params.features">¶</a> (<em>Tensor</em>) – A tensor of features which will be used to train
the RetainNet. Either a datamodule or features must be provided,
they cannot be None together. If both are provided, features is
ignored. Default to <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://arxiv.org/abs/1608.05745">RETAIN: An Interpretable Predictive Model for Healthcare using Reverse Time Attention Mechanism</a></p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">Retain</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">Retain</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">th</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">))))</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.Retain.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_temporal_attributions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></span><a class="reference internal" href="_modules/tint/attr/retain.html#Retain.attribute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.Retain.attribute" title="Permalink to this definition"></a></dt>
<dd><p>attribute method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.Retain.attribute.params.inputs"></span><strong>inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Retain.attribute.params.inputs">¶</a> (<em>tensor</em><em> or </em><em>tuple</em><em> of </em><em>tensors</em>) – Input for which integrated
gradients are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.
If forward_func takes multiple tensors as input, a tuple
of the input tensors should be provided. It is assumed
that for all given input tensors, dimension 0 corresponds
to the number of examples, and if multiple input tensors
are provided, the examples must be aligned appropriately.</p></li>
<li><p><span class="target" id="tint.attr.Retain.attribute.params.target"></span><strong>target</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Retain.attribute.params.target">¶</a> (<em>int</em><em>, </em><em>tuple</em><em>, </em><em>tensor</em><em> or </em><em>list</em><em>, </em><em>optional</em>) – <p>Output indices for
which gradients are computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><p>a single integer or a tensor containing a single
integer, which is applied to all input examples</p></li>
<li><p>a list of integers or a 1D tensor, with length matching
the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p></li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><p>A single tuple, which contains #output_dims - 1
elements. This target index is applied to all examples.</p></li>
<li><p>A list of tuples with length equal to the number of
examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p></li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.Retain.attribute.params.return_temporal_attributions"></span><strong>return_temporal_attributions</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Retain.attribute.params.return_temporal_attributions">¶</a> (<em>bool</em>) – Whether to return
attributions for all times or not.
Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The attributions with respect to each input feature.
Attributions will always be
the same size as the provided inputs, with each value
providing the attribution of the corresponding input index.
If a single tensor is provided as inputs, a single tensor is
returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><ul class="simple">
<li><p><strong>attributions</strong> (<em>tensor</em> or tuple of <em>tensors</em>)</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.Retain.representation">
<span class="sig-name descname"><span class="pre">representation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/retain.html#Retain.representation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.Retain.representation" title="Permalink to this definition"></a></dt>
<dd><p>Get representations based on a model, inputs and potentially targets.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.Retain.representation.params.inputs"></span><strong>inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Retain.representation.params.inputs">¶</a> (<em>th.Tensor</em>) – Input data.</p></li>
<li><p><span class="target" id="tint.attr.Retain.representation.params.target"></span><strong>target</strong><a class="paramlink headerlink reference internal" href="#tint.attr.Retain.representation.params.target">¶</a> (<em>th.Tensor</em>) – Targets. Default to <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>attributions.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>th.Tensor</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.SequentialIntegratedGradients">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">SequentialIntegratedGradients</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multiply_by_inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/seq_ig.html#SequentialIntegratedGradients"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.SequentialIntegratedGradients" title="Permalink to this definition"></a></dt>
<dd><p>Sequential Integrated Gradients.</p>
<p>This method is the regular Integrated Gradients (IG) applied on each
component of a sequence. However, the baseline is specific to each
component: it keeps fixed the rest of the sequence while only setting the
component of interest to a reference baseline.</p>
<p>For instance, on a setence of m words, the attribution of each word is
computed by running IG with a specific baseline: fixing every other word
to their current value, and replacing the word of interest with “&lt;pad&gt;”,
an uninformative baseline.</p>
<p>This method can be computationally expensive on long sequences, as it
needs to compute IG on each component individually. It is therefore
suggested to reduce <code class="docutils literal notranslate"><span class="pre">n_steps</span></code> when using this method on long sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.SequentialIntegratedGradients.params.forward_func"></span><strong>forward_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.SequentialIntegratedGradients.params.forward_func">¶</a> (<em>callable</em>) – The forward function of the model or any
modification of it</p></li>
<li><p><span class="target" id="tint.attr.SequentialIntegratedGradients.params.multiply_by_inputs"></span><strong>multiply_by_inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.SequentialIntegratedGradients.params.multiply_by_inputs">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – <p>Indicates whether to factor
model inputs’ multiplier in the final attribution scores.
In the literature this is also known as local vs global
attribution. If inputs’ multiplier isn’t factored in,
then that type of attribution method is also called local
attribution. If it is, then that type of attribution
method is called global.
More detailed can be found here:
<a class="reference external" href="https://arxiv.org/abs/1711.06104">https://arxiv.org/abs/1711.06104</a></p>
<p>In case of integrated gradients, if <cite>multiply_by_inputs</cite>
is set to True, final sensitivity scores are being multiplied by
(inputs - baselines).</p>
</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://arxiv.org/abs/2305.15853">Sequential Integrated Gradients: a simple but effective method for explaining language models</a></p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">SequentialIntegratedGradients</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.models</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">SequentialIntegratedGradients</span><span class="p">(</span><span class="n">mlp</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.SequentialIntegratedGradients.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baselines</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">BaselineType</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TargetType</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'gausslegendre'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">internal_batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_convergence_delta</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="k"><span class="pre">False</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></span><a class="reference internal" href="_modules/tint/attr/seq_ig.html#SequentialIntegratedGradients.attribute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.SequentialIntegratedGradients.attribute" title="Permalink to this definition"></a></dt>
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baselines</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">BaselineType</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TargetType</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'gausslegendre'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">internal_batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_convergence_delta</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="k"><span class="pre">True</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">TensorOrTupleOfTensorsGeneric</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span></dt>
<dd><p>This method attributes the output of the model with given target index
(in case it is provided, otherwise it assumes that output is a
scalar) to the inputs of the model using the approach described above.</p>
<p>In addition to that it also returns, if <cite>return_convergence_delta</cite> is
set to True, integral approximation delta based on the completeness
property of integrated gradients.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.SequentialIntegratedGradients.attribute.params.inputs"></span><strong>inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.SequentialIntegratedGradients.attribute.params.inputs">¶</a> (<em>tensor</em><em> or </em><em>tuple</em><em> of </em><em>tensors</em>) – Input for which integrated
gradients are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.
If forward_func takes multiple tensors as input, a tuple
of the input tensors should be provided. It is assumed
that for all given input tensors, dimension 0 corresponds
to the number of examples, and if multiple input tensors
are provided, the examples must be aligned appropriately.</p></li>
<li><p><span class="target" id="tint.attr.SequentialIntegratedGradients.attribute.params.baselines"></span><strong>baselines</strong><a class="paramlink headerlink reference internal" href="#tint.attr.SequentialIntegratedGradients.attribute.params.baselines">¶</a> (<em>scalar</em><em>, </em><em>tensor</em><em>, </em><em>tuple</em><em> of </em><em>scalars</em><em> or </em><em>tensors</em><em>, </em><em>optional</em>) – <p>Baselines define the starting point from which integral
is computed and can be provided as:</p>
<ul>
<li><p>a single tensor, if inputs is a single tensor, with
exactly the same dimensions as inputs or the first
dimension is one and the remaining dimensions match
with inputs.</p></li>
<li><p>a single scalar, if inputs is a single tensor, which will
be broadcasted for each input value in input tensor.</p></li>
<li><p>a tuple of tensors or scalars, the baseline corresponding
to each tensor in the inputs’ tuple can be:</p>
<ul>
<li><p>either a tensor with matching dimensions to
corresponding tensor in the inputs’ tuple
or the first dimension is one and the remaining
dimensions match with the corresponding
input tensor.</p></li>
<li><p>or a scalar, corresponding to a tensor in the
inputs’ tuple. This scalar value is broadcasted
for corresponding input tensor.</p></li>
</ul>
</li>
</ul>
<p>In the cases when <cite>baselines</cite> is not provided, we internally
use zero scalar corresponding to each input tensor.</p>
<p>Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.SequentialIntegratedGradients.attribute.params.target"></span><strong>target</strong><a class="paramlink headerlink reference internal" href="#tint.attr.SequentialIntegratedGradients.attribute.params.target">¶</a> (<em>int</em><em>, </em><em>tuple</em><em>, </em><em>tensor</em><em> or </em><em>list</em><em>, </em><em>optional</em>) – <p>Output indices for
which gradients are computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><p>a single integer or a tensor containing a single
integer, which is applied to all input examples</p></li>
<li><p>a list of integers or a 1D tensor, with length matching
the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p></li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><p>A single tuple, which contains #output_dims - 1
elements. This target index is applied to all examples.</p></li>
<li><p>A list of tuples with length equal to the number of
examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p></li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.SequentialIntegratedGradients.attribute.params.additional_forward_args"></span><strong>additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.SequentialIntegratedGradients.attribute.params.additional_forward_args">¶</a> (<em>any</em><em>, </em><em>optional</em>) – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a
tuple containing multiple additional arguments including
tensors or any arbitrary python types. These arguments
are provided to forward_func in order following the
arguments in inputs.
For a tensor, the first dimension of the tensor must
correspond to the number of examples. It will be
repeated for each of <cite>n_steps</cite> along the integrated
path. For all other types, the given argument is used
for all forward evaluations.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.SequentialIntegratedGradients.attribute.params.n_steps"></span><strong>n_steps</strong><a class="paramlink headerlink reference internal" href="#tint.attr.SequentialIntegratedGradients.attribute.params.n_steps">¶</a> (<em>int</em><em>, </em><em>optional</em>) – The number of steps used by the approximation
method. Default: 50.</p></li>
<li><p><span class="target" id="tint.attr.SequentialIntegratedGradients.attribute.params.method"></span><strong>method</strong><a class="paramlink headerlink reference internal" href="#tint.attr.SequentialIntegratedGradients.attribute.params.method">¶</a> (<em>string</em><em>, </em><em>optional</em>) – Method for approximating the integral,
one of <cite>riemann_right</cite>, <cite>riemann_left</cite>, <cite>riemann_middle</cite>,
<cite>riemann_trapezoid</cite> or <cite>gausslegendre</cite>.
Default: <cite>gausslegendre</cite> if no method is provided.</p></li>
<li><p><span class="target" id="tint.attr.SequentialIntegratedGradients.attribute.params.internal_batch_size"></span><strong>internal_batch_size</strong><a class="paramlink headerlink reference internal" href="#tint.attr.SequentialIntegratedGradients.attribute.params.internal_batch_size">¶</a> (<em>int</em><em>, </em><em>optional</em>) – Divides total #steps * #examples
data points into chunks of size at most internal_batch_size,
which are computed (forward / backward passes)
sequentially. internal_batch_size must be at least equal to
#examples.
For DataParallel models, each batch is split among the
available devices, so evaluations on each available
device contain internal_batch_size / num_devices examples.
If internal_batch_size is None, then all evaluations are
processed in one batch.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.SequentialIntegratedGradients.attribute.params.return_convergence_delta"></span><strong>return_convergence_delta</strong><a class="paramlink headerlink reference internal" href="#tint.attr.SequentialIntegratedGradients.attribute.params.return_convergence_delta">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – Indicates whether to return
convergence delta or not. If <cite>return_convergence_delta</cite>
is set to True convergence delta will be returned in
a tuple following attributions.
Default: False</p></li>
<li><p><span class="target" id="tint.attr.SequentialIntegratedGradients.attribute.params.show_progress"></span><strong>show_progress</strong><a class="paramlink headerlink reference internal" href="#tint.attr.SequentialIntegratedGradients.attribute.params.show_progress">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – Displays the progress of
computation. It will try to use tqdm if available for
advanced features (e.g. time estimation). Otherwise, it
will fallback to a simple output of progress.
Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><dl class="simple">
<dt><strong>attributions</strong> (<em>tensor</em> or tuple of <em>tensors</em>):</dt><dd><p>Integrated gradients with respect to each input feature.
attributions will always be the same size as the provided
inputs, with each value providing the attribution of the
corresponding input index.
If a single tensor is provided as inputs, a single tensor is
returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>delta</strong> (<em>tensor</em>, returned if return_convergence_delta=True):</dt><dd><p>The difference between the total approximated and true
integrated gradients. This is computed using the property
that the total sum of forward_func(inputs) -
forward_func(baselines) must equal the total sum of the
integrated gradient.
Delta is calculated per example, meaning that the number of
elements in returned delta tensor is equal to the number of
of examples in inputs.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>attributions</strong> or 2-element tuple of <strong>attributions</strong>, <strong>delta</strong></p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># ImageClassifier takes a single input tensor of images Nx3x32x32,</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># and returns an Nx10 tensor of class probabilities.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">ImageClassifier</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sig</span> <span class="o">=</span> <span class="n">SequentialIntegratedGradients</span><span class="p">(</span><span class="n">net</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Computes integrated gradients for class 3.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attribution</span> <span class="o">=</span> <span class="n">sig</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.SequentialIntegratedGradients.has_convergence_delta">
<span class="sig-name descname"><span class="pre">has_convergence_delta</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="reference internal" href="_modules/tint/attr/seq_ig.html#SequentialIntegratedGradients.has_convergence_delta"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.SequentialIntegratedGradients.has_convergence_delta" title="Permalink to this definition"></a></dt>
<dd><p>This method informs the user whether the attribution algorithm provides
a convergence delta (aka an approximation error) or not. Convergence
delta may serve as a proxy of correctness of attribution algorithm’s
approximation. If deriving attribution class provides a
<cite>compute_convergence_delta</cite> method, it should
override both <cite>compute_convergence_delta</cite> and <cite>has_convergence_delta</cite> methods.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Returns whether the attribution algorithm
provides a convergence delta (aka approximation error) or not.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.TSRTunnel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">TSRTunnel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">attribution_method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Attribution</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/tsr_tunnel.html#TSRTunnel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.TSRTunnel" title="Permalink to this definition"></a></dt>
<dd><p>Two-step temporal saliency rescaling Tunnel.</p>
<p>Performs a two-step interpretation method:</p>
<ul class="simple">
<li><p>Mask all features at each time and compute the difference in the
resulting attribution.</p></li>
<li><p>Mask each feature at each time and compute the difference in the
resulting attribution, if the result of the first step is higher
than a threshold.</p></li>
</ul>
<p>By default, the masked features are replaced with zeros. However, a
custom baseline can also be passed.</p>
<p>Using the arguments <code class="docutils literal notranslate"><span class="pre">sliding_window_shapes</span></code> and <code class="docutils literal notranslate"><span class="pre">strides</span></code>, different
alternatives of TSR can be used:</p>
<ul>
<li><p>If:</p>
<ul class="simple">
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">sliding_window_shapes</span></code> = <cite>(1, 1, …)</cite></p></li>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">strides</span></code> = <cite>1</cite></p></li>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">threshold</span></code> = <span class="math notranslate nohighlight">\(\alpha\)</span></p></li>
</ul>
<p>the Feature-Relevance Score is computed by masking each feature
individually providing the Time-Relevance Score is above the threshold.
This corresponds to the <strong>Temporal Saliency Rescaling</strong> (TSR) method
(Algorithm 1).</p>
</li>
<li><p>If:</p>
<ul class="simple">
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">sliding_window_shapes</span></code> = <cite>(1, G, G, …)</cite></p></li>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">strides</span></code> = <cite>(1, G, G, …)</cite></p></li>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">threshold</span></code> = <span class="math notranslate nohighlight">\(\alpha\)</span></p></li>
</ul>
<p>the Feature-Relevance Score is computed by masking each feature as a
group of G features. This corresponds to the <strong>Temporal Saliency
Rescaling With Feature Grouping</strong> method (Algorithm 2).</p>
</li>
<li><p>If:</p>
<ul class="simple">
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">sliding_window_shapes</span></code> = <cite>(inputs.shape[1], 1, 1, …)</cite></p></li>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">strides</span></code> = <cite>1</cite></p></li>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">threshold</span></code> = <cite>0.0</cite></p></li>
</ul>
<p>the Feature-Relevance Score is computed by first masking each features
individually at every time steps. This corresponds to the <strong>Temporal
Feature Saliency Rescaling</strong> (TFSR) method (Algorithm 3).</p>
</li>
</ul>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>The convergence delta is ignored by this method, even if explicitely
required by the attribution method.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The attribution method used must output a tensor or tuple of tensor
of the same size as the inputs.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="target" id="tint.attr.TSRTunnel.params.attribution_method"></span><strong>attribution_method</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TSRTunnel.params.attribution_method">¶</a> (<em>Attribution</em>) – An instance of any attribution algorithm
of type <cite>Attribution</cite>. E.g. Integrated Gradients,
Conductance or Saliency.</p>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://arxiv.org/abs/2010.13924">Benchmarking Deep Learning Interpretability in Time Series Predictions</a></p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">captum.attr</span> <span class="kn">import</span> <span class="n">Saliency</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">TSRTunnel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.models</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">TSRTunnel</span><span class="p">(</span><span class="n">Saliency</span><span class="p">(</span><span class="n">mlp</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.TSRTunnel.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sliding_window_shapes</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baselines</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">perturbations_per_eval</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></span><a class="reference internal" href="_modules/tint/attr/tsr_tunnel.html#TSRTunnel.attribute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.TSRTunnel.attribute" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.TSRTunnel.attribute.params.inputs"></span><strong>inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TSRTunnel.attribute.params.inputs">¶</a> (<em>tensor</em><em> or </em><em>tuple</em><em> of </em><em>tensors</em>) – Input for which integrated
gradients are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.
If forward_func takes multiple tensors as input, a tuple
of the input tensors should be provided. It is assumed
that for all given input tensors, dimension 0 corresponds
to the number of examples, and if multiple input tensors
are provided, the examples must be aligned appropriately.
It is also assumed that for all given input tensors,
dimension 1 corresponds to the time dimension, and if
multiple input tensors are provided, the examples must
be aligned appropriately.</p></li>
<li><p><span class="target" id="tint.attr.TSRTunnel.attribute.params.sliding_window_shapes"></span><strong>sliding_window_shapes</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TSRTunnel.attribute.params.sliding_window_shapes">¶</a> (<em>tuple</em><em> or </em><em>tuple</em><em> of </em><em>tuples</em>) – Shape of patch
(hyperrectangle) to occlude each input. For a single
input tensor, this must be a tuple of length equal to the
number of dimensions of the input tensor - 1, defining
the dimensions of the patch. If the input tensor is 1-d,
this should be an empty tuple. For multiple input tensors,
this must be a tuple containing one tuple for each input
tensor defining the dimensions of the patch for that
input tensor, as described for the single tensor case.</p></li>
<li><p><span class="target" id="tint.attr.TSRTunnel.attribute.params.strides"></span><strong>strides</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TSRTunnel.attribute.params.strides">¶</a> (<em>int</em><em> or </em><em>tuple</em><em> or </em><em>tuple</em><em> of </em><em>ints</em><em> or </em><em>tuple</em><em> of </em><em>tuples</em><em>, </em><em>optional</em>) – This defines the step by which the occlusion hyperrectangle
should be shifted by in each direction for each iteration.
For a single tensor input, this can be either a single
integer, which is used as the step size in each direction,
or a tuple of integers matching the number of dimensions
in the occlusion shape, defining the step size in the
corresponding dimension. For multiple tensor inputs, this
can be either a tuple of integers, one for each input
tensor (used for all dimensions of the corresponding
tensor), or a tuple of tuples, providing the stride per
dimension for each tensor.
To ensure that all inputs are covered by at least one
sliding window, the stride for any dimension must be
&lt;= the corresponding sliding window dimension if the
sliding window dimension is less than the input
dimension.
If None is provided, a stride of 1 is used for each
dimension of each input tensor.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.TSRTunnel.attribute.params.baselines"></span><strong>baselines</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TSRTunnel.attribute.params.baselines">¶</a> (<em>scalar</em><em>, </em><em>tensor</em><em>, </em><em>tuple</em><em> of </em><em>scalars</em><em> or </em><em>tensors</em><em>, </em><em>optional</em>) – <p>Baselines define the starting point from which integral
is computed and can be provided as:</p>
<ul>
<li><p>a single tensor, if inputs is a single tensor, with
exactly the same dimensions as inputs or the first
dimension is one and the remaining dimensions match
with inputs.</p></li>
<li><p>a single scalar, if inputs is a single tensor, which will
be broadcasted for each input value in input tensor.</p></li>
<li><p>a tuple of tensors or scalars, the baseline corresponding
to each tensor in the inputs’ tuple can be:</p>
<ul>
<li><p>either a tensor with matching dimensions to
corresponding tensor in the inputs’ tuple
or the first dimension is one and the remaining
dimensions match with the corresponding
input tensor.</p></li>
<li><p>or a scalar, corresponding to a tensor in the
inputs’ tuple. This scalar value is broadcasted
for corresponding input tensor.</p></li>
</ul>
</li>
</ul>
<p>In the cases when <cite>baselines</cite> is not provided, we internally
use zero scalar corresponding to each input tensor.</p>
<p>Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.TSRTunnel.attribute.params.target"></span><strong>target</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TSRTunnel.attribute.params.target">¶</a> (<em>int</em><em>, </em><em>tuple</em><em>, </em><em>Tensor</em><em>, or </em><em>list</em><em>, </em><em>optional</em>) – <p>Output indices for
which difference is computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><p>a single integer or a tensor containing a single
integer, which is applied to all input examples</p></li>
<li><p>a list of integers or a 1D tensor, with length matching
the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p></li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><p>A single tuple, which contains #output_dims - 1
elements. This target index is applied to all examples.</p></li>
<li><p>A list of tuples with length equal to the number of
examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p></li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.TSRTunnel.attribute.params.additional_forward_args"></span><strong>additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TSRTunnel.attribute.params.additional_forward_args">¶</a> (<em>any</em><em>, </em><em>optional</em>) – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a
tuple containing multiple additional arguments including
tensors or any arbitrary python types. These arguments
are provided to forward_func in order following the
arguments in inputs.
For a tensor, the first dimension of the tensor must
correspond to the number of examples. For all other types,
the given argument is used for all forward evaluations.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.TSRTunnel.attribute.params.threshold"></span><strong>threshold</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TSRTunnel.attribute.params.threshold">¶</a> (<em>float</em>) – Threshold for the second step computation.
Default: 0.0</p></li>
<li><p><span class="target" id="tint.attr.TSRTunnel.attribute.params.normalize"></span><strong>normalize</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TSRTunnel.attribute.params.normalize">¶</a> (<em>float</em>) – Whether to normalize the temporal attribution
before applying the threshold.
Default: True</p></li>
<li><p><span class="target" id="tint.attr.TSRTunnel.attribute.params.perturbations_per_eval"></span><strong>perturbations_per_eval</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TSRTunnel.attribute.params.perturbations_per_eval">¶</a> (<em>int</em><em>, </em><em>optional</em>) – Allows multiple occlusions
to be included in one batch (one call to forward_fn).
By default, perturbations_per_eval is 1, so each occlusion
is processed individually.
Each forward pass will contain a maximum of
perturbations_per_eval * #examples samples.
For DataParallel models, each batch is split among the
available devices, so evaluations on each available
device contain at most
(perturbations_per_eval * #examples) / num_devices
samples.
Default: 1</p></li>
<li><p><span class="target" id="tint.attr.TSRTunnel.attribute.params.show_progress"></span><strong>show_progress</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TSRTunnel.attribute.params.show_progress">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – Displays the progress of computation.
It will try to use tqdm if available for advanced features
(e.g. time estimation). Otherwise, it will fallback to
a simple output of progress.
Default: False</p></li>
<li><p><span class="target" id="tint.attr.TSRTunnel.attribute.params.**kwargs"></span><strong>**kwargs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TSRTunnel.attribute.params.**kwargs">¶</a> – (Any, optional): Contains a list of arguments that are
passed  to <cite>attribution_method</cite> attribution algorithm.
Any additional arguments that should be used for the
chosen attribution method should be included here.
For instance, such arguments include
<cite>additional_forward_args</cite> and <cite>baselines</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><dl class="simple">
<dt><strong>attributions</strong> (<em>tensor</em> or tuple of <em>tensors</em>):</dt><dd><p>The attributions with respect to each input feature.
Attributions will always be
the same size as the provided inputs, with each value
providing the attribution of the corresponding input index.
If a single tensor is provided as inputs, a single tensor is
returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>tensor</em> or tuple of <em>tensors</em> of <strong>attributions</strong></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.TSRTunnel.has_convergence_delta">
<span class="sig-name descname"><span class="pre">has_convergence_delta</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="reference internal" href="_modules/tint/attr/tsr_tunnel.html#TSRTunnel.has_convergence_delta"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.TSRTunnel.has_convergence_delta" title="Permalink to this definition"></a></dt>
<dd><p>This method informs the user whether the attribution algorithm provides
a convergence delta (aka an approximation error) or not. Convergence
delta may serve as a proxy of correctness of attribution algorithm’s
approximation. If deriving attribution class provides a
<cite>compute_convergence_delta</cite> method, it should
override both <cite>compute_convergence_delta</cite> and <cite>has_convergence_delta</cite> methods.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Returns whether the attribution algorithm
provides a convergence delta (aka approximation error) or not.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.TemporalAugmentedOcclusion">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">TemporalAugmentedOcclusion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_sampling</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_temporal</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/temporal_augmented_occlusion.html#TemporalAugmentedOcclusion"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.TemporalAugmentedOcclusion" title="Permalink to this definition"></a></dt>
<dd><p>Temporal Augmented Occlusion.</p>
<p>This method modifies the original augmented occlusion by only perturbing
the last time, leaving the previous times unchanged. It can be used
together with <code class="docutils literal notranslate"><span class="pre">time_forward_tunnel</span></code> to compute attributions on time
series.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.TemporalAugmentedOcclusion.params.forward_func"></span><strong>forward_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalAugmentedOcclusion.params.forward_func">¶</a> (<em>callable</em>) – The forward function of the model or
any modification of it</p></li>
<li><p><span class="target" id="tint.attr.TemporalAugmentedOcclusion.params.data"></span><strong>data</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalAugmentedOcclusion.params.data">¶</a> (<em>tuple</em><em>, </em><em>Tensor</em>) – The data from which the baselines are sampled.</p></li>
<li><p><span class="target" id="tint.attr.TemporalAugmentedOcclusion.params.n_sampling"></span><strong>n_sampling</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalAugmentedOcclusion.params.n_sampling">¶</a> (<em>int</em>) – Number of sampling to run for each occlusion.
Default to 1</p></li>
<li><p><span class="target" id="tint.attr.TemporalAugmentedOcclusion.params.is_temporal"></span><strong>is_temporal</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalAugmentedOcclusion.params.is_temporal">¶</a> (<em>bool</em>) – Whether the data is temporal or not.
If <code class="docutils literal notranslate"><span class="pre">True</span></code>, the data will be ablated to the inputs
on the temporal dimension (dimension 1). Default to <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://arxiv.org/abs/2003.02821">What went wrong and when? Instance-wise Feature Importance for Time-series Models</a></p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">TemporalAugmentedOcclusion</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.models</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">TemporalAugmentedOcclusion</span><span class="p">(</span><span class="n">mlp</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,))</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.TemporalAugmentedOcclusion.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sliding_window_shapes</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">perturbations_per_eval</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attributions_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></span><a class="reference internal" href="_modules/tint/attr/temporal_augmented_occlusion.html#TemporalAugmentedOcclusion.attribute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.TemporalAugmentedOcclusion.attribute" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.TemporalAugmentedOcclusion.attribute.params.inputs"></span><strong>inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalAugmentedOcclusion.attribute.params.inputs">¶</a> (<em>tensor</em><em> or </em><em>tuple</em><em> of </em><em>tensors</em>) – Input for which occlusion
attributions are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.
If forward_func takes multiple tensors as input, a tuple
of the input tensors should be provided. It is assumed
that for all given input tensors, dimension 0 corresponds
to the number of examples (aka batch size), and if
multiple input tensors are provided, the examples must
be aligned appropriately.</p></li>
<li><p><span class="target" id="tint.attr.TemporalAugmentedOcclusion.attribute.params.sliding_window_shapes"></span><strong>sliding_window_shapes</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalAugmentedOcclusion.attribute.params.sliding_window_shapes">¶</a> (<em>tuple</em><em> or </em><em>tuple</em><em> of </em><em>tuples</em>) – Shape of patch
(hyperrectangle) to occlude each input. For a single
input tensor, this must be a tuple of length equal to the
number of dimensions of the input tensor - 2, defining
the dimensions of the patch. If the input tensor is 2-d,
this should be an empty tuple. For multiple input tensors,
this must be a tuple containing one tuple for each input
tensor defining the dimensions of the patch for that
input tensor, as described for the single tensor case.</p></li>
<li><p><span class="target" id="tint.attr.TemporalAugmentedOcclusion.attribute.params.strides"></span><strong>strides</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalAugmentedOcclusion.attribute.params.strides">¶</a> (<em>int</em><em> or </em><em>tuple</em><em> or </em><em>tuple</em><em> of </em><em>ints</em><em> or </em><em>tuple</em><em> of </em><em>tuples</em><em>, </em><em>optional</em>) – This defines the step by which the occlusion hyperrectangle
should be shifted by in each direction for each iteration.
For a single tensor input, this can be either a single
integer, which is used as the step size in each direction,
or a tuple of integers matching the number of dimensions
in the occlusion shape, defining the step size in the
corresponding dimension. For multiple tensor inputs, this
can be either a tuple of integers, one for each input
tensor (used for all dimensions of the corresponding
tensor), or a tuple of tuples, providing the stride per
dimension for each tensor.
To ensure that all inputs are covered by at least one
sliding window, the stride for any dimension must be
&lt;= the corresponding sliding window dimension if the
sliding window dimension is less than the input
dimension.
If None is provided, a stride of 1 is used for each
dimension of each input tensor.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.TemporalAugmentedOcclusion.attribute.params.target"></span><strong>target</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalAugmentedOcclusion.attribute.params.target">¶</a> (<em>int</em><em>, </em><em>tuple</em><em>, </em><em>tensor</em><em> or </em><em>list</em><em>, </em><em>optional</em>) – <p>Output indices for
which difference is computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><p>a single integer or a tensor containing a single
integer, which is applied to all input examples</p></li>
<li><p>a list of integers or a 1D tensor, with length matching
the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p></li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><p>A single tuple, which contains #output_dims - 1
elements. This target index is applied to all examples.</p></li>
<li><p>A list of tuples with length equal to the number of
examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p></li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.TemporalAugmentedOcclusion.attribute.params.additional_forward_args"></span><strong>additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalAugmentedOcclusion.attribute.params.additional_forward_args">¶</a> (<em>any</em><em>, </em><em>optional</em>) – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a
tuple containing multiple additional arguments including
tensors or any arbitrary python types. These arguments
are provided to forward_func in order following the
arguments in inputs.
For a tensor, the first dimension of the tensor must
correspond to the number of examples. For all other types,
the given argument is used for all forward evaluations.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.TemporalAugmentedOcclusion.attribute.params.perturbations_per_eval"></span><strong>perturbations_per_eval</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalAugmentedOcclusion.attribute.params.perturbations_per_eval">¶</a> (<em>int</em><em>, </em><em>optional</em>) – Allows multiple occlusions
to be included in one batch (one call to forward_fn).
By default, perturbations_per_eval is 1, so each occlusion
is processed individually.
Each forward pass will contain a maximum of
perturbations_per_eval * #examples samples.
For DataParallel models, each batch is split among the
available devices, so evaluations on each available
device contain at most
(perturbations_per_eval * #examples) / num_devices
samples.
Default: 1</p></li>
<li><p><span class="target" id="tint.attr.TemporalAugmentedOcclusion.attribute.params.attributions_fn"></span><strong>attributions_fn</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalAugmentedOcclusion.attribute.params.attributions_fn">¶</a> (<em>Callable</em><em>, </em><em>optional</em>) – Applies a function to the
attributions before performing the weighted sum.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.TemporalAugmentedOcclusion.attribute.params.show_progress"></span><strong>show_progress</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalAugmentedOcclusion.attribute.params.show_progress">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – Displays the progress of computation.
It will try to use tqdm if available for advanced features
(e.g. time estimation). Otherwise, it will fallback to
a simple output of progress.
Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><dl class="simple">
<dt><strong>attributions</strong> (<em>tensor</em> or tuple of <em>tensors</em>):</dt><dd><p>The attributions with respect to each input feature.
Attributions will always be
the same size as the provided inputs, with each value
providing the attribution of the corresponding input index.
If a single tensor is provided as inputs, a single tensor is
returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>tensor</em> or tuple of <em>tensors</em> of <strong>attributions</strong></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.TemporalIntegratedGradients">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">TemporalIntegratedGradients</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">multiply_by_inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/temporal_ig.html#TemporalIntegratedGradients"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.TemporalIntegratedGradients" title="Permalink to this definition"></a></dt>
<dd><p>Temporal Integrated Gradients.</p>
<p>This method computes gradients iteratively on a time series as such:
it crops the sequence up to a time, and only moves this last time from
a baseline to its original value.</p>
<p>The number of steps per time depends on the strategy. If it is
<code class="docutils literal notranslate"><span class="pre">'fixed'</span></code>, then n_steps gradients are computed for each time.
If it is <code class="docutils literal notranslate"><span class="pre">'interval'</span></code>, the number of steps depends on the interval
between two times: the larger, the greater number of points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.TemporalIntegratedGradients.params.forward_func"></span><strong>forward_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalIntegratedGradients.params.forward_func">¶</a> (<em>callable</em>) – The forward function of the model or
any modification of it.</p></li>
<li><p><span class="target" id="tint.attr.TemporalIntegratedGradients.params.multiply_by_inputs"></span><strong>multiply_by_inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalIntegratedGradients.params.multiply_by_inputs">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – <p>Indicates whether to factor
model inputs’ multiplier in the final attribution scores.
In the literature this is also known as local vs global
attribution. If inputs’ multiplier isn’t factored in,
then that type of attribution method is also called local
attribution. If it is, then that type of attribution
method is called global.
More detailed can be found here:
<a class="reference external" href="https://arxiv.org/abs/1711.06104">https://arxiv.org/abs/1711.06104</a></p>
<p>In case of integrated gradients, if <cite>multiply_by_inputs</cite>
is set to True, final sensitivity scores are being multiplied by
(inputs - baselines).</p>
</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://arxiv.org/abs/2306.02968">Time Interpret: a Unified Model Interpretability Library for Time Series</a></p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">TemporalIntegratedGradients</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.models</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">TemporalIntegratedGradients</span><span class="p">(</span><span class="n">mlp</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.TemporalIntegratedGradients.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baselines</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">BaselineType</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TargetType</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">times</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'gausslegendre'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'fixed'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">internal_batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_convergence_delta</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="k"><span class="pre">False</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temporal_target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temporal_additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_temporal_attributions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></span><a class="reference internal" href="_modules/tint/attr/temporal_ig.html#TemporalIntegratedGradients.attribute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.TemporalIntegratedGradients.attribute" title="Permalink to this definition"></a></dt>
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baselines</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">BaselineType</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TargetType</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">times</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_steps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'gausslegendre'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strategy</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'fixed'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">internal_batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_convergence_delta</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="k"><span class="pre">True</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temporal_target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temporal_additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_temporal_attributions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">TensorOrTupleOfTensorsGeneric</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span></dt>
<dd><p>Attribute method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.TemporalIntegratedGradients.attribute.params.inputs"></span><strong>inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalIntegratedGradients.attribute.params.inputs">¶</a> (<em>tensor</em><em> or </em><em>tuple</em><em> of </em><em>tensors</em>) – Input for which integrated
gradients are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.
If forward_func takes multiple tensors as input, a tuple
of the input tensors should be provided. It is assumed
that for all given input tensors, dimension 0 corresponds
to the number of examples, and if multiple input tensors
are provided, the examples must be aligned appropriately.</p></li>
<li><p><span class="target" id="tint.attr.TemporalIntegratedGradients.attribute.params.baselines"></span><strong>baselines</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalIntegratedGradients.attribute.params.baselines">¶</a> (<em>scalar</em><em>, </em><em>tensor</em><em>, </em><em>tuple</em><em> of </em><em>scalars</em><em> or </em><em>tensors</em><em>, </em><em>optional</em>) – <p>Baselines define the starting point from which integral
is computed and can be provided as:</p>
<ul>
<li><p>a single tensor, if inputs is a single tensor, with
exactly the same dimensions as inputs or the first
dimension is one and the remaining dimensions match
with inputs.</p></li>
<li><p>a single scalar, if inputs is a single tensor, which will
be broadcasted for each input value in input tensor.</p></li>
<li><p>a tuple of tensors or scalars, the baseline corresponding
to each tensor in the inputs’ tuple can be:</p>
<ul>
<li><p>either a tensor with matching dimensions to
corresponding tensor in the inputs’ tuple
or the first dimension is one and the remaining
dimensions match with the corresponding
input tensor.</p></li>
<li><p>or a scalar, corresponding to a tensor in the
inputs’ tuple. This scalar value is broadcasted
for corresponding input tensor.</p></li>
</ul>
</li>
</ul>
<p>In the cases when <cite>baselines</cite> is not provided, we internally
use zero scalar corresponding to each input tensor.</p>
<p>Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.TemporalIntegratedGradients.attribute.params.target"></span><strong>target</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalIntegratedGradients.attribute.params.target">¶</a> (<em>int</em><em>, </em><em>tuple</em><em>, </em><em>tensor</em><em> or </em><em>list</em><em>, </em><em>optional</em>) – <p>Output indices for
which gradients are computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><p>a single integer or a tensor containing a single
integer, which is applied to all input examples</p></li>
<li><p>a list of integers or a 1D tensor, with length matching
the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p></li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><p>A single tuple, which contains #output_dims - 1
elements. This target index is applied to all examples.</p></li>
<li><p>A list of tuples with length equal to the number of
examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p></li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.TemporalIntegratedGradients.attribute.params.additional_forward_args"></span><strong>additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalIntegratedGradients.attribute.params.additional_forward_args">¶</a> (<em>any</em><em>, </em><em>optional</em>) – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a
tuple containing multiple additional arguments including
tensors or any arbitrary python types. These arguments
are provided to forward_func in order following the
arguments in inputs.
For a tensor, the first dimension of the tensor must
correspond to the number of examples. It will be
repeated for each of <cite>n_steps</cite> along the integrated
path. For all other types, the given argument is used
for all forward evaluations.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.TemporalIntegratedGradients.attribute.params.times"></span><strong>times</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalIntegratedGradients.attribute.params.times">¶</a> (<em>Tensor</em><em>, </em><em>optional</em>) – Tensor of times. If not provided, it is
assumed that the points are temporally equally spaced.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.TemporalIntegratedGradients.attribute.params.n_steps"></span><strong>n_steps</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalIntegratedGradients.attribute.params.n_steps">¶</a> (<em>int</em><em>, </em><em>optional</em>) – The number of steps used by the approximation
method. Default: 50.</p></li>
<li><p><span class="target" id="tint.attr.TemporalIntegratedGradients.attribute.params.method"></span><strong>method</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalIntegratedGradients.attribute.params.method">¶</a> (<em>string</em><em>, </em><em>optional</em>) – Method for approximating the integral,
one of <cite>riemann_right</cite>, <cite>riemann_left</cite>, <cite>riemann_middle</cite>,
<cite>riemann_trapezoid</cite> or <cite>gausslegendre</cite>.
Default: <cite>gausslegendre</cite> if no method is provided.</p></li>
<li><p><span class="target" id="tint.attr.TemporalIntegratedGradients.attribute.params.strategy"></span><strong>strategy</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalIntegratedGradients.attribute.params.strategy">¶</a> (<em>str</em><em>, </em><em>optinal</em>) – Strategy to distribute gradients
evaluations over time. Either <code class="docutils literal notranslate"><span class="pre">'fixed'</span></code> or <code class="docutils literal notranslate"><span class="pre">'interval'</span></code>
Default: ‘fixed’</p></li>
<li><p><span class="target" id="tint.attr.TemporalIntegratedGradients.attribute.params.internal_batch_size"></span><strong>internal_batch_size</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalIntegratedGradients.attribute.params.internal_batch_size">¶</a> (<em>int</em><em>, </em><em>optional</em>) – Divides total #steps * #examples
data points into chunks of size at most internal_batch_size,
which are computed (forward / backward passes)
sequentially. internal_batch_size must be at least equal to
#examples.
For DataParallel models, each batch is split among the
available devices, so evaluations on each available
device contain internal_batch_size / num_devices examples.
If internal_batch_size is None, then all evaluations are
processed in one batch.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.TemporalIntegratedGradients.attribute.params.return_convergence_delta"></span><strong>return_convergence_delta</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalIntegratedGradients.attribute.params.return_convergence_delta">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – Indicates whether to return
convergence delta or not. If <cite>return_convergence_delta</cite>
is set to True convergence delta will be returned in
a tuple following attributions.
Default: False</p></li>
<li><p><span class="target" id="tint.attr.TemporalIntegratedGradients.attribute.params.temporal_target"></span><strong>temporal_target</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalIntegratedGradients.attribute.params.temporal_target">¶</a> – Temporal target. Default: False</p></li>
<li><p><span class="target" id="tint.attr.TemporalIntegratedGradients.attribute.params.temporal_additional_forward_args"></span><strong>temporal_additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalIntegratedGradients.attribute.params.temporal_additional_forward_args">¶</a> (<em>tuple</em>) – Set each
additional forward arg which is temporal.
Only used with return_temporal_attributions.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.TemporalIntegratedGradients.attribute.params.return_temporal_attributions"></span><strong>return_temporal_attributions</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalIntegratedGradients.attribute.params.return_temporal_attributions">¶</a> (<em>bool</em>) – Whether to return all saliencies
for all time points or only the last one per time point.
Default: False</p></li>
<li><p><span class="target" id="tint.attr.TemporalIntegratedGradients.attribute.params.show_progress"></span><strong>show_progress</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalIntegratedGradients.attribute.params.show_progress">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – Displays the progress of
computation. It will try to use tqdm if available for
advanced features (e.g. time estimation). Otherwise, it
will fallback to a simple output of progress.
Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><dl class="simple">
<dt><strong>attributions</strong> (<em>tensor</em> or tuple of <em>tensors</em>):</dt><dd><p>Integrated gradients with respect to each input feature.
attributions will always be the same size as the provided
inputs, with each value providing the attribution of the
corresponding input index.
If a single tensor is provided as inputs, a single tensor is
returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>delta</strong> (<em>tensor</em>, returned if return_convergence_delta=True):</dt><dd><p>The difference between the total approximated and true
integrated gradients. This is computed using the property
that the total sum of forward_func(inputs) -
forward_func(baselines) must equal the total sum of the
integrated gradient.
Delta is calculated per example, meaning that the number of
elements in returned delta tensor is equal to the number of
of examples in inputs.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>attributions</strong> or 2-element tuple of <strong>attributions</strong>, <strong>delta</strong></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.TemporalOcclusion">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">TemporalOcclusion</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_func</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/temporal_occlusion.html#TemporalOcclusion"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.TemporalOcclusion" title="Permalink to this definition"></a></dt>
<dd><p>Temporal Occlusion.</p>
<p>This method modifies the original occlusion by only perturbing the last
time, leaving the previous times unchanged. It can be used together with
<code class="docutils literal notranslate"><span class="pre">time_forward_tunnel</span></code> to compute attributions on time series.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="target" id="tint.attr.TemporalOcclusion.params.forward_func"></span><strong>forward_func</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalOcclusion.params.forward_func">¶</a> (<em>callable</em>) – The forward function of the model or
any modification of it.</p>
</dd>
</dl>
<p class="rubric">References</p>
<p><a class="reference external" href="https://arxiv.org/abs/2003.02821">What went wrong and when? Instance-wise Feature Importance for Time-series Models</a></p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">TemporalOcclusion</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.models</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">TemporalOcclusion</span><span class="p">(</span><span class="n">mlp</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,))</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.TemporalOcclusion.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sliding_window_shapes</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">strides</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">baselines</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">float</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">None</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">int</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">perturbations_per_eval</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">attributions_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">TensorOrTupleOfTensorsGeneric</span></span></span><a class="reference internal" href="_modules/tint/attr/temporal_occlusion.html#TemporalOcclusion.attribute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.TemporalOcclusion.attribute" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.TemporalOcclusion.attribute.params.inputs"></span><strong>inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalOcclusion.attribute.params.inputs">¶</a> (<em>tensor</em><em> or </em><em>tuple</em><em> of </em><em>tensors</em>) – Input for which occlusion
attributions are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.
If forward_func takes multiple tensors as input, a tuple
of the input tensors should be provided. It is assumed
that for all given input tensors, dimension 0 corresponds
to the number of examples (aka batch size), and if
multiple input tensors are provided, the examples must
be aligned appropriately.</p></li>
<li><p><span class="target" id="tint.attr.TemporalOcclusion.attribute.params.sliding_window_shapes"></span><strong>sliding_window_shapes</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalOcclusion.attribute.params.sliding_window_shapes">¶</a> (<em>tuple</em><em> or </em><em>tuple</em><em> of </em><em>tuples</em>) – Shape of patch
(hyperrectangle) to occlude each input. For a single
input tensor, this must be a tuple of length equal to the
number of dimensions of the input tensor - 2, defining
the dimensions of the patch. If the input tensor is 2-d,
this should be an empty tuple. For multiple input tensors,
this must be a tuple containing one tuple for each input
tensor defining the dimensions of the patch for that
input tensor, as described for the single tensor case.</p></li>
<li><p><span class="target" id="tint.attr.TemporalOcclusion.attribute.params.strides"></span><strong>strides</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalOcclusion.attribute.params.strides">¶</a> (<em>int</em><em> or </em><em>tuple</em><em> or </em><em>tuple</em><em> of </em><em>ints</em><em> or </em><em>tuple</em><em> of </em><em>tuples</em><em>, </em><em>optional</em>) – This defines the step by which the occlusion hyperrectangle
should be shifted by in each direction for each iteration.
For a single tensor input, this can be either a single
integer, which is used as the step size in each direction,
or a tuple of integers matching the number of dimensions
in the occlusion shape, defining the step size in the
corresponding dimension. For multiple tensor inputs, this
can be either a tuple of integers, one for each input
tensor (used for all dimensions of the corresponding
tensor), or a tuple of tuples, providing the stride per
dimension for each tensor.
To ensure that all inputs are covered by at least one
sliding window, the stride for any dimension must be
&lt;= the corresponding sliding window dimension if the
sliding window dimension is less than the input
dimension.
If None is provided, a stride of 1 is used for each
dimension of each input tensor.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.TemporalOcclusion.attribute.params.baselines"></span><strong>baselines</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalOcclusion.attribute.params.baselines">¶</a> (<em>scalar</em><em>, </em><em>tensor</em><em>, </em><em>tuple</em><em> of </em><em>scalars</em><em> or </em><em>tensors</em><em>, </em><em>optional</em>) – <p>Baselines define reference value which replaces each
feature when occluded.
Baselines can be provided as:</p>
<ul>
<li><p>a single tensor, if inputs is a single tensor, with
exactly the same dimensions as inputs or
broadcastable to match the dimensions of inputs</p></li>
<li><p>a single scalar, if inputs is a single tensor, which will
be broadcasted for each input value in input tensor.</p></li>
<li><p>a tuple of tensors or scalars, the baseline corresponding
to each tensor in the inputs’ tuple can be:</p>
<ul>
<li><p>either a tensor with matching dimensions to
corresponding tensor in the inputs’ tuple
or the first dimension is one and the remaining
dimensions match with the corresponding
input tensor.</p></li>
<li><p>or a scalar, corresponding to a tensor in the
inputs’ tuple. This scalar value is broadcasted
for corresponding input tensor.</p></li>
</ul>
</li>
</ul>
<p>In the cases when <cite>baselines</cite> is not provided, we internally
use zero scalar corresponding to each input tensor.
Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.TemporalOcclusion.attribute.params.target"></span><strong>target</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalOcclusion.attribute.params.target">¶</a> (<em>int</em><em>, </em><em>tuple</em><em>, </em><em>tensor</em><em> or </em><em>list</em><em>, </em><em>optional</em>) – <p>Output indices for
which difference is computed (for classification cases,
this is usually the target class).
If the network returns a scalar value per example,
no target index is necessary.
For general 2D outputs, targets can be either:</p>
<ul>
<li><p>a single integer or a tensor containing a single
integer, which is applied to all input examples</p></li>
<li><p>a list of integers or a 1D tensor, with length matching
the number of examples in inputs (dim 0). Each integer
is applied as the target for the corresponding example.</p></li>
</ul>
<p>For outputs with &gt; 2 dimensions, targets can be either:</p>
<ul>
<li><p>A single tuple, which contains #output_dims - 1
elements. This target index is applied to all examples.</p></li>
<li><p>A list of tuples with length equal to the number of
examples in inputs (dim 0), and each tuple containing
#output_dims - 1 elements. Each tuple is applied as the
target for the corresponding example.</p></li>
</ul>
<p>Default: None</p>
</p></li>
<li><p><span class="target" id="tint.attr.TemporalOcclusion.attribute.params.additional_forward_args"></span><strong>additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalOcclusion.attribute.params.additional_forward_args">¶</a> (<em>any</em><em>, </em><em>optional</em>) – If the forward function
requires additional arguments other than the inputs for
which attributions should not be computed, this argument
can be provided. It must be either a single additional
argument of a Tensor or arbitrary (non-tuple) type or a
tuple containing multiple additional arguments including
tensors or any arbitrary python types. These arguments
are provided to forward_func in order following the
arguments in inputs.
For a tensor, the first dimension of the tensor must
correspond to the number of examples. For all other types,
the given argument is used for all forward evaluations.
Note that attributions are not computed with respect
to these arguments.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.TemporalOcclusion.attribute.params.perturbations_per_eval"></span><strong>perturbations_per_eval</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalOcclusion.attribute.params.perturbations_per_eval">¶</a> (<em>int</em><em>, </em><em>optional</em>) – Allows multiple occlusions
to be included in one batch (one call to forward_fn).
By default, perturbations_per_eval is 1, so each occlusion
is processed individually.
Each forward pass will contain a maximum of
perturbations_per_eval * #examples samples.
For DataParallel models, each batch is split among the
available devices, so evaluations on each available
device contain at most
(perturbations_per_eval * #examples) / num_devices
samples.
Default: 1</p></li>
<li><p><span class="target" id="tint.attr.TemporalOcclusion.attribute.params.attributions_fn"></span><strong>attributions_fn</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalOcclusion.attribute.params.attributions_fn">¶</a> (<em>Callable</em><em>, </em><em>optional</em>) – Applies a function to the
attributions before performing the weighted sum.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.TemporalOcclusion.attribute.params.show_progress"></span><strong>show_progress</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TemporalOcclusion.attribute.params.show_progress">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – Displays the progress of computation.
It will try to use tqdm if available for advanced features
(e.g. time estimation). Otherwise, it will fallback to
a simple output of progress.
Default: False</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><dl class="simple">
<dt><strong>attributions</strong> (<em>tensor</em> or tuple of <em>tensors</em>):</dt><dd><p>The attributions with respect to each input feature.
Attributions will always be
the same size as the provided inputs, with each value
providing the attribution of the corresponding input index.
If a single tensor is provided as inputs, a single tensor is
returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><em>tensor</em> or tuple of <em>tensors</em> of <strong>attributions</strong></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="tint.attr.TimeForwardTunnel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">tint.attr.</span></span><span class="sig-name descname"><span class="pre">TimeForwardTunnel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">attribution_method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Attribution</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/tint/attr/time_forward_tunnel.html#TimeForwardTunnel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.TimeForwardTunnel" title="Permalink to this definition"></a></dt>
<dd><p>Time Forward Tunnel.</p>
<p>Performs interpretation method by iteratively retrieving the input data
up to a time, and computing the predictions using this data and the
forward_func.</p>
<p>The true target can be passed, otherwise it will be inferred depending on
the task.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="target" id="tint.attr.TimeForwardTunnel.params.attribution_method"></span><strong>attribution_method</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TimeForwardTunnel.params.attribution_method">¶</a> (<em>Attribution</em>) – An instance of any attribution algorithm
of type <cite>Attribution</cite>. E.g. Integrated Gradients,
Conductance or Saliency.</p>
</dd>
</dl>
<p class="rubric">References</p>
<ol class="arabic simple">
<li><p><a class="reference external" href="https://arxiv.org/abs/2003.02821">What went wrong and when? Instance-wise Feature Importance for Time-series Models</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/2306.02968">Time Interpret: a Unified Model Interpretability Library for Time Series</a></p></li>
</ol>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span> <span class="k">as</span> <span class="nn">th</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">captum.attr</span> <span class="kn">import</span> <span class="n">Saliency</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.attr</span> <span class="kn">import</span> <span class="n">TimeForwardTunnel</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">tint.models</span> <span class="kn">import</span> <span class="n">MLP</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">inputs</span> <span class="o">=</span> <span class="n">th</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlp</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">explainer</span> <span class="o">=</span> <span class="n">TimeForwardTunnel</span><span class="p">(</span><span class="n">Saliency</span><span class="p">(</span><span class="n">mlp</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attr</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.TimeForwardTunnel.attribute">
<span class="sig-name descname"><span class="pre">attribute</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'none'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temporal_target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">temporal_additional_forward_args</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">bool</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_temporal_attributions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_progress</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Any</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="p"><span class="pre">...</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/tint/attr/time_forward_tunnel.html#TimeForwardTunnel.attribute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.TimeForwardTunnel.attribute" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><span class="target" id="tint.attr.TimeForwardTunnel.attribute.params.inputs"></span><strong>inputs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TimeForwardTunnel.attribute.params.inputs">¶</a> (<em>tensor</em><em> or </em><em>tuple</em><em> of </em><em>tensors</em>) – Input for which integrated
gradients are computed. If forward_func takes a single
tensor as input, a single input tensor should be provided.
If forward_func takes multiple tensors as input, a tuple
of the input tensors should be provided. It is assumed
that for all given input tensors, dimension 0 corresponds
to the number of examples, and if multiple input tensors
are provided, the examples must be aligned appropriately.
It is also assumed that for all given input tensors,
dimension 1 corresponds to the time dimension, and if
multiple input tensors are provided, the examples must
be aligned appropriately.</p></li>
<li><p><span class="target" id="tint.attr.TimeForwardTunnel.attribute.params.task"></span><strong>task</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TimeForwardTunnel.attribute.params.task">¶</a> (<em>str</em>) – Type of task done by the model. Either <code class="docutils literal notranslate"><span class="pre">'binary'</span></code>,
<code class="docutils literal notranslate"><span class="pre">'multilabel'</span></code>, <code class="docutils literal notranslate"><span class="pre">'multiclass'</span></code> or <code class="docutils literal notranslate"><span class="pre">'regression'</span></code>.
Default: ‘binary’</p></li>
<li><p><span class="target" id="tint.attr.TimeForwardTunnel.attribute.params.threshold"></span><strong>threshold</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TimeForwardTunnel.attribute.params.threshold">¶</a> (<em>float</em>) – Threshold for the multilabel task.
Default: 0.5</p></li>
<li><p><span class="target" id="tint.attr.TimeForwardTunnel.attribute.params.temporal_target"></span><strong>temporal_target</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TimeForwardTunnel.attribute.params.temporal_target">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – Determine if the targe is
temporal and needs to be cut.
Default: False</p></li>
<li><p><span class="target" id="tint.attr.TimeForwardTunnel.attribute.params.temporal_additional_forward_args"></span><strong>temporal_additional_forward_args</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TimeForwardTunnel.attribute.params.temporal_additional_forward_args">¶</a> (<em>tuple</em><em>, </em><em>optional</em>) – For each
additional forward arg, determine if it is temporal
or not.
Default: None</p></li>
<li><p><span class="target" id="tint.attr.TimeForwardTunnel.attribute.params.return_temporal_attributions"></span><strong>return_temporal_attributions</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TimeForwardTunnel.attribute.params.return_temporal_attributions">¶</a> (<em>bool</em>) – Whether to return all saliencies
for all time points or only the last one per time point.
Default: False</p></li>
<li><p><span class="target" id="tint.attr.TimeForwardTunnel.attribute.params.show_progress"></span><strong>show_progress</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TimeForwardTunnel.attribute.params.show_progress">¶</a> (<em>bool</em><em>, </em><em>optional</em>) – Displays the progress of computation.
It will try to use tqdm if available for advanced features
(e.g. time estimation). Otherwise, it will fallback to
a simple output of progress.
Default: False</p></li>
<li><p><span class="target" id="tint.attr.TimeForwardTunnel.attribute.params.**kwargs"></span><strong>**kwargs</strong><a class="paramlink headerlink reference internal" href="#tint.attr.TimeForwardTunnel.attribute.params.**kwargs">¶</a> – (Any, optional): Contains a list of arguments that are
passed  to <cite>attribution_method</cite> attribution algorithm.
Any additional arguments that should be used for the
chosen attribution method should be included here.
For instance, such arguments include
<cite>additional_forward_args</cite> and <cite>baselines</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><dl class="simple">
<dt><strong>attributions</strong> (<em>tensor</em> or tuple of <em>tensors</em>):</dt><dd><p>Attribution with
respect to each input feature. attributions will always be
the same size as the provided inputs, with each value
providing the attribution of the corresponding input index.
If a single tensor is provided as inputs, a single tensor
is returned. If a tuple is provided for inputs, a tuple of
corresponding sized tensors is returned.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>delta</strong> (<em>float</em>, returned if return_convergence_delta=True):</dt><dd><p>Approximation error computed by the
attribution algorithm. Not all attribution algorithms
return delta value. It is computed only for some
algorithms, e.g. integrated gradients.</p>
</dd>
</dl>
</li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>attributions</strong> or 2-element tuple of <strong>attributions</strong>, <strong>delta</strong></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="tint.attr.TimeForwardTunnel.has_convergence_delta">
<span class="sig-name descname"><span class="pre">has_convergence_delta</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="reference internal" href="_modules/tint/attr/time_forward_tunnel.html#TimeForwardTunnel.has_convergence_delta"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#tint.attr.TimeForwardTunnel.has_convergence_delta" title="Permalink to this definition"></a></dt>
<dd><p>This method informs the user whether the attribution algorithm provides
a convergence delta (aka an approximation error) or not. Convergence
delta may serve as a proxy of correctness of attribution algorithm’s
approximation. If deriving attribution class provides a
<cite>compute_convergence_delta</cite> method, it should
override both <cite>compute_convergence_delta</cite> and <cite>has_convergence_delta</cite> methods.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Returns whether the attribution algorithm
provides a convergence delta (aka approximation error) or not.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="install.html" class="btn btn-neutral float-left" title="Installation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="attr_models.html" class="btn btn-neutral float-right" title="Attribution Models" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright Joseph Enguehard.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>